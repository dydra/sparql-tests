<http://blog.aksw.org/2011/dr-philipp_cimiano_visits_aksw/> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<p>On Jan 21st, Dr.Philipp Cimiano, Dr. Christina Unger and Dr.\nJohn McCrae from the <a href=\"http://www.sc.cit-ec.uni-bielefeld.de/home\" target=\"_blank\">Semantic Computing Group</a> at CITEC at the University of\nBielefeld visited AKSW. After each one briefly introduced\nthemselves, S\u00F6ren gave an overview of the activities and projects\nthat AKSW is currently involved in focusing on the current projects\nthat would be of interest to the visitors. Thereafter, John gave a\ndetailed presentation about the <a href=\"http://www.sc.cit-ec.uni-bielefeld.de/projects/monnet\" target=\"_blank\">MONNET</a> project, in which a lexical model for\nontologies is developed, which provides multilingual ontology\nlocalization, cross-lingual ontology-based information extraction\nand multi-lingual knowledge access and visualization. This was\nfollowed by an interesting discussion of possible integration of\nMONNET with OntoWiki. In particular, OntoWiki could be used as an\neditor for so called lemon models, which are used in MONNET. Next,\nSebastian Hellmann presented his PhD project, that is, the <a href=\"http://aksw.org/Projects/NLP2RDF\" target=\"_blank\">NLP2RDF\nframework</a>, which integrates multiple NLP tools and linguistic\nontologies in order to explicate implicit meaning of natural\nlanguage by means of RDF/OWL descriptions. He also shared his\nlatest efforts to build a linguistic LOD cloud. Post lunch, we\nsplit up into a smaller group to discuss about specific projects\nwithin both groups. Christina gave a presentation on the question\nanswering system <a href=\"http://www.sc.cit-ec.uni-bielefeld.de/pythia\" target=\"_blank\">Pythia</a> that uses lemon for linguistic parsing.\nThereafter, John demonstrated the lemon system, S\u00F6ren showed the\nLOD Query system (currently work in progress) and Jens demonstrated\nthe AutoSPARQL prototype.\u00A0 Moreover, experimental settings for\nthe \u201C<a href=\"http://www.sc.cit-ec.uni-bielefeld.de/qald-1\" target=\"_blank\">1st Challenge on Question Answering over Linked Data</a>\u201D\nwere discussed. The meeting ended with exchange of interesting\nideas discussions about potential collaborations between the two\ngroups. Some individual meetings between group meetings were\nscheduled, in particular related to question answering systems and\nNLP models, where we hope to push the state of the art by combining\nknowledge and experience from both groups.</p>\n<p><a href=\"http://blog.aksw.org/wp-content/uploads/2011/02/Talk.jpg\"><img class=\"size-medium wp-image-200 alignleft\" title=\"S\u00F6ren Talk\" src=\"http://blog.aksw.org/wp-content/uploads/2011/02/Talk-300x136.jpg\" alt=\"\" width=\"300\" height=\"136\"></img></a></p>\n<p><a href=\"http://blog.aksw.org/wp-content/uploads/2011/02/IMG_1056.jpg\"><img class=\"alignright size-medium wp-image-217\" title=\"John Talk\" src=\"http://blog.aksw.org/wp-content/uploads/2011/02/IMG_1056-300x225.jpg\" alt=\"\" width=\"168\" height=\"126\"></img></a></p>\n</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://blog.aksw.org/2011/dr-philipp_cimiano_visits_aksw/> <http://purl.org/dc/elements/1.1/creator> "AKSW Group - University of Leipzig" .
<http://blog.aksw.org/2011/dr-philipp_cimiano_visits_aksw/> <http://purl.org/dc/elements/1.1/date> "2011-02-08T10:22:43Z" .
<http://blog.aksw.org/2011/dr-philipp_cimiano_visits_aksw/> <http://purl.org/dc/elements/1.1/relation> "http://blog.aksw.org/" .
<http://blog.aksw.org/2011/dr-philipp_cimiano_visits_aksw/> <http://purl.org/dc/elements/1.1/source> "AKSW Group - University of Leipzig" .
<http://blog.aksw.org/2011/dr-philipp_cimiano_visits_aksw/> <http://purl.org/rss/1.0/description> "On Jan 21st, Dr.Philipp Cimiano, Dr. Christina Unger and Dr. John McCrae from the Semantic Computing Group at CITEC at the University of Bielefeld visited AKSW. After each one briefly introduced themselves, S\u00F6ren gave an overview of the activities and projects that AKSW is currently involved in focusing on the current projects that would be of interest to the visitors. Thereafter, John gave a detailed presentation about the MONNET project, in which a lexical model for ontologies is developed, which provides multilingual ontology localization, cross-lingual ontology-based information extraction and multi-lingual knowledge access and visualization. This was followed by an interesting ..." .
<http://blog.aksw.org/2011/dr-philipp_cimiano_visits_aksw/> <http://purl.org/rss/1.0/link> "http://blog.aksw.org/2011/dr-philipp_cimiano_visits_aksw/" .
<http://blog.aksw.org/2011/dr-philipp_cimiano_visits_aksw/> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<p>On Jan 21st, Dr.Philipp Cimiano, Dr. Christina Unger and Dr.\nJohn McCrae from the <a href=\n\"http://www.sc.cit-ec.uni-bielefeld.de/home\" target=\n\"_blank\">Semantic Computing Group</a> at CITEC at the University of\nBielefeld visited AKSW. After each one briefly introduced\nthemselves, S\u00F6ren gave an overview of the activities and projects\nthat AKSW is currently involved in focusing on the current projects\nthat would be of interest to the visitors. Thereafter, John gave a\ndetailed presentation about the <a href=\n\"http://www.sc.cit-ec.uni-bielefeld.de/projects/monnet\" target=\n\"_blank\">MONNET</a> project, in which a lexical model for\nontologies is developed, which provides multilingual ontology\nlocalization, cross-lingual ontology-based information extraction\nand multi-lingual knowledge access and visualization. This was\nfollowed by an interesting discussion of possible integration of\nMONNET with OntoWiki. In particular, OntoWiki could be used as an\neditor for so called lemon models, which are used in MONNET. Next,\nSebastian Hellmann presented his PhD project, that is, the <a href=\n\"http://aksw.org/Projects/NLP2RDF\" target=\"_blank\">NLP2RDF\nframework</a>, which integrates multiple NLP tools and linguistic\nontologies in order to explicate implicit meaning of natural\nlanguage by means of RDF/OWL descriptions. He also shared his\nlatest efforts to build a linguistic LOD cloud. Post lunch, we\nsplit up into a smaller group to discuss about specific projects\nwithin both groups. Christina gave a presentation on the question\nanswering system <a href=\n\"http://www.sc.cit-ec.uni-bielefeld.de/pythia\" target=\n\"_blank\">Pythia</a> that uses lemon for linguistic parsing.\nThereafter, John demonstrated the lemon system, S\u00F6ren showed the\nLOD Query system (currently work in progress) and Jens demonstrated\nthe AutoSPARQL prototype.&#160; Moreover, experimental settings for\nthe \u201C<a href=\"http://www.sc.cit-ec.uni-bielefeld.de/qald-1\" target=\n\"_blank\">1st Challenge on Question Answering over Linked Data</a>\u201D\nwere discussed. The meeting ended with exchange of interesting\nideas discussions about potential collaborations between the two\ngroups. Some individual meetings between group meetings were\nscheduled, in particular related to question answering systems and\nNLP models, where we hope to push the state of the art by combining\nknowledge and experience from both groups.</p>\n<p><a href=\n\"http://blog.aksw.org/wp-content/uploads/2011/02/Talk.jpg\"><img class=\"size-medium wp-image-200 alignleft\"\ntitle=\"S\u00F6ren Talk\" src=\n\"http://blog.aksw.org/wp-content/uploads/2011/02/Talk-300x136.jpg\"\nalt=\"\" width=\"300\" height=\"136\" /></a></p>\n<p><a href=\n\"http://blog.aksw.org/wp-content/uploads/2011/02/IMG_1056.jpg\"><img class=\"alignright size-medium wp-image-217\"\ntitle=\"John Talk\" src=\n\"http://blog.aksw.org/wp-content/uploads/2011/02/IMG_1056-300x225.jpg\"\nalt=\"\" width=\"168\" height=\"126\" /></a></p>\n</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://blog.aksw.org/2011/dr-philipp_cimiano_visits_aksw/> <http://purl.org/rss/1.0/title> "Dr.Philipp Cimiano visits AKW" .
<http://blog.aksw.org/2011/dr-philipp_cimiano_visits_aksw/> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://blog.georgikobilarov.com/2011/01/making-linked-data-work-isnt-the-problem/> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<p>As an entrepreneur it is my job to create solutions for\nproblems. You could also call that creating products that meet a\nneed. But as a very technical person (despite my business degree),\nI like to think of problems and solutions. In my previous life as\nresearcher it was my job to come up with and prototype ideas that\nmay be turned into solutions if matched with the right problem.\nLinked Data is something where the problem&amp;solution matching\nhas gone wrong, and in this post I share what I believe is the\nreason.<br></br>\n<span id=\"more-564\"></span><br></br>\n<a href=\"http://linkeddata.org\">Linking Open Data</a> is one of\nthose projects I got involved in as a researcher. The idea was to\ninterlink data on the web (as opposed to making the services on top\nof the data talk to each other, as in traditional EAI) and \u201Cturn\nthe Web into a database\u201D. Okay. That was back in 2007.</p>\n<p>So what happened was that organisations, early on from the media\nindustry in Europe and among the very first my friends at the BBC,\nbegan to use Linked Data. So apparently, Linked Data (in particular\nthe early prototypes around DBpedia and a few other data sets)\nprovided a solution to a problem, or at least seemed promising\nenough as such. Great.</p>\n<p>But neither Linked Open Data nor the Semantic Web have really\ntaken off from there yet. I know many people will disagree with me\nand point to the <a href=\"http://www.readwriteweb.com/cloud/2011/01/the-concept-of-linked-data.php\">\nfamous Linked Open Data cloud</a> diagram, which shows a large (and\ngrowing) number of data sets as part of the Linked Data Web. But\nwhere are the showcases of problems being solved?</p>\n<p>If you can\u2019t show me problems being solved then something is\nwrong with the solution. \u201Cwe need more time\u201D is rarely the real\nissue, esp. when there is some inherent network effect in the\nsystem. Then there should be some magic tipping point, and you\u2019re\njust not hitting it and need to adjust your product and try again\nwith a modified approach.</p>\n<p>My point here is not that I want to propose any particular\ndirection or change, but instead I want to stress what I believe is\nan issue in the community: too few people are actually trying to\nunderstand the problem that Linked Data is supposed to be the\nsolution to. If you don\u2019t understand the problem you can not\ndevelop a solution or improve a half-working one. Why? Well, what\ndo you do next? Which part to work on? What to change? There is no\nground for those decisions if you don\u2019t have at least a well\ninformed guess (or better some evidence) about the problem to\nsolve. And you can\u2019t evaluate your results.</p>\n<p>And the second, even more important point: don\u2019t confuse the\nsolution with the problem. Turning the Web into a database is not\nthe problem. It may be a possible solution to the problem of people\nneeding to use data in applications they build or use. Without a\ndeep understanding of the user\u2019s need, you don\u2019t know what to build\nfor.</p>\n<p>Publishing data on the Web as Linked Data is also not the\nproblem. Because nobody wants to publish data. People may want\nother people to consume their data, and in order to reach that goal\nthey need to publish data on the Web.</p>\n<p>So, Linked Data community, let\u2019s have that discussion and do the\nanalysis about the problems that Linked Data could solve, shall we?\nAnd decide about development directions on that basis. People who\nwant to disrupt any industry with an innovation need to do their\nbest to understand their user\u2019s problem, test their assumptions,\nand adjust along the way. Otherwise you end up with something\nhighly sophisticated that nobody really cares about.</p>\n<p>Designers and entrepreneurs understand that process of analysis,\nprototyping, testing and iteration quite well. Let\u2019s make the\nresearch community more aware of it.</p>\n</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://blog.georgikobilarov.com/2011/01/making-linked-data-work-isnt-the-problem/> <http://purl.org/dc/elements/1.1/creator> "Georgi Kobilarov" .
<http://blog.georgikobilarov.com/2011/01/making-linked-data-work-isnt-the-problem/> <http://purl.org/dc/elements/1.1/date> "2011-01-21T17:36:46Z" .
<http://blog.georgikobilarov.com/2011/01/making-linked-data-work-isnt-the-problem/> <http://purl.org/dc/elements/1.1/relation> "http://blog.georgikobilarov.com" .
<http://blog.georgikobilarov.com/2011/01/making-linked-data-work-isnt-the-problem/> <http://purl.org/dc/elements/1.1/source> "Georgi Kobilarov" .
<http://blog.georgikobilarov.com/2011/01/making-linked-data-work-isnt-the-problem/> <http://purl.org/rss/1.0/description> "As an entrepreneur it is my job to create solutions for problems. You could also call that creating products that meet a need. But as a very technical person (despite my business degree), I like to think of problems and solutions. In my previous life as researcher it was my job to come up with and prototype ideas that may be turned into solutions if matched with the right problem. Linked Data is something where the problem&amp;solution matching has gone wrong, and in this post I share what I believe is the reason. Linking Open Data is one of those ..." .
<http://blog.georgikobilarov.com/2011/01/making-linked-data-work-isnt-the-problem/> <http://purl.org/rss/1.0/link> "http://blog.georgikobilarov.com/2011/01/making-linked-data-work-isnt-the-problem/" .
<http://blog.georgikobilarov.com/2011/01/making-linked-data-work-isnt-the-problem/> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<p>As an entrepreneur it is my job to create solutions for\nproblems. You could also call that creating products that meet a\nneed. But as a very technical person (despite my business degree),\nI like to think of problems and solutions. In my previous life as\nresearcher it was my job to come up with and prototype ideas that\nmay be turned into solutions if matched with the right problem.\nLinked Data is something where the problem&amp;solution matching\nhas gone wrong, and in this post I share what I believe is the\nreason.<br />\n<span id=\"more-564\"></span><br />\n<a href=\"http://linkeddata.org\">Linking Open Data</a> is one of\nthose projects I got involved in as a researcher. The idea was to\ninterlink data on the web (as opposed to making the services on top\nof the data talk to each other, as in traditional EAI) and \u201Cturn\nthe Web into a database\u201D. Okay. That was back in 2007.</p>\n<p>So what happened was that organisations, early on from the media\nindustry in Europe and among the very first my friends at the BBC,\nbegan to use Linked Data. So apparently, Linked Data (in particular\nthe early prototypes around DBpedia and a few other data sets)\nprovided a solution to a problem, or at least seemed promising\nenough as such. Great.</p>\n<p>But neither Linked Open Data nor the Semantic Web have really\ntaken off from there yet. I know many people will disagree with me\nand point to the <a href=\n\"http://www.readwriteweb.com/cloud/2011/01/the-concept-of-linked-data.php\">\nfamous Linked Open Data cloud</a> diagram, which shows a large (and\ngrowing) number of data sets as part of the Linked Data Web. But\nwhere are the showcases of problems being solved?</p>\n<p>If you can\u2019t show me problems being solved then something is\nwrong with the solution. \u201Cwe need more time\u201D is rarely the real\nissue, esp. when there is some inherent network effect in the\nsystem. Then there should be some magic tipping point, and you\u2019re\njust not hitting it and need to adjust your product and try again\nwith a modified approach.</p>\n<p>My point here is not that I want to propose any particular\ndirection or change, but instead I want to stress what I believe is\nan issue in the community: too few people are actually trying to\nunderstand the problem that Linked Data is supposed to be the\nsolution to. If you don\u2019t understand the problem you can not\ndevelop a solution or improve a half-working one. Why? Well, what\ndo you do next? Which part to work on? What to change? There is no\nground for those decisions if you don\u2019t have at least a well\ninformed guess (or better some evidence) about the problem to\nsolve. And you can\u2019t evaluate your results.</p>\n<p>And the second, even more important point: don\u2019t confuse the\nsolution with the problem. Turning the Web into a database is not\nthe problem. It may be a possible solution to the problem of people\nneeding to use data in applications they build or use. Without a\ndeep understanding of the user\u2019s need, you don\u2019t know what to build\nfor.</p>\n<p>Publishing data on the Web as Linked Data is also not the\nproblem. Because nobody wants to publish data. People may want\nother people to consume their data, and in order to reach that goal\nthey need to publish data on the Web.</p>\n<p>So, Linked Data community, let\u2019s have that discussion and do the\nanalysis about the problems that Linked Data could solve, shall we?\nAnd decide about development directions on that basis. People who\nwant to disrupt any industry with an innovation need to do their\nbest to understand their user\u2019s problem, test their assumptions,\nand adjust along the way. Otherwise you end up with something\nhighly sophisticated that nobody really cares about.</p>\n<p>Designers and entrepreneurs understand that process of analysis,\nprototyping, testing and iteration quite well. Let\u2019s make the\nresearch community more aware of it.</p>\n</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://blog.georgikobilarov.com/2011/01/making-linked-data-work-isnt-the-problem/> <http://purl.org/rss/1.0/title> "Making Linked Data work isn\u2019t the problem" .
<http://blog.georgikobilarov.com/2011/01/making-linked-data-work-isnt-the-problem/> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://blog.planetrdf.com/added-dydra-to-planet-rdf> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<p>Added the <a href=\"http://blog.dydra.com/\">Dydra corporate\nblog</a> to Planet RDF for their new Cloud RDF+SPARQL Service they\njust announced in Beta. See <a href=\"http://dydra.com/\">Dydra</a>\nor follow them on twitter at <a href=\"http://twitter.com/dydradata\">@dydradata</a>.</p>\n<p><a href=\"http://blog.planetrdf.com/added-dydra-to-planet-rdf\">Permalink</a>\n| <a href=\"http://blog.planetrdf.com/added-dydra-to-planet-rdf#comment\">Leave\na comment\u00A0\u00A0\u00BB</a></p>\n</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://blog.planetrdf.com/added-dydra-to-planet-rdf> <http://purl.org/dc/elements/1.1/creator> "Planet RDF" .
<http://blog.planetrdf.com/added-dydra-to-planet-rdf> <http://purl.org/dc/elements/1.1/date> "2011-02-08T05:54Z" .
<http://blog.planetrdf.com/added-dydra-to-planet-rdf> <http://purl.org/dc/elements/1.1/relation> "http://blog.planetrdf.com/" .
<http://blog.planetrdf.com/added-dydra-to-planet-rdf> <http://purl.org/dc/elements/1.1/source> "Planet RDF site blog" .
<http://blog.planetrdf.com/added-dydra-to-planet-rdf> <http://purl.org/rss/1.0/description> "\n \n Added the  Dydra corporate\nblog  to Planet RDF for their new Cloud RDF+SPARQL Service they\njust announced in Beta. See  Dydra \nor follow them on twitter at  @dydradata . \n  Permalink \n|  Leave\na comment&#160;&#160;\u00BB  \n \n" .
<http://blog.planetrdf.com/added-dydra-to-planet-rdf> <http://purl.org/rss/1.0/link> "http://blog.planetrdf.com/added-dydra-to-planet-rdf" .
<http://blog.planetrdf.com/added-dydra-to-planet-rdf> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<p>Added the <a href=\"http://blog.dydra.com/\">Dydra corporate\nblog</a> to Planet RDF for their new Cloud RDF+SPARQL Service they\njust announced in Beta. See <a href=\"http://dydra.com/\">Dydra</a>\nor follow them on twitter at <a href=\n\"http://twitter.com/dydradata\">@dydradata</a>.</p>\n<p><a href=\n\"http://blog.planetrdf.com/added-dydra-to-planet-rdf\">Permalink</a>\n| <a href=\n\"http://blog.planetrdf.com/added-dydra-to-planet-rdf#comment\">Leave\na comment&#160;&#160;\u00BB</a></p>\n</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://blog.planetrdf.com/added-dydra-to-planet-rdf> <http://purl.org/rss/1.0/title> "Added Dydra to Planet RDF" .
<http://blog.planetrdf.com/added-dydra-to-planet-rdf> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://blog.semantic-web.at/2011/02/07/drupal-and-the-semantic-web-interview-with-stephane-corlosquet/> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<p><a href=\"http://openspring.net/\">St\u00E9phane Corlosquet</a> has\nbeen the main driving force in incorporating Semantic Web\ncapabilities into <a href=\"http://drupal.org/\">Drupal</a>. In the\n<a href=\"http://drupal.org/drupal-7-released\">recent release</a> of\nDrupal 7, Semantic Web technologies became part of the core of this\npopular CMS, which is used to power at least 1% of all the world\u2019s\nweb sites.</p>\n<p><a href=\"http://blog.semantic-web.at/wp-content/uploads/2011/02/stephane.jpg\">\n<img src=\"http://blog.semantic-web.at/wp-content/uploads/2011/02/stephane-150x150.jpg\" alt=\"\" title=\"stephane corlosquet\" width=\"150\" height=\"150\" class=\"aligncenter size-thumbnail wp-image-1917\"></img></a></p>\n<p><strong>Drupal is the leading CMS when it comes to implementing\nSemantic Web standards. What are the reasons for this, what makes\nDrupal such a good fit for Semantic Web technologies?</strong></p>\n<p>Historically, Drupal is known to be web standard compliant. It\nsupported the RDF-based aggregation format known as RSS 1.0 as\nearly as in 2001, which was later upgraded to RSS 2.0. The Drupal\ncommunity prides itself in valid HTML code, not only for the code\ngenerated by Drupal, but also by taking the extra step of\nautomatically fixing faulty HTML entered by its users. Drupal has\nbeen using XHTML since its version 4.0 in 2002. The next logical\nstep beyond XHTML was to add a layer of semantics with the RDFa\nstandard, a W3C recommendation published in 2008.</p>\n<p>There are definitely many reasons that contributed to the\naddition of RDFa into Drupal 7. The first comes from the Drupal\nproject lead, Dries Buytaert, who is passionate about the web and\nopen source. Secondly, the growing Drupal community is very web\nsavvy and includes many experts from different backgrounds in\naccessilibity, CSS, HTML, security etc. As a result, every release\nof Drupal includes many latest standards. The community meets twice\na year at conferences (<a href=\"http://chicago2011.drupal.org/\">DrupalCon</a>s), thes events play\na great role in hashing out what technologies or designs will be\nincorporated into the next version of Drupal. Because of the\nflexibility of its internal architecture, Drupal is able to keep up\nwith the latest web standards. Content in Drupal is very structured\nand provides site administrators with a user interface to build the\nsite structure they want, using entity types, content types, fields\nand taxonomies for categorization. When it comes to other CMSs,\nJoomla!\u2019s community appears to be more fragmented with a core\nsoftware that is not as extensible as Drupal and Wordpress is more\nof a blogging platform, so turning it into a full blown CMS can be\nchallenging. Both Wordpress and Joomla! are in fact adapting the\nconcept of Drupal\u2019s Content Construction Kit (CCK) to their\nsoftware but they have not yet reached the same level of maturity\nas Drupal.</p>\n<p><strong>A common objection to the adoption of Semantic Web\ntechnologies is that the learning curve is steep and that it is too\ncomplicated for many web developers to get into it. How can Drupal\n7 change that? Which features accessible for the average web site\noperator will it offer?</strong></p>\n<p>Semantic Web technologies don\u2019t have to be complicated when\napplied to simple use cases! We purposely chose only of a subset of\nsemantic web technologies to integrate into the core of Drupal,\nkeeping the learning curve for the Drupal developers and users as\nlow as possible. The main technology is RDFa which includes the\nnotions of vocabularies (a schema, or collection of attributes) as\nwell as Compact URIs (CURIEs) which make the authoring of RDFa\neasier. In fact, some web developers might have come across these\nnotions before when working with Dublin Core in the meta tags as\nsuch dc:title or dc:date.</p>\n<p><strong>Which benefits will web site owners get when they switch\nto a semantics enabled Drupal 7?</strong></p>\n<p>Google and Bing increasingly rely on machine-readable structured\ndata from the websites that they crawl. The design of Drupal 7\nembeds semantic meta data that makes machine-to-machine (M2M)\nsearch native for a Drupal 7 website. RDFa can add value by giving\nsearch engines more details such as the latitude and longitude of a\nvenue for display on a map; or providing the ISO date format for\nlocalization and proper display in the search results for different\ncountries.</p>\n<p><strong>What are your hopes regarding the development of other\napplications that either provide or consume data from D7 sites?\nWhich improvements of standards, best practices or (lightweight)\nontologies in the Semantic Web community would you like to\nsee?</strong></p>\n<p>Services like <a href=\"http://sig.ma/\">Sig.ma</a> are already\nable to collect semantic data from different sources and display it\nin new ways in the form of mash-ups. Eventually, these services\nthat consume semantic data will not be just Drupal specific, as\nmore platforms jump on the semantic web band wagon. What I hope to\nsee as improvements or best practices in the future are more\nwell-maintained vocabularies. Many of the existing vocabularies are\nover engineered, some fail to de-reference properly. Their is also\nsome work to be done in order to improve the tooling made available\nto web developers as well as introducing the simple concepts of\nLinked Data to web developers via easy to read documentation.</p>\n<p><strong>Thank you for this interview, St\u00E9phane!</strong></p>\n</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://blog.semantic-web.at/2011/02/07/drupal-and-the-semantic-web-interview-with-stephane-corlosquet/> <http://purl.org/dc/elements/1.1/creator> "Semantic Web Company (Austria)" .
<http://blog.semantic-web.at/2011/02/07/drupal-and-the-semantic-web-interview-with-stephane-corlosquet/> <http://purl.org/dc/elements/1.1/date> "2011-02-07T14:59:12Z" .
<http://blog.semantic-web.at/2011/02/07/drupal-and-the-semantic-web-interview-with-stephane-corlosquet/> <http://purl.org/dc/elements/1.1/relation> "http://blog.semantic-web.at/" .
<http://blog.semantic-web.at/2011/02/07/drupal-and-the-semantic-web-interview-with-stephane-corlosquet/> <http://purl.org/dc/elements/1.1/source> "Semantic Puzzle by Semantic Web Company (Austria)" .
<http://blog.semantic-web.at/2011/02/07/drupal-and-the-semantic-web-interview-with-stephane-corlosquet/> <http://purl.org/rss/1.0/description> "St\u00E9phane Corlosquet has been the main driving force in incorporating Semantic Web capabilities into Drupal . In the recent release of Drupal 7, Semantic Web technologies became part of the core of this popular CMS, which is used to power at least 1% of all the world\u2019s web sites. Drupal is the leading CMS when it comes to implementing Semantic Web standards. What are the reasons for this, what makes Drupal such a good fit for Semantic Web technologies? Historically, Drupal is known to be web standard compliant. It supported the RDF-based aggregation format known as RSS 1.0 as early ..." .
<http://blog.semantic-web.at/2011/02/07/drupal-and-the-semantic-web-interview-with-stephane-corlosquet/> <http://purl.org/rss/1.0/link> "http://blog.semantic-web.at/2011/02/07/drupal-and-the-semantic-web-interview-with-stephane-corlosquet/" .
<http://blog.semantic-web.at/2011/02/07/drupal-and-the-semantic-web-interview-with-stephane-corlosquet/> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<p><a href=\"http://openspring.net/\">St\u00E9phane Corlosquet</a> has\nbeen the main driving force in incorporating Semantic Web\ncapabilities into <a href=\"http://drupal.org/\">Drupal</a>. In the\n<a href=\"http://drupal.org/drupal-7-released\">recent release</a> of\nDrupal 7, Semantic Web technologies became part of the core of this\npopular CMS, which is used to power at least 1% of all the world\u2019s\nweb sites.</p>\n<p><a href=\n\"http://blog.semantic-web.at/wp-content/uploads/2011/02/stephane.jpg\">\n<img src=\n\"http://blog.semantic-web.at/wp-content/uploads/2011/02/stephane-150x150.jpg\"\nalt=\"\" title=\"stephane corlosquet\" width=\"150\" height=\"150\" class=\n\"aligncenter size-thumbnail wp-image-1917\" /></a></p>\n<p><strong>Drupal is the leading CMS when it comes to implementing\nSemantic Web standards. What are the reasons for this, what makes\nDrupal such a good fit for Semantic Web technologies?</strong></p>\n<p>Historically, Drupal is known to be web standard compliant. It\nsupported the RDF-based aggregation format known as RSS 1.0 as\nearly as in 2001, which was later upgraded to RSS 2.0. The Drupal\ncommunity prides itself in valid HTML code, not only for the code\ngenerated by Drupal, but also by taking the extra step of\nautomatically fixing faulty HTML entered by its users. Drupal has\nbeen using XHTML since its version 4.0 in 2002. The next logical\nstep beyond XHTML was to add a layer of semantics with the RDFa\nstandard, a W3C recommendation published in 2008.</p>\n<p>There are definitely many reasons that contributed to the\naddition of RDFa into Drupal 7. The first comes from the Drupal\nproject lead, Dries Buytaert, who is passionate about the web and\nopen source. Secondly, the growing Drupal community is very web\nsavvy and includes many experts from different backgrounds in\naccessilibity, CSS, HTML, security etc. As a result, every release\nof Drupal includes many latest standards. The community meets twice\na year at conferences (<a href=\n\"http://chicago2011.drupal.org/\">DrupalCon</a>s), thes events play\na great role in hashing out what technologies or designs will be\nincorporated into the next version of Drupal. Because of the\nflexibility of its internal architecture, Drupal is able to keep up\nwith the latest web standards. Content in Drupal is very structured\nand provides site administrators with a user interface to build the\nsite structure they want, using entity types, content types, fields\nand taxonomies for categorization. When it comes to other CMSs,\nJoomla!\u2019s community appears to be more fragmented with a core\nsoftware that is not as extensible as Drupal and Wordpress is more\nof a blogging platform, so turning it into a full blown CMS can be\nchallenging. Both Wordpress and Joomla! are in fact adapting the\nconcept of Drupal\u2019s Content Construction Kit (CCK) to their\nsoftware but they have not yet reached the same level of maturity\nas Drupal.</p>\n<p><strong>A common objection to the adoption of Semantic Web\ntechnologies is that the learning curve is steep and that it is too\ncomplicated for many web developers to get into it. How can Drupal\n7 change that? Which features accessible for the average web site\noperator will it offer?</strong></p>\n<p>Semantic Web technologies don\u2019t have to be complicated when\napplied to simple use cases! We purposely chose only of a subset of\nsemantic web technologies to integrate into the core of Drupal,\nkeeping the learning curve for the Drupal developers and users as\nlow as possible. The main technology is RDFa which includes the\nnotions of vocabularies (a schema, or collection of attributes) as\nwell as Compact URIs (CURIEs) which make the authoring of RDFa\neasier. In fact, some web developers might have come across these\nnotions before when working with Dublin Core in the meta tags as\nsuch dc:title or dc:date.</p>\n<p><strong>Which benefits will web site owners get when they switch\nto a semantics enabled Drupal 7?</strong></p>\n<p>Google and Bing increasingly rely on machine-readable structured\ndata from the websites that they crawl. The design of Drupal 7\nembeds semantic meta data that makes machine-to-machine (M2M)\nsearch native for a Drupal 7 website. RDFa can add value by giving\nsearch engines more details such as the latitude and longitude of a\nvenue for display on a map; or providing the ISO date format for\nlocalization and proper display in the search results for different\ncountries.</p>\n<p><strong>What are your hopes regarding the development of other\napplications that either provide or consume data from D7 sites?\nWhich improvements of standards, best practices or (lightweight)\nontologies in the Semantic Web community would you like to\nsee?</strong></p>\n<p>Services like <a href=\"http://sig.ma/\">Sig.ma</a> are already\nable to collect semantic data from different sources and display it\nin new ways in the form of mash-ups. Eventually, these services\nthat consume semantic data will not be just Drupal specific, as\nmore platforms jump on the semantic web band wagon. What I hope to\nsee as improvements or best practices in the future are more\nwell-maintained vocabularies. Many of the existing vocabularies are\nover engineered, some fail to de-reference properly. Their is also\nsome work to be done in order to improve the tooling made available\nto web developers as well as introducing the simple concepts of\nLinked Data to web developers via easy to read documentation.</p>\n<p><strong>Thank you for this interview, St\u00E9phane!</strong></p>\n</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://blog.semantic-web.at/2011/02/07/drupal-and-the-semantic-web-interview-with-stephane-corlosquet/> <http://purl.org/rss/1.0/title> "Drupal and the Semantic Web \u2013 Interview with St\u00E9phane\nCorlosquet" .
<http://blog.semantic-web.at/2011/02/07/drupal-and-the-semantic-web-interview-with-stephane-corlosquet/> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://blogs.ecs.soton.ac.uk/enakting/2011/01/28/fast-sparql-xml-results-parser-in-python/> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<p>For one of our projects we need results from SPARQL endpoints as\nquickly as possible, with little to no need for validation.</p>\n<p>As such, I re-wrote our original SPARQL XML results parser to\nuse Expat, the non-validating (and fast) XML parser.</p>\n<p>The results format is a dict in roughly the same as the bindings\npart of the SPARQL JSON results format.</p>\n<p>Example of use:</p>\n<pre>\nsp = SparqlParser()\nresults = sp.Parse(xmlstring)\n</pre>\n<p>Code:</p>\n<pre>\nimport xml.parsers.expat\n\n# Fast Expat based SPARQL stream parser Copyright (c) 2011 Daniel Alexander Smith, University of Southampton\nclass SparqlParser:\n\n    def __init__(self):\n        self.results = []\n        self.current = {}\n        self.current_name = \"\"\n        self.current_chars = \"\"\n        self.current_type = \"\"\n        self.getting_chars = False\n        self.parser = xml.parsers.expat.ParserCreate()\n        self.parser.StartElementHandler = self.start_element\n        self.parser.EndElementHandler = self.end_element\n        self.parser.CharacterDataHandler = self.char_data\n\n    def start_element(self, name, attrs):\n        if name == 'binding':\n            self.current_name = attrs['name']\n        if name == 'literal':\n            self.current_type = 'literal'\n            self.getting_chars = True\n        if name == 'bnode':\n            self.current_type = 'bnode'\n            self.getting_chars = True\n        if name == 'uri':\n            self.current_type = 'uri'\n            self.getting_chars = True\n\n    def end_element(self, name):\n        if name == 'binding':\n            self.current[self.current_name] = {'value': self.current_chars, 'type': self.current_type}\n            self.current_chars = \"\"\n        if name == 'literal':\n            self.getting_chars = False\n        if name == 'bnode':\n            self.getting_chars = False\n        if name == 'uri':\n            self.getting_chars = False\n        if name == 'result':\n            self.results.append(self.current)\n            self.current = {}\n\n    def char_data(self, data):\n        if self.getting_chars:\n            self.current_chars = self.current_chars + data\n\n    def Parse(self, data):\n        self.parser.Parse(data, 0)\n        return self.results\n</pre></div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://blogs.ecs.soton.ac.uk/enakting/2011/01/28/fast-sparql-xml-results-parser-in-python/> <http://purl.org/dc/elements/1.1/creator> "EnAKTing project" .
<http://blogs.ecs.soton.ac.uk/enakting/2011/01/28/fast-sparql-xml-results-parser-in-python/> <http://purl.org/dc/elements/1.1/date> "2011-01-28T10:49:29Z" .
<http://blogs.ecs.soton.ac.uk/enakting/2011/01/28/fast-sparql-xml-results-parser-in-python/> <http://purl.org/dc/elements/1.1/relation> "http://blogs.ecs.soton.ac.uk/enakting/" .
<http://blogs.ecs.soton.ac.uk/enakting/2011/01/28/fast-sparql-xml-results-parser-in-python/> <http://purl.org/dc/elements/1.1/source> "EnAKTing project" .
<http://blogs.ecs.soton.ac.uk/enakting/2011/01/28/fast-sparql-xml-results-parser-in-python/> <http://purl.org/rss/1.0/description> "For one of our projects we need results from SPARQL endpoints as quickly as possible, with little to no need for validation. As such, I re-wrote our original SPARQL XML results parser to use Expat, the non-validating (and fast) XML parser. The results format is a dict in roughly the same as the bindings part of the SPARQL JSON results format. Example of use: sp = SparqlParser() results = sp.Parse(xmlstring) Code: import xml.parsers.expat # Fast Expat based SPARQL stream parser Copyright (c) 2011 Daniel Alexander Smith, University of Southampton class SparqlParser: def __init__(self): self.results = [] self.current = {} self.current_name ..." .
<http://blogs.ecs.soton.ac.uk/enakting/2011/01/28/fast-sparql-xml-results-parser-in-python/> <http://purl.org/rss/1.0/link> "http://blogs.ecs.soton.ac.uk/enakting/2011/01/28/fast-sparql-xml-results-parser-in-python/" .
<http://blogs.ecs.soton.ac.uk/enakting/2011/01/28/fast-sparql-xml-results-parser-in-python/> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<p>For one of our projects we need results from SPARQL endpoints as\nquickly as possible, with little to no need for validation.</p>\n<p>As such, I re-wrote our original SPARQL XML results parser to\nuse Expat, the non-validating (and fast) XML parser.</p>\n<p>The results format is a dict in roughly the same as the bindings\npart of the SPARQL JSON results format.</p>\n<p>Example of use:</p>\n<pre>\nsp = SparqlParser()\nresults = sp.Parse(xmlstring)\n</pre>\n<p>Code:</p>\n<pre>\nimport xml.parsers.expat\n\n# Fast Expat based SPARQL stream parser Copyright (c) 2011 Daniel Alexander Smith, University of Southampton\nclass SparqlParser:\n\n    def __init__(self):\n        self.results = []\n        self.current = {}\n        self.current_name = \"\"\n        self.current_chars = \"\"\n        self.current_type = \"\"\n        self.getting_chars = False\n        self.parser = xml.parsers.expat.ParserCreate()\n        self.parser.StartElementHandler = self.start_element\n        self.parser.EndElementHandler = self.end_element\n        self.parser.CharacterDataHandler = self.char_data\n\n    def start_element(self, name, attrs):\n        if name == 'binding':\n            self.current_name = attrs['name']\n        if name == 'literal':\n            self.current_type = 'literal'\n            self.getting_chars = True\n        if name == 'bnode':\n            self.current_type = 'bnode'\n            self.getting_chars = True\n        if name == 'uri':\n            self.current_type = 'uri'\n            self.getting_chars = True\n\n    def end_element(self, name):\n        if name == 'binding':\n            self.current[self.current_name] = {'value': self.current_chars, 'type': self.current_type}\n            self.current_chars = \"\"\n        if name == 'literal':\n            self.getting_chars = False\n        if name == 'bnode':\n            self.getting_chars = False\n        if name == 'uri':\n            self.getting_chars = False\n        if name == 'result':\n            self.results.append(self.current)\n            self.current = {}\n\n    def char_data(self, data):\n        if self.getting_chars:\n            self.current_chars = self.current_chars + data\n\n    def Parse(self, data):\n        self.parser.Parse(data, 0)\n        return self.results\n</pre></div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://blogs.ecs.soton.ac.uk/enakting/2011/01/28/fast-sparql-xml-results-parser-in-python/> <http://purl.org/rss/1.0/title> "Fast SPARQL XML Results Parser in Python" .
<http://blogs.ecs.soton.ac.uk/enakting/2011/01/28/fast-sparql-xml-results-parser-in-python/> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt2.php> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<p><img style=\"border-right-width: 0px;border-top-width: 0px;border-bottom-width: 0px;margin-left: 0px;border-left-width: 0px;margin-right: 0px\" title=\"linkedlocalgov\" border=\"0\" alt=\"linkedlocalgov\" align=\"right\" src=\"http://blogs.talis.com/nodalities/files/2011/01/linkedlocalgov.jpg\" width=\"345\" height=\"119\"></img>I started the <a href=\"http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt1.php\">\nprevious post</a> in this mini-series with an assumption \u2013\n..<em>working on the assumption that publishing this</em> [local\ngovernment spending] <em>data is a good thing.</em> That post\nattracted <a href=\"http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt1.php#comments\">\nseveral comments,</a> fortunately none challenging the\nassumption.\u00A0\u00A0 So learning from that experience I am going\nto start with another assumption in this post.\u00A0\n<strong>Publishing Local Authority data, such as local spending\ndata, as \u2018Linked Data\u2019 is also a good thing.</strong>\u00A0 Those\nnew to this mini-series, check back to the <a href=\"http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt1.php\">\nprevious post</a> for my reasoning behind the assertion.</p>\n<p>In this post I am going to be concentrating more on the\n<em>How</em> than the <em>Why Bother</em>.\u00A0</p>\n<p><a href=\"http://spending.lichfielddc.gov.uk/\"><img style=\"border-right-width: 0px;border-top-width: 0px;border-bottom-width: 0px;margin-left: 0px;border-left-width: 0px;margin-right: 0px\" title=\"home\" border=\"0\" alt=\"home\" align=\"left\" src=\"http://blogs.talis.com/nodalities/files/2011/01/home.jpg\" width=\"197\" height=\"133\"></img></a>To help with this I am going to use, some\nof the excellent work that <a href=\"http://www.pezholio.co.uk/\">Stuart Harrison</a> at <a href=\"http://www.lichfielddc.gov.uk\">Lichfield District Council</a> has\ndone in this area, as examples.\u00A0 Take a look at the spending\ndata part of their site: <a title=\"http://spending.lichfielddc.gov.uk/\" href=\"http://spending.lichfielddc.gov.uk/\">spending.lichfielddc.gov.uk/</a>.\u00A0\u00A0\nOn the surface navigating your way around the site looking at\ncouncil spend by type, subject, month, and supplier is the kind of\nexperience a user would expect. Great for a website displaying\ninformation about a single council.\u00A0</p>\n<p>However, it is more than a web site.\u00A0 Inspection of the\nDownload data tab shows that you can get your hands on the source\ndata in csv format.\u00A0 Here is one line, representing a line of\nexpenditure, from that data:</p>\n<p><font size=\"1\" face=\"Courier New\">\"http://statistics.data.gov.uk/doc/local-authority/41UD\",\"Lichfield\nDistrict\nCouncil\",\"2010-04-06\",\"7747\",\"http://spending.lichfielddc.gov.uk/spend/8605670\",\"120.00\",\"BRISTOW\n&amp; SUTOR\",\"401\",\"Revenue Collection\",\"Supplies &amp;\nServices\",\"Bailiff Fees\",\"\"</font></p>\n<p>\u2026 which represents the data displayed on this <a href=\"http://spending.lichfielddc.gov.uk/spend/8605670\">human readable\npage</a>:</p>\n<p><a href=\"http://spending.lichfielddc.gov.uk/spend/8605670\"><img style=\"border-right-width: 0px;float: none;border-top-width: 0px;border-bottom-width: 0px;margin-left: auto;border-left-width: 0px;margin-right: auto\" title=\"Lichfield District Council Spending Data - Details of payment number 8605670\" border=\"0\" alt=\"Lichfield District Council Spending Data - Details of payment number 8605670\" src=\"http://blogs.talis.com/nodalities/files/2011/01/LichfieldDistrictCouncilSpendingDataDetailsofpaymentnumber8605670.jpg\" width=\"180\" height=\"170\"></img></a><br></br>\nLooking through the csv, you can pick out the strings of characters\nfor information such as the date, supplier name, department name\netc.\u00A0 In addition you can pick out a couple of <a href=\"http://en.wikipedia.org/wiki/Uniform_Resource_Identifier\">URI</a>s:</p>\n<ul>\n<li><a href=\"http://statistics.data.gov.uk/doc/local-authority/41UD\">http://statistics.data.gov.uk/doc/local-authority/41UD</a>\n\u2013 The UK Government identifier for Lichfield DC</li>\n<li><a href=\"http://spending.lichfielddc.gov.uk/spend/8605670\">http://spending.lichfielddc.gov.uk/spend/8605670</a>\n\u2013\u00A0 Lichfield\u2019s identifier for this payment</li>\n</ul>\n<p><a href=\"http://blogs.talis.com/nodalities/files/2011/01/LinkedDataforLichfieldDistrictCouncil007Cstatistics.data_.gov_.uk_.jpg\">\n<img style=\"border-right-width: 0px;border-top-width: 0px;border-bottom-width: 0px;margin-left: 0px;border-left-width: 0px;margin-right: 0px\" title=\"Linked Data for Lichfield District Council %007C statistics.data.gov.uk\" border=\"0\" alt=\"Linked Data for Lichfield District Council %007C statistics.data.gov.uk\" align=\"right\" src=\"http://blogs.talis.com/nodalities/files/2011/01/LinkedDataforLichfieldDistrictCouncil007Cstatistics.data_.gov_.uk_thumb.jpg\" width=\"244\" height=\"130\"></img></a> In the context of csv, that\u2019s all\nthese URIs are, identifiers.\u00A0 However because they are http\nURIs you can click through to the address to get more\ninformation.\u00A0 If you do that with your web browser you get a\nhuman readable representation of the data.\u00A0 These sites also\nprovide access to the same data, formatted in RDF, for use by\ndevelopers.</p>\n<p><a href=\"http://blogs.talis.com/nodalities/files/2011/01/Sourceofhttp___spending.lichfielddc.gov_.uk_spend_8605670.rdf_.jpg\">\n<img style=\"border-bottom: 0px;border-left: 0px;margin-left: 0px;border-top: 0px;margin-right: 0px;border-right: 0px\" title=\"Source of http___spending.lichfielddc.gov.uk_spend_8605670.rdf\" border=\"0\" alt=\"Source of http___spending.lichfielddc.gov.uk_spend_8605670.rdf\" align=\"left\" src=\"http://blogs.talis.com/nodalities/files/2011/01/Sourceofhttp___spending.lichfielddc.gov_.uk_spend_8605670.rdf_thumb.jpg\" width=\"324\" height=\"106\"></img></a> You can see that data by adding\n\u2018.rdf\u2019 to the end of the address, thus: <a title=\"http://spending.lichfielddc.gov.uk/spend/8605670.rdf\" href=\"http://spending.lichfielddc.gov.uk/spend/8605670.rdf\">http://spending.lichfielddc.gov.uk/spend/8605670.rdf</a>\nand then selecting the \u2018view source\u2019 option of your browser for the\npage of gobbledegook that you get back.\u00A0\u00A0</p>\n<p>Inspecting the RDF, you will see that most things, except\ndescriptive labels and financial values, are are now identified as\nURIs such as <a title=\"http://spending.lichfielddc.gov.uk/subjective/bailiff-fees\" href=\"http://spending.lichfielddc.gov.uk/subjective/bailiff-fees\">http://spending.lichfielddc.gov.uk/subjective/bailiff-fees</a>\nand <a title=\"http://spending.lichfielddc.gov.uk/invoice/7747\" href=\"http://spending.lichfielddc.gov.uk/invoice/7747\">http://spending.lichfielddc.gov.uk/invoice/7747</a>.\u00A0\nAgain if you follow those links, you will get a human readable\nrepresentation of that resource, and the RDF behind it by adding a\n\u2018.rdf\u2019 suffix.</p>\n<p>The eagle-eyed, inspecting the RDF-XML for Lichfield payment\nnumber 8605670, will have noticed a couple of things.\u00A0\nFirstly, a liberal sprinkling of elements with names like\n<font face=\"Courier New\">payment:expenditureCategory</font> or\n<font face=\"Courier New\">payment:payment.</font> These come from\nthe <a href=\"http://data.gov.uk/resources/payments/reference\">Payments\nOntology</a> as published on data.gov.uk as the recommended way of\nencoding spending, and other payment associated data, in RDF.</p>\n<p>Secondly, you may have spotted that there is no date, or\nsupplier name or identifier.\u00A0 That is because those pieces of\ninformation are attributes associated with a payment \u2013 <a href=\"http://spending.lichfielddc.gov.uk/invoice/7747\">invoice number\n7747</a> in this case.</p>\n<p><a href=\"http://www.bbc.co.uk/nature/life/Whooper_Swan\"><img style=\"border-bottom: 0px;border-left: 0px;margin-left: 0px;border-top: 0px;margin-right: 0px;border-right: 0px\" title=\"BBC - Wildlife Finder - Whooper swan facts, pictures &amp; stunning videos\" border=\"0\" alt=\"BBC - Wildlife Finder - Whooper swan facts, pictures &amp; stunning videos\" align=\"left\" src=\"http://blogs.talis.com/nodalities/files/2011/01/BBCWildlifeFinderWhooperswanfactspicturesstunningvideos.jpg\" width=\"244\" height=\"205\"></img></a> Zooming out from the data for a\nmoment, and looking at the human readable form, you will see that\nmost things, like spend type, invoice number, supplier name, are\nclickable links, which take you through to relevant information\nabout those things \u2013 <a href=\"http://spending.lichfielddc.gov.uk/supplier/rma-design-ltd.html\">address\ndetails &amp; payments</a> for a supplier, <a href=\"http://spending.lichfielddc.gov.uk/type/supplies-services.html\">all\npayments for a category</a> etc.\u00A0 This intuitive natural\nnavigation style often comes as a positive consequence of thinking\nabout data as a set of linked resources instead of the traditional\nrows &amp; columns that we are used to.\u00A0 Another great example\nof this effect can be found on a site such as the <a href=\"http://www.bbc.co.uk/nature/life/Whooper_Swan\">BBC Wildlife\nFinder</a>.\u00A0 That is not to say that you could not have\ncreated such a site without even considering Linked Data, of course\nyou could.\u00A0 However, data modelled as a set of linked\nresources almost self-describes the ideal navigation paths for a\nuser interface to display it to a human.</p>\n<p>The Linked Data practice of modelling data, such as spending\ndata, as a set of linked resources and identifying those resources\nwith URIs [which if looked up will provide information about that\nresource] is equally applicable to those outside of an individual\nauthority.\u00A0 By being able to consume that data, whilst\nunderstanding the relationships within it and having confidence in\nthe authority and persistence of the identifiers within it, a\ndeveloper can approach the task of aggregating, comparing, and\nusing that data in their applications more easily.</p>\n<p>So, how do I (as a local authority) get my data from its raw\nflat csv format, in to RDF with suitable URIs and produce a site\nlike Lichfield\u2019s?\u00A0 The simple answer is that you may not have\nto \u2013 others may help you do some, if not all, of it.\u00A0\u00A0\nWith help from organisations such as <a href=\"http://www.esd.org.uk/esdtoolkit/default.aspx\">esd-toolkit</a>,\n<a href=\"http://openlylocal.com/\">OpenlyLocal</a>, <a href=\"http://whatis.spotlightonspend.org.uk/\">SpotlightOnSpend</a>, and\nwith projects such as the <a href=\"http://blogs.talis.com/platform-consulting/2010/11/12/adding-linked-data-value-to-local-government/\">\nxSpend project</a> we are working on with LGID, many of the\nconversion [from csv], data formatting processes, and aggregation\nare being addressed \u2013 maybe not as quickly or completely as we\nwould like, but they are.\u00A0 As to a human readable web view of\nyour data, you may be able to copy Stuart by taking up the offer of\na free Talis Platform Store and then running your own web server\nwith his code that he hopes to share as open source.\u00A0\nAlternatively it might be worth waiting for others to aggregate\nyour data and provide a way for your citizens to view your\ndata.</p>\n<p>As easy as that then! \u2013 Well not quite, there are some issues\nabout URI naming and creation, and how you bring the data together\nthat still do need addressing by those engaged in this.\u00A0 But\nthat is for Part 3\u2026.</p>\n</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt2.php> <http://purl.org/dc/elements/1.1/creator> "Talis" .
<http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt2.php> <http://purl.org/dc/elements/1.1/date> "2011-01-28T16:39:20Z" .
<http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt2.php> <http://purl.org/dc/elements/1.1/relation> "http://blogs.talis.com/nodalities/" .
<http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt2.php> <http://purl.org/dc/elements/1.1/source> "Nodalities by Talis" .
<http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt2.php> <http://purl.org/rss/1.0/description> "I started the previous post in this mini-series with an assumption \u2013 .. working on the assumption that publishing this [local government spending] data is a good thing. That post attracted several comments, fortunately none challenging the assumption.&#160;&#160; So learning from that experience I am going to start with another assumption in this post.&#160; Publishing Local Authority data, such as local spending data, as \u2018Linked Data\u2019 is also a good thing. &#160; Those new to this mini-series, check back to the previous post for my reasoning behind the assertion. In this post I am going to be concentrating more on ..." .
<http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt2.php> <http://purl.org/rss/1.0/link> "http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt2.php" .
<http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt2.php> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<p><img style=\n\"border-right-width: 0px;border-top-width: 0px;border-bottom-width: 0px;margin-left: 0px;border-left-width: 0px;margin-right: 0px\"\ntitle=\"linkedlocalgov\" border=\"0\" alt=\"linkedlocalgov\" align=\n\"right\" src=\n\"http://blogs.talis.com/nodalities/files/2011/01/linkedlocalgov.jpg\"\nwidth=\"345\" height=\"119\" />I started the <a href=\n\"http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt1.php\">\nprevious post</a> in this mini-series with an assumption \u2013\n..<em>working on the assumption that publishing this</em> [local\ngovernment spending] <em>data is a good thing.</em> That post\nattracted <a href=\n\"http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt1.php#comments\">\nseveral comments,</a> fortunately none challenging the\nassumption.&#160;&#160; So learning from that experience I am going\nto start with another assumption in this post.&#160;\n<strong>Publishing Local Authority data, such as local spending\ndata, as \u2018Linked Data\u2019 is also a good thing.</strong>&#160; Those\nnew to this mini-series, check back to the <a href=\n\"http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt1.php\">\nprevious post</a> for my reasoning behind the assertion.</p>\n<p>In this post I am going to be concentrating more on the\n<em>How</em> than the <em>Why Bother</em>.&#160;</p>\n<p><a href=\"http://spending.lichfielddc.gov.uk/\"><img style=\n\"border-right-width: 0px;border-top-width: 0px;border-bottom-width: 0px;margin-left: 0px;border-left-width: 0px;margin-right: 0px\"\ntitle=\"home\" border=\"0\" alt=\"home\" align=\"left\" src=\n\"http://blogs.talis.com/nodalities/files/2011/01/home.jpg\" width=\n\"197\" height=\"133\" /></a>To help with this I am going to use, some\nof the excellent work that <a href=\n\"http://www.pezholio.co.uk/\">Stuart Harrison</a> at <a href=\n\"http://www.lichfielddc.gov.uk\">Lichfield District Council</a> has\ndone in this area, as examples.&#160; Take a look at the spending\ndata part of their site: <a title=\n\"http://spending.lichfielddc.gov.uk/\" href=\n\"http://spending.lichfielddc.gov.uk/\">spending.lichfielddc.gov.uk/</a>.&#160;&#160;\nOn the surface navigating your way around the site looking at\ncouncil spend by type, subject, month, and supplier is the kind of\nexperience a user would expect. Great for a website displaying\ninformation about a single council.&#160;</p>\n<p>However, it is more than a web site.&#160; Inspection of the\nDownload data tab shows that you can get your hands on the source\ndata in csv format.&#160; Here is one line, representing a line of\nexpenditure, from that data:</p>\n<p><font size=\"1\" face=\n\"Courier New\">\"http://statistics.data.gov.uk/doc/local-authority/41UD\",\"Lichfield\nDistrict\nCouncil\",\"2010-04-06\",\"7747\",\"http://spending.lichfielddc.gov.uk/spend/8605670\",\"120.00\",\"BRISTOW\n&amp; SUTOR\",\"401\",\"Revenue Collection\",\"Supplies &amp;\nServices\",\"Bailiff Fees\",\"\"</font></p>\n<p>\u2026 which represents the data displayed on this <a href=\n\"http://spending.lichfielddc.gov.uk/spend/8605670\">human readable\npage</a>:</p>\n<p><a href=\n\"http://spending.lichfielddc.gov.uk/spend/8605670\"><img style=\n\"border-right-width: 0px;float: none;border-top-width: 0px;border-bottom-width: 0px;margin-left: auto;border-left-width: 0px;margin-right: auto\"\ntitle=\n\"Lichfield District Council Spending Data - Details of payment number 8605670\"\nborder=\"0\" alt=\n\"Lichfield District Council Spending Data - Details of payment number 8605670\"\nsrc=\n\"http://blogs.talis.com/nodalities/files/2011/01/LichfieldDistrictCouncilSpendingDataDetailsofpaymentnumber8605670.jpg\"\nwidth=\"180\" height=\"170\" /></a><br />\nLooking through the csv, you can pick out the strings of characters\nfor information such as the date, supplier name, department name\netc.&#160; In addition you can pick out a couple of <a href=\n\"http://en.wikipedia.org/wiki/Uniform_Resource_Identifier\">URI</a>s:</p>\n<ul>\n<li><a href=\n\"http://statistics.data.gov.uk/doc/local-authority/41UD\">http://statistics.data.gov.uk/doc/local-authority/41UD</a>\n\u2013 The UK Government identifier for Lichfield DC</li>\n<li><a href=\n\"http://spending.lichfielddc.gov.uk/spend/8605670\">http://spending.lichfielddc.gov.uk/spend/8605670</a>\n\u2013&#160; Lichfield\u2019s identifier for this payment</li>\n</ul>\n<p><a href=\n\"http://blogs.talis.com/nodalities/files/2011/01/LinkedDataforLichfieldDistrictCouncil007Cstatistics.data_.gov_.uk_.jpg\">\n<img style=\n\"border-right-width: 0px;border-top-width: 0px;border-bottom-width: 0px;margin-left: 0px;border-left-width: 0px;margin-right: 0px\"\ntitle=\n\"Linked Data for Lichfield District Council %007C statistics.data.gov.uk\"\nborder=\"0\" alt=\n\"Linked Data for Lichfield District Council %007C statistics.data.gov.uk\"\nalign=\"right\" src=\n\"http://blogs.talis.com/nodalities/files/2011/01/LinkedDataforLichfieldDistrictCouncil007Cstatistics.data_.gov_.uk_thumb.jpg\"\nwidth=\"244\" height=\"130\" /></a> In the context of csv, that\u2019s all\nthese URIs are, identifiers.&#160; However because they are http\nURIs you can click through to the address to get more\ninformation.&#160; If you do that with your web browser you get a\nhuman readable representation of the data.&#160; These sites also\nprovide access to the same data, formatted in RDF, for use by\ndevelopers.</p>\n<p><a href=\n\"http://blogs.talis.com/nodalities/files/2011/01/Sourceofhttp___spending.lichfielddc.gov_.uk_spend_8605670.rdf_.jpg\">\n<img style=\n\"border-bottom: 0px;border-left: 0px;margin-left: 0px;border-top: 0px;margin-right: 0px;border-right: 0px\"\ntitle=\n\"Source of http___spending.lichfielddc.gov.uk_spend_8605670.rdf\"\nborder=\"0\" alt=\n\"Source of http___spending.lichfielddc.gov.uk_spend_8605670.rdf\"\nalign=\"left\" src=\n\"http://blogs.talis.com/nodalities/files/2011/01/Sourceofhttp___spending.lichfielddc.gov_.uk_spend_8605670.rdf_thumb.jpg\"\nwidth=\"324\" height=\"106\" /></a> You can see that data by adding\n\u2018.rdf\u2019 to the end of the address, thus: <a title=\n\"http://spending.lichfielddc.gov.uk/spend/8605670.rdf\" href=\n\"http://spending.lichfielddc.gov.uk/spend/8605670.rdf\">http://spending.lichfielddc.gov.uk/spend/8605670.rdf</a>\nand then selecting the \u2018view source\u2019 option of your browser for the\npage of gobbledegook that you get back.&#160;&#160;</p>\n<p>Inspecting the RDF, you will see that most things, except\ndescriptive labels and financial values, are are now identified as\nURIs such as <a title=\n\"http://spending.lichfielddc.gov.uk/subjective/bailiff-fees\" href=\n\"http://spending.lichfielddc.gov.uk/subjective/bailiff-fees\">http://spending.lichfielddc.gov.uk/subjective/bailiff-fees</a>\nand <a title=\"http://spending.lichfielddc.gov.uk/invoice/7747\"\nhref=\"http://spending.lichfielddc.gov.uk/invoice/7747\">http://spending.lichfielddc.gov.uk/invoice/7747</a>.&#160;\nAgain if you follow those links, you will get a human readable\nrepresentation of that resource, and the RDF behind it by adding a\n\u2018.rdf\u2019 suffix.</p>\n<p>The eagle-eyed, inspecting the RDF-XML for Lichfield payment\nnumber 8605670, will have noticed a couple of things.&#160;\nFirstly, a liberal sprinkling of elements with names like\n<font face=\"Courier New\">payment:expenditureCategory</font> or\n<font face=\"Courier New\">payment:payment.</font> These come from\nthe <a href=\n\"http://data.gov.uk/resources/payments/reference\">Payments\nOntology</a> as published on data.gov.uk as the recommended way of\nencoding spending, and other payment associated data, in RDF.</p>\n<p>Secondly, you may have spotted that there is no date, or\nsupplier name or identifier.&#160; That is because those pieces of\ninformation are attributes associated with a payment \u2013 <a href=\n\"http://spending.lichfielddc.gov.uk/invoice/7747\">invoice number\n7747</a> in this case.</p>\n<p><a href=\n\"http://www.bbc.co.uk/nature/life/Whooper_Swan\"><img style=\n\"border-bottom: 0px;border-left: 0px;margin-left: 0px;border-top: 0px;margin-right: 0px;border-right: 0px\"\ntitle=\n\"BBC - Wildlife Finder - Whooper swan facts, pictures &amp; stunning videos\"\nborder=\"0\" alt=\n\"BBC - Wildlife Finder - Whooper swan facts, pictures &amp; stunning videos\"\nalign=\"left\" src=\n\"http://blogs.talis.com/nodalities/files/2011/01/BBCWildlifeFinderWhooperswanfactspicturesstunningvideos.jpg\"\nwidth=\"244\" height=\"205\" /></a> Zooming out from the data for a\nmoment, and looking at the human readable form, you will see that\nmost things, like spend type, invoice number, supplier name, are\nclickable links, which take you through to relevant information\nabout those things \u2013 <a href=\n\"http://spending.lichfielddc.gov.uk/supplier/rma-design-ltd.html\">address\ndetails &amp; payments</a> for a supplier, <a href=\n\"http://spending.lichfielddc.gov.uk/type/supplies-services.html\">all\npayments for a category</a> etc.&#160; This intuitive natural\nnavigation style often comes as a positive consequence of thinking\nabout data as a set of linked resources instead of the traditional\nrows &amp; columns that we are used to.&#160; Another great example\nof this effect can be found on a site such as the <a href=\n\"http://www.bbc.co.uk/nature/life/Whooper_Swan\">BBC Wildlife\nFinder</a>.&#160; That is not to say that you could not have\ncreated such a site without even considering Linked Data, of course\nyou could.&#160; However, data modelled as a set of linked\nresources almost self-describes the ideal navigation paths for a\nuser interface to display it to a human.</p>\n<p>The Linked Data practice of modelling data, such as spending\ndata, as a set of linked resources and identifying those resources\nwith URIs [which if looked up will provide information about that\nresource] is equally applicable to those outside of an individual\nauthority.&#160; By being able to consume that data, whilst\nunderstanding the relationships within it and having confidence in\nthe authority and persistence of the identifiers within it, a\ndeveloper can approach the task of aggregating, comparing, and\nusing that data in their applications more easily.</p>\n<p>So, how do I (as a local authority) get my data from its raw\nflat csv format, in to RDF with suitable URIs and produce a site\nlike Lichfield\u2019s?&#160; The simple answer is that you may not have\nto \u2013 others may help you do some, if not all, of it.&#160;&#160;\nWith help from organisations such as <a href=\n\"http://www.esd.org.uk/esdtoolkit/default.aspx\">esd-toolkit</a>,\n<a href=\"http://openlylocal.com/\">OpenlyLocal</a>, <a href=\n\"http://whatis.spotlightonspend.org.uk/\">SpotlightOnSpend</a>, and\nwith projects such as the <a href=\n\"http://blogs.talis.com/platform-consulting/2010/11/12/adding-linked-data-value-to-local-government/\">\nxSpend project</a> we are working on with LGID, many of the\nconversion [from csv], data formatting processes, and aggregation\nare being addressed \u2013 maybe not as quickly or completely as we\nwould like, but they are.&#160; As to a human readable web view of\nyour data, you may be able to copy Stuart by taking up the offer of\na free Talis Platform Store and then running your own web server\nwith his code that he hopes to share as open source.&#160;\nAlternatively it might be worth waiting for others to aggregate\nyour data and provide a way for your citizens to view your\ndata.</p>\n<p>As easy as that then! \u2013 Well not quite, there are some issues\nabout URI naming and creation, and how you bring the data together\nthat still do need addressing by those engaged in this.&#160; But\nthat is for Part 3\u2026.</p>\n</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt2.php> <http://purl.org/rss/1.0/title> "Linked Spending Data \u2013 How and Why Bother Pt2" .
<http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt2.php> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://blogs.talis.com/nodalities/2011/02/nodalities-issue-12-%e2%80%93-now-available.php> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<p>Issue 12 of Nodalities is now available for <a href=\"http://www.talis.com/nodalities\">download</a>.<a href=\"http://blogs.talis.com/nodalities/files/2011/02/Nodalities121.jpg\"><img class=\"alignright size-full wp-image-5405\" title=\"Nodalities12\" src=\"http://blogs.talis.com/nodalities/files/2011/02/Nodalities121.jpg\" alt=\"\" width=\"297\" height=\"391\"></img></a></p>\n<p>In this issue, some rather practical things that Linked Data is\ngood at solving are being put to use saving lives: quite literally,\nas Bart van Leeuwen explains in our cover story. Simple ideas\njoining up public data and GIS devices are helping the Amsterdam\nfire service get their equipment to the scenes of fires more\nquickly and safely.</p>\n<p>Elsewhere, Martin Belam, an information architect at the\nGuardian, tells us about their approach to Linked Data, and what it\nmeans to them. Talis\u2019 Leigh Dodds outlines some of the challenge\nand opportunities of Linked Data in an evolving world in his\narticle. Also supporting Linked Data research is the\nmulti-organisational LATC Project which is introduced in this\nissue. And finally, Tim Hodson discusses a very practical approach\nto starting with Linked Data, and may also discuss eating an\nelephant.</p>\n<p>You can subscribe to Nodalities for free <a href=\"http://www.talis.com/nodalities/subscribe/\" target=\"_blank\">here</a> and read previous issues <a href=\"http://www.talis.com/nodalities/previous_issues/\" target=\"_blank\">here</a>.</p>\n</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://blogs.talis.com/nodalities/2011/02/nodalities-issue-12-%e2%80%93-now-available.php> <http://purl.org/dc/elements/1.1/creator> "Talis" .
<http://blogs.talis.com/nodalities/2011/02/nodalities-issue-12-%e2%80%93-now-available.php> <http://purl.org/dc/elements/1.1/date> "2011-02-01T11:56:16Z" .
<http://blogs.talis.com/nodalities/2011/02/nodalities-issue-12-%e2%80%93-now-available.php> <http://purl.org/dc/elements/1.1/relation> "http://blogs.talis.com/nodalities/" .
<http://blogs.talis.com/nodalities/2011/02/nodalities-issue-12-%e2%80%93-now-available.php> <http://purl.org/dc/elements/1.1/source> "Nodalities by Talis" .
<http://blogs.talis.com/nodalities/2011/02/nodalities-issue-12-%e2%80%93-now-available.php> <http://purl.org/rss/1.0/description> "Issue 12 of Nodalities is now available for download . In this issue, some rather practical things that Linked Data is good at solving are being put to use saving lives: quite literally, as Bart van Leeuwen explains in our cover story. Simple ideas joining up public data and GIS devices are helping the Amsterdam fire service get their equipment to the scenes of fires more quickly and safely. Elsewhere, Martin Belam, an information architect at the Guardian, tells us about their approach to Linked Data, and what it means to them. Talis\u2019 Leigh Dodds outlines some of the challenge ..." .
<http://blogs.talis.com/nodalities/2011/02/nodalities-issue-12-%e2%80%93-now-available.php> <http://purl.org/rss/1.0/link> "http://blogs.talis.com/nodalities/2011/02/nodalities-issue-12-%e2%80%93-now-available.php" .
<http://blogs.talis.com/nodalities/2011/02/nodalities-issue-12-%e2%80%93-now-available.php> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<p>Issue 12 of Nodalities is now available for <a href=\n\"http://www.talis.com/nodalities\">download</a>.<a href=\n\"http://blogs.talis.com/nodalities/files/2011/02/Nodalities121.jpg\"><img class=\"alignright size-full wp-image-5405\"\ntitle=\"Nodalities12\" src=\n\"http://blogs.talis.com/nodalities/files/2011/02/Nodalities121.jpg\"\nalt=\"\" width=\"297\" height=\"391\" /></a></p>\n<p>In this issue, some rather practical things that Linked Data is\ngood at solving are being put to use saving lives: quite literally,\nas Bart van Leeuwen explains in our cover story. Simple ideas\njoining up public data and GIS devices are helping the Amsterdam\nfire service get their equipment to the scenes of fires more\nquickly and safely.</p>\n<p>Elsewhere, Martin Belam, an information architect at the\nGuardian, tells us about their approach to Linked Data, and what it\nmeans to them. Talis\u2019 Leigh Dodds outlines some of the challenge\nand opportunities of Linked Data in an evolving world in his\narticle. Also supporting Linked Data research is the\nmulti-organisational LATC Project which is introduced in this\nissue. And finally, Tim Hodson discusses a very practical approach\nto starting with Linked Data, and may also discuss eating an\nelephant.</p>\n<p>You can subscribe to Nodalities for free <a href=\n\"http://www.talis.com/nodalities/subscribe/\" target=\n\"_blank\">here</a> and read previous issues <a href=\n\"http://www.talis.com/nodalities/previous_issues/\" target=\n\"_blank\">here</a>.</p>\n</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://blogs.talis.com/nodalities/2011/02/nodalities-issue-12-%e2%80%93-now-available.php> <http://purl.org/rss/1.0/title> "Nodalities Issue 12 \u2013 now available" .
<http://blogs.talis.com/nodalities/2011/02/nodalities-issue-12-%e2%80%93-now-available.php> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://blogs.talis.com/nodalities/2011/02/talis-inc-ceo-bernadette-hyland-speaks-to-the-semantic-link-%e2%80%93-episode-1-and-2.php> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<p><strong><a href=\"http://blogs.talis.com/nodalities/files/2011/02/bernadette.jpeg\"><img class=\"alignright size-full wp-image-5420\" title=\"bernadette\" src=\"http://blogs.talis.com/nodalities/files/2011/02/bernadette.jpeg\" alt=\"\" width=\"188\" height=\"209\"></img></a></strong>Each month, Talis\nInc CEO, Bernadette Hyland participates in The Semantic Link\npodcast series amongst other Semantic thought leaders. Paul Miller,\nthe host of the series, introduces <a href=\"http://semanticweb.com/the-semantic-link-episode-1-december-2010_b16991\" target=\"_blank\">episode one</a> and the \u201CPodPanel\u201D which includes:\nPeter Brown, currently Chair of the Board of Directors of standards\nbody OASIS; Christine Connors, a consultant specialising in\nontology and taxonomy design and related issues; Eric Franzon, Vice\nPresident of WebMediaBrands; Ivan Herman, Semantic Web Activity\nLead for the World Wide Web Consortium (W3C); Eric Hoffer,\nConsultant and Andraz Tori, CTO of Zemanta. The <a href=\"http://semanticweb.com/the-semantic-link-episode-2-january-2011_b17338\" target=\"_blank\">second instalment</a> is also now available.</p>\n<p><a href=\"http://blogs.talis.com/nodalities/files/2011/02/semanticweb.jpg\"><img class=\"aligncenter size-full wp-image-5423\" title=\"semanticweb\" src=\"http://blogs.talis.com/nodalities/files/2011/02/semanticweb.jpg\" alt=\"\" width=\"465\" height=\"38\"></img></a></p>\n</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://blogs.talis.com/nodalities/2011/02/talis-inc-ceo-bernadette-hyland-speaks-to-the-semantic-link-%e2%80%93-episode-1-and-2.php> <http://purl.org/dc/elements/1.1/creator> "Talis" .
<http://blogs.talis.com/nodalities/2011/02/talis-inc-ceo-bernadette-hyland-speaks-to-the-semantic-link-%e2%80%93-episode-1-and-2.php> <http://purl.org/dc/elements/1.1/date> "2011-02-01T12:04:39Z" .
<http://blogs.talis.com/nodalities/2011/02/talis-inc-ceo-bernadette-hyland-speaks-to-the-semantic-link-%e2%80%93-episode-1-and-2.php> <http://purl.org/dc/elements/1.1/relation> "http://blogs.talis.com/nodalities/" .
<http://blogs.talis.com/nodalities/2011/02/talis-inc-ceo-bernadette-hyland-speaks-to-the-semantic-link-%e2%80%93-episode-1-and-2.php> <http://purl.org/dc/elements/1.1/source> "Nodalities by Talis" .
<http://blogs.talis.com/nodalities/2011/02/talis-inc-ceo-bernadette-hyland-speaks-to-the-semantic-link-%e2%80%93-episode-1-and-2.php> <http://purl.org/rss/1.0/description> "\n \n      Each month, Talis\nInc CEO, Bernadette Hyland participates in The Semantic Link\npodcast series amongst other Semantic thought leaders. Paul Miller,\nthe host of the series, introduces  episode one  and the \u201CPodPanel\u201D which includes:\nPeter Brown, currently Chair of the Board of Directors of standards\nbody OASIS; Christine Connors, a consultant specialising in\nontology and taxonomy design and related issues; Eric Franzon, Vice\nPresident of WebMediaBrands; Ivan Herman, Semantic Web Activity\nLead for the World Wide Web Consortium (W3C); Eric Hoffer,\nConsultant and Andraz Tori, CTO of Zemanta. The  second instalment  is also now available. \n     \n \n" .
<http://blogs.talis.com/nodalities/2011/02/talis-inc-ceo-bernadette-hyland-speaks-to-the-semantic-link-%e2%80%93-episode-1-and-2.php> <http://purl.org/rss/1.0/link> "http://blogs.talis.com/nodalities/2011/02/talis-inc-ceo-bernadette-hyland-speaks-to-the-semantic-link-%e2%80%93-episode-1-and-2.php" .
<http://blogs.talis.com/nodalities/2011/02/talis-inc-ceo-bernadette-hyland-speaks-to-the-semantic-link-%e2%80%93-episode-1-and-2.php> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<p><strong><a href=\n\"http://blogs.talis.com/nodalities/files/2011/02/bernadette.jpeg\"><img class=\"alignright size-full wp-image-5420\"\ntitle=\"bernadette\" src=\n\"http://blogs.talis.com/nodalities/files/2011/02/bernadette.jpeg\"\nalt=\"\" width=\"188\" height=\"209\" /></a></strong>Each month, Talis\nInc CEO, Bernadette Hyland participates in The Semantic Link\npodcast series amongst other Semantic thought leaders. Paul Miller,\nthe host of the series, introduces <a href=\n\"http://semanticweb.com/the-semantic-link-episode-1-december-2010_b16991\"\ntarget=\"_blank\">episode one</a> and the \u201CPodPanel\u201D which includes:\nPeter Brown, currently Chair of the Board of Directors of standards\nbody OASIS; Christine Connors, a consultant specialising in\nontology and taxonomy design and related issues; Eric Franzon, Vice\nPresident of WebMediaBrands; Ivan Herman, Semantic Web Activity\nLead for the World Wide Web Consortium (W3C); Eric Hoffer,\nConsultant and Andraz Tori, CTO of Zemanta. The <a href=\n\"http://semanticweb.com/the-semantic-link-episode-2-january-2011_b17338\"\ntarget=\"_blank\">second instalment</a> is also now available.</p>\n<p><a href=\n\"http://blogs.talis.com/nodalities/files/2011/02/semanticweb.jpg\"><img class=\"aligncenter size-full wp-image-5423\"\ntitle=\"semanticweb\" src=\n\"http://blogs.talis.com/nodalities/files/2011/02/semanticweb.jpg\"\nalt=\"\" width=\"465\" height=\"38\" /></a></p>\n</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://blogs.talis.com/nodalities/2011/02/talis-inc-ceo-bernadette-hyland-speaks-to-the-semantic-link-%e2%80%93-episode-1-and-2.php> <http://purl.org/rss/1.0/title> "Talis Inc CEO, Bernadette Hyland speaks to The Semantic Link\n\u2013 Episode 1 and 2" .
<http://blogs.talis.com/nodalities/2011/02/talis-inc-ceo-bernadette-hyland-speaks-to-the-semantic-link-%e2%80%93-episode-1-and-2.php> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://danbri.org/words/2011/02/01/658> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<p>This is a quick visual teaser for some <a href=\"http://archive.org/\">archive.org</a>-related work I\u2019m doing with\nNoTube colleagues, and a collaboration <a href=\"http://twitter.com/#!/kidehen/status/32470388189429760\">with\nKingsley Idehen</a> on navigating it.</p>\n<p>In NoTube we are trying to match people and TV content by using\nrich linked data representations of both. I love <a href=\"http://archive.org/\">Archive.org</a> and with <a href=\"http://danbri.org/words/2010/10/27/565\">their help</a> have\ncrawled an experimental subset of the video-related metadata for\nthe Archive. I\u2019ve also used a couple of other sources; Sean P.\nAune\u2019s <a href=\"http://tech.blorge.com/Structure:%20/2010/08/11/top-40-best-free-legal-movies-you-can-download-right-now/\">\nlist</a> of 40 great movies, and the Wikipedia page listing\n<a href=\"http://en.wikipedia.org/wiki/List_of_films_in_the_public_domain_in_the_United_States\">\nUS public domain films</a>. I fixed, merged and scraped until I had\na reasonable <a href=\"http://buttons.notube.tv/moredata/archive.org/films/_archivemeta.nt\">\nsample dataset</a> for testing.</p>\n<p><img class=\"alignright\" title=\"Intertain Lab - projected Pivot\" src=\"http://farm6.static.flickr.com/5138/5410838210_5aa82e5474_m.jpg\" alt=\"\"></img></p>\n<p>I wanted to test the <a href=\"http://en.wikipedia.org/wiki/Microsoft_Live_Labs_Pivot\">Microsoft\nPivot Viewe</a>r (a Silverlight control), and since OpenLink\u2019s\nVirtuoso package now has built-in support, I got talking with\nKingsley and we ended up with the following demo. Since not\neveryone has Silverlight, and this is just a rough prototype that\nmay be offline, I\u2019ve made a few screenshots. The real thing is very\nvisual, with animated zooms and transitions, but screenshots give\nthe basic idea.</p>\n<p>Notes: the core dataset for now is just <em>links</em> between\narchive.org entries and Wikipedia/dbpedia pages. In NoTube we\u2019ll\nalso try <a href=\"http://lupedia.ontotext.com/\">Lupedia</a>,\n<a href=\"http://www.zemanta.com/\">Zemanta</a>, Reuter\u2019s <a href=\"http://www.opencalais.com/\">OpenCalais</a> services on the\nArchive.org descriptions to see if they suggest other useful links\nand categories, as well as any other enrichment sources (delicious\ntags, machine learning) we can find. There is also more metadata\nfrom the Archive that we should also be using.</p>\n<p>This simple preview simply shows how <em>one extra fact</em> per\nArchived item creates new opportunities for navigation, discovery\nand understanding. Note that the UI is in no way tuned to be TV,\nvideo or archive specific; rather it just lets you explore a group\nof items by their \u2018facets\u2019 or common properties. It also reveals\nthat wiki data is rather chaotic, however some fields (release\ndate, runtime, director, star etc.) are reliably present. And of\ncourse, since the data is from Wikipedia, users can always fix the\ndata.</p>\n<p>You often hear Linked Data enthusiasts talk about data \u201Csilos\u201D,\nand the need to interconnect them. All that means here, is that\nwhen collections are linked, then improvements to information on\none side of the link bring improvements automatically to the other.\nWhen a Wikipedia page about a director, actor or movie is improved,\nit now also improves our means of navigating Archive.org\u2019s\nwonderful collection. And when someone contributes new video or new\nHTML5-powered players to the Archive, they\u2019re also enriching the\nEncyclopedia too.</p>\n<p><a href=\"http://danbri.org/words/wp-content/uploads/2011/02/archive-pivot-releasedate.png\">\n<img class=\"alignnone size-large wp-image-660\" title=\"archive-pivot-releasedate\" src=\"http://danbri.org/words/wp-content/uploads/2011/02/archive-pivot-releasedate-1024x515.png\" alt=\"Archive.org films on a timeline by release date according to Wikipedia.\" width=\"640\" height=\"321\"></img></a></p>\n<p>One thing to mention is that everything here comes from the\nWikipedia data that is automatically extracted from by <a href=\"http://dbpedia.org/\">DBpedia</a>, and that currently the\nextractors are not working perfectly on all films. So it should get\nbetter in the future. I also added a lot of the image links myself,\nsemi-automatically. For now, this navigation is much more\nfactually-based than topic; however we do have Wikipedia categories\nfor each film, director, studio etc., and these have been mapped to\nother category systems (formal and informal), so there\u2019s a lot of\nother directions to explore.</p>\n<p>What else can we do? How about flip the tiled barchart to\norganize by the film\u2019s <em>distributor</em>, and constrain the\n\u2018<em>release date</em>\u2018 facet to the 1940s:</p>\n<p><a href=\"http://danbri.org/words/wp-content/uploads/2011/02/distributors-1940s.png\">\n<img class=\"alignnone size-large wp-image-662\" title=\"distributors-1940s\" src=\"http://danbri.org/words/wp-content/uploads/2011/02/distributors-1940s-1024x447.png\" alt=\"\" width=\"640\" height=\"279\"></img></a></p>\n<p>That\u2019s nice. But remember that with Linked Data, you\u2019re always\ndealing with a subset of data. It\u2019s hard to know (and it\u2019s hard for\nthe interface designers to show us) when you have all the relevant\ndata in hand. In this case, we can see what this is telling us\nabout the videos currently available within the demo. But does it\ntell us anything interesting about all the films in the Archive?\nAll the films in the world? Maybe a little, but interpretation is\ndifficult.</p>\n<p>Next: zoom in to a specific item. The legendary <a href=\"http://www.archive.org/details/Plan_9_from_Outer_Space_1959\">Plan\n9 from Outer Space</a> (<a href=\"http://en.wikipedia.org/wiki/Plan_9_from_Outer_Space\">wikipedia</a>\n/ <a href=\"http://dbpedia.org/page/Plan_9_from_Outer_Space\">dbpedia</a>).</p>\n<p><em>Note the HTML-based info panel on the right hand side. In\nthis case it\u2019s automatically generated by Virtuoso from properties\nof the item. A TV-oriented version would be less generic.</em></p>\n<p><a href=\"http://danbri.org/words/wp-content/uploads/2011/02/plan9.png\"><img class=\"alignnone size-large wp-image-663\" title=\"plan9\" src=\"http://danbri.org/words/wp-content/uploads/2011/02/plan9-1024x449.png\" alt=\"\" width=\"640\" height=\"280\"></img></a></p>\n<p>Finally, we can explore the collection by constraining the\ntimeline to show us items organized according to release date, for\nsome facet. Here we show it picking out the career of one Edward J.\nKay, at least as far as he shows up as composer of items in this\ncollection:</p>\n<p><a href=\"http://danbri.org/words/wp-content/uploads/2011/02/when-edward-kay.png\">\n<img class=\"alignnone size-large wp-image-664\" title=\"when-edward-kay\" src=\"http://danbri.org/words/wp-content/uploads/2011/02/when-edward-kay-1024x450.png\" alt=\"\" width=\"640\" height=\"281\"></img></a></p>\n<p>Now turning back to Wikipedia to learn about \u2018Edward J. Kay\u2019, I\nfind he has no entry (beyond these passing mentions of his name) in\nthe English Wikipedia, despite his work on <a href=\"http://en.wikipedia.org/wiki/The_Ape_Man\">The Ape Man</a>,\n<a href=\"http://en.wikipedia.org/wiki/The_Fatal_Hour\">The Fatal\nHour,</a> and other films. \u00A0While the German Wikipedia does\nhonour him with <a href=\"http://de.wikipedia.org/wiki/Edward_J._Kay\">an entry</a>, I wonder\nwhether this kind of <a href=\"http://en.wikipedia.org/wiki/Linked_Data\">Linked Data</a>\nnavigation will change the dynamics of the \u2018<a href=\"http://meta.wikimedia.org/wiki/Deletionism\">deletionism</a>\u2018\ndebates at Wikipedia. \u00A0Firstly by showing that structured data\nmanaged elsewhere can enrich the Wikipedia (and vice-versa),\nremoving some pressure for a single Wiki to cover everything.\nSecondly it provides a tool to stand further back from the data and\nview things in a larger context; a context where for example Edward\nJ. Kay\u2019s achievements become clearer.</p>\n<p>Much like <a href=\"http://www.freebase.com/labs/parallax/\">Freebase Parallax</a>, the\nPivot viewer hints at a future in which we explore data by\nnavigating from <em>sets of things</em> to other <em>sets of\nthings</em> - like the set of film\u2019s Edward J. Kay contributed to.\n\u00A0Pivot doesn\u2019t yet cover this, but it does very vividly\npresent the potential for this kind of navigation, showing that\nnavigation of films, TV shows and actors may be richer when it\nembraces more general mechanisms.</p>\n</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://danbri.org/words/2011/02/01/658> <http://purl.org/dc/elements/1.1/creator> "Dan Brickley" .
<http://danbri.org/words/2011/02/01/658> <http://purl.org/dc/elements/1.1/date> "2011-02-01T19:43:50Z" .
<http://danbri.org/words/2011/02/01/658> <http://purl.org/dc/elements/1.1/relation> "http://danbri.org/words/" .
<http://danbri.org/words/2011/02/01/658> <http://purl.org/dc/elements/1.1/source> "danbri's foaf stories" .
<http://danbri.org/words/2011/02/01/658> <http://purl.org/rss/1.0/description> "This is a quick visual teaser for some archive.org -related work I\u2019m doing with NoTube colleagues, and a collaboration with Kingsley Idehen on navigating it. In NoTube we are trying to match people and TV content by using rich linked data representations of both. I love Archive.org and with their help have crawled an experimental subset of the video-related metadata for the Archive. I\u2019ve also used a couple of other sources; Sean P. Aune\u2019s list of 40 great movies, and the Wikipedia page listing US public domain films . I fixed, merged and scraped until I had a reasonable sample ..." .
<http://danbri.org/words/2011/02/01/658> <http://purl.org/rss/1.0/link> "http://danbri.org/words/2011/02/01/658" .
<http://danbri.org/words/2011/02/01/658> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<p>This is a quick visual teaser for some <a href=\n\"http://archive.org/\">archive.org</a>-related work I\u2019m doing with\nNoTube colleagues, and a collaboration <a href=\n\"http://twitter.com/#!/kidehen/status/32470388189429760\">with\nKingsley Idehen</a> on navigating it.</p>\n<p>In NoTube we are trying to match people and TV content by using\nrich linked data representations of both. I love <a href=\n\"http://archive.org/\">Archive.org</a> and with <a href=\n\"http://danbri.org/words/2010/10/27/565\">their help</a> have\ncrawled an experimental subset of the video-related metadata for\nthe Archive. I\u2019ve also used a couple of other sources; Sean P.\nAune\u2019s <a href=\n\"http://tech.blorge.com/Structure:%20/2010/08/11/top-40-best-free-legal-movies-you-can-download-right-now/\">\nlist</a> of 40 great movies, and the Wikipedia page listing\n<a href=\"http://en.wikipedia.org/wiki/List_of_films_in_the_public_domain_in_the_United_States\">\nUS public domain films</a>. I fixed, merged and scraped until I had\na reasonable <a href=\n\"http://buttons.notube.tv/moredata/archive.org/films/_archivemeta.nt\">\nsample dataset</a> for testing.</p>\n<p><img class=\" alignright\" title=\"Intertain Lab - projected Pivot\"\nsrc=\n\"http://farm6.static.flickr.com/5138/5410838210_5aa82e5474_m.jpg\"\nalt=\"\" /></p>\n<p>I wanted to test the <a href=\n\"http://en.wikipedia.org/wiki/Microsoft_Live_Labs_Pivot\">Microsoft\nPivot Viewe</a>r (a Silverlight control), and since OpenLink\u2019s\nVirtuoso package now has built-in support, I got talking with\nKingsley and we ended up with the following demo. Since not\neveryone has Silverlight, and this is just a rough prototype that\nmay be offline, I\u2019ve made a few screenshots. The real thing is very\nvisual, with animated zooms and transitions, but screenshots give\nthe basic idea.</p>\n<p>Notes: the core dataset for now is just <em>links</em> between\narchive.org entries and Wikipedia/dbpedia pages. In NoTube we\u2019ll\nalso try <a href=\"http://lupedia.ontotext.com/\">Lupedia</a>,\n<a href=\"http://www.zemanta.com/\">Zemanta</a>, Reuter\u2019s <a href=\n\"http://www.opencalais.com/\">OpenCalais</a> services on the\nArchive.org descriptions to see if they suggest other useful links\nand categories, as well as any other enrichment sources (delicious\ntags, machine learning) we can find. There is also more metadata\nfrom the Archive that we should also be using.</p>\n<p>This simple preview simply shows how <em>one extra fact</em> per\nArchived item creates new opportunities for navigation, discovery\nand understanding. Note that the UI is in no way tuned to be TV,\nvideo or archive specific; rather it just lets you explore a group\nof items by their \u2018facets\u2019 or common properties. It also reveals\nthat wiki data is rather chaotic, however some fields (release\ndate, runtime, director, star etc.) are reliably present. And of\ncourse, since the data is from Wikipedia, users can always fix the\ndata.</p>\n<p>You often hear Linked Data enthusiasts talk about data \u201Csilos\u201D,\nand the need to interconnect them. All that means here, is that\nwhen collections are linked, then improvements to information on\none side of the link bring improvements automatically to the other.\nWhen a Wikipedia page about a director, actor or movie is improved,\nit now also improves our means of navigating Archive.org\u2019s\nwonderful collection. And when someone contributes new video or new\nHTML5-powered players to the Archive, they\u2019re also enriching the\nEncyclopedia too.</p>\n<p><a href=\n\"http://danbri.org/words/wp-content/uploads/2011/02/archive-pivot-releasedate.png\">\n<img class=\"alignnone size-large wp-image-660\" title=\n\"archive-pivot-releasedate\" src=\n\"http://danbri.org/words/wp-content/uploads/2011/02/archive-pivot-releasedate-1024x515.png\"\nalt=\n\"Archive.org films on a timeline by release date according to Wikipedia.\"\nwidth=\"640\" height=\"321\" /></a></p>\n<p>One thing to mention is that everything here comes from the\nWikipedia data that is automatically extracted from by <a href=\n\"http://dbpedia.org/\">DBpedia</a>, and that currently the\nextractors are not working perfectly on all films. So it should get\nbetter in the future. I also added a lot of the image links myself,\nsemi-automatically. For now, this navigation is much more\nfactually-based than topic; however we do have Wikipedia categories\nfor each film, director, studio etc., and these have been mapped to\nother category systems (formal and informal), so there\u2019s a lot of\nother directions to explore.</p>\n<p>What else can we do? How about flip the tiled barchart to\norganize by the film\u2019s <em>distributor</em>, and constrain the\n\u2018<em>release date</em>\u2018 facet to the 1940s:</p>\n<p><a href=\n\"http://danbri.org/words/wp-content/uploads/2011/02/distributors-1940s.png\">\n<img class=\"alignnone size-large wp-image-662\" title=\n\"distributors-1940s\" src=\n\"http://danbri.org/words/wp-content/uploads/2011/02/distributors-1940s-1024x447.png\"\nalt=\"\" width=\"640\" height=\"279\" /></a></p>\n<p>That\u2019s nice. But remember that with Linked Data, you\u2019re always\ndealing with a subset of data. It\u2019s hard to know (and it\u2019s hard for\nthe interface designers to show us) when you have all the relevant\ndata in hand. In this case, we can see what this is telling us\nabout the videos currently available within the demo. But does it\ntell us anything interesting about all the films in the Archive?\nAll the films in the world? Maybe a little, but interpretation is\ndifficult.</p>\n<p>Next: zoom in to a specific item. The legendary <a href=\n\"http://www.archive.org/details/Plan_9_from_Outer_Space_1959\">Plan\n9 from Outer Space</a> (<a href=\n\"http://en.wikipedia.org/wiki/Plan_9_from_Outer_Space\">wikipedia</a>\n/ <a href=\n\"http://dbpedia.org/page/Plan_9_from_Outer_Space\">dbpedia</a>).</p>\n<p><em>Note the HTML-based info panel on the right hand side. In\nthis case it\u2019s automatically generated by Virtuoso from properties\nof the item. A TV-oriented version would be less generic.</em></p>\n<p><a href=\n\"http://danbri.org/words/wp-content/uploads/2011/02/plan9.png\"><img class=\"alignnone size-large wp-image-663\"\ntitle=\"plan9\" src=\n\"http://danbri.org/words/wp-content/uploads/2011/02/plan9-1024x449.png\"\nalt=\"\" width=\"640\" height=\"280\" /></a></p>\n<p>Finally, we can explore the collection by constraining the\ntimeline to show us items organized according to release date, for\nsome facet. Here we show it picking out the career of one Edward J.\nKay, at least as far as he shows up as composer of items in this\ncollection:</p>\n<p><a href=\n\"http://danbri.org/words/wp-content/uploads/2011/02/when-edward-kay.png\">\n<img class=\"alignnone size-large wp-image-664\" title=\n\"when-edward-kay\" src=\n\"http://danbri.org/words/wp-content/uploads/2011/02/when-edward-kay-1024x450.png\"\nalt=\"\" width=\"640\" height=\"281\" /></a></p>\n<p>Now turning back to Wikipedia to learn about \u2018Edward J. Kay\u2019, I\nfind he has no entry (beyond these passing mentions of his name) in\nthe English Wikipedia, despite his work on <a href=\n\"http://en.wikipedia.org/wiki/The_Ape_Man\">The Ape Man</a>,\n<a href=\"http://en.wikipedia.org/wiki/The_Fatal_Hour\">The Fatal\nHour,</a> and other films. &#160;While the German Wikipedia does\nhonour him with <a href=\n\"http://de.wikipedia.org/wiki/Edward_J._Kay\">an entry</a>, I wonder\nwhether this kind of <a href=\n\"http://en.wikipedia.org/wiki/Linked_Data\">Linked Data</a>\nnavigation will change the dynamics of the \u2018<a href=\n\"http://meta.wikimedia.org/wiki/Deletionism\">deletionism</a>\u2018\ndebates at Wikipedia. &#160;Firstly by showing that structured data\nmanaged elsewhere can enrich the Wikipedia (and vice-versa),\nremoving some pressure for a single Wiki to cover everything.\nSecondly it provides a tool to stand further back from the data and\nview things in a larger context; a context where for example Edward\nJ. Kay\u2019s achievements become clearer.</p>\n<p>Much like <a href=\n\"http://www.freebase.com/labs/parallax/\">Freebase Parallax</a>, the\nPivot viewer hints at a future in which we explore data by\nnavigating from <em>sets of things</em> to other <em>sets of\nthings</em> - like the set of film\u2019s Edward J. Kay contributed to.\n&#160;Pivot doesn\u2019t yet cover this, but it does very vividly\npresent the potential for this kind of navigation, showing that\nnavigation of films, TV shows and actors may be richer when it\nembraces more general mechanisms.</p>\n</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://danbri.org/words/2011/02/01/658> <http://purl.org/rss/1.0/title> "Video Linking: Archives and Encyclopedias" .
<http://danbri.org/words/2011/02/01/658> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://dannyayers.com/2011/01/22/Some-Problems> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<p>Georgi Kobilarov has a refreshing post, suggesting <a href=\"http://blog.georgikobilarov.com/2011/01/making-linked-data-work-isnt-the-problem/\">\nMaking Linked Data work isnt the problem</a>. I'm inclined to agree\nwith most of what he says. The technology in itself isn't a\nsolution to any problem, rather an enabler to solve problems. While\nthe idea of serendipity is appealing, it isn't very good\njustification for a huge global commitment of resources. So what\nkind of problems do we, as living, social and technological\norganisms wish to solve?<br></br>\n<br></br>\nTo start exploring this space I reckon there are (at least) two\ngeneral modes of knowledge use. The first is relatively\ndomain-specific, directed by a set of requirements associated with\na corresponding set of real-world tasks and operations. These I'd\nput under the umbrella of <strong>Applications</strong>, akin to\nthe computer applications we already use but augmented with\nknowledge engineering facilities and access to the Web of Data. As\na shortcut the starting point here is <a href=\"http://www.ninebynine.org/SWAD-E/Scenario-HomeNetwork/HomeNetwork/HomeNetwork-347.htm\">\nConnolly's Bane</a>: \"<em>The bane of my existence is doing things\nI know the computer could do for me.</em>\". But in general it goes\nfar further, in that there are plenty of beneficial things we don't\nalready do. A second mode would be ad hoc, fairly immediate,\nunplanned, call it <strong>Just-in-time</strong> problem solving,\nthe kind of thing that we currently turn to search engines\nfor.<br></br>\n<br></br>\nAs an example of the <strong>Applications</strong> mode, one of the\nearly drivers for the Web was <strong>e-commerce</strong>. I think\nI'm fairly safe in saying that only the surface of the potential\nthere has been scratched. There's a hint of what can be possible\nwith things like the individual-targetting of Google Ads and Amazon\nrecommendations. In this space the <a href=\"http://www.heppnetz.de/projects/goodrelations/\">GoodRelations</a>\nontology is a marvellous baseline. But what we're not really seeing\nyet is the whole supply chain from the manufacturer to consumer\nbeing integrated. Fairly loosely-coupled (as it is today) In one\ndirection there are the financial aspects (<em>\"follow the\nmoney\"</em>), in the other direction is all the transport,\nmanufacturing and processing that go from raw materials to\ndelivered finished product. Within those different parts of the\npipeline there are a whole host of problems relating to technology\ntied together by human and natural resources.<br></br>\n<br></br>\nAlongside this commercial world there are macroeconomic and\nmacrosocial systems, those areas traditionally covered by\n<strong>government</strong>. We're already seeing some movement\naround transparency with the various government data projects, but\nI think we're still a very long way from seeing genuinely informed\npolicy and decision making. Reflecting the darker side of\nadvertising right down to commercial spam and taking advantage of\ngeneral ignorance, good governance is seriously compromised by\nself-interest (of individuals and corporations) and misinformation.\nI recently heard a radio programme talking about the UK\nConservative Party's successful \"Broken Britain\" election campaign.\nAn aspect of this was that violent crime was perceived as being on\nthe increase. However the actual statistics suggest that in reality\nthis malaise had actually been declining (see <a href=\"http://www.guardian.co.uk/uk/2011/jan/20/murder-rate-lowest-12-years\">\nMurder rate lowest for 12 years</a> <em>\"Home Office figures show\noverall crime fell by 5% in England and Wales\"</em>). Politicians\nwill always lie, but damage is only done when they get away with it\nand aren't held to account with the facts. But I don't really want\nto suggest that prevention of political badness is the goal here,\nrather the encouragement and facilitation of goodness\n(<em>man</em>...).<br></br>\n<br></br>\nAnother huge area where there are countless problems to solve is\n<strong>science</strong>. While the Web has vastly improved\ninformation sharing and been a boon to research, I'm not sure the\nunderlying methodologies have changed that much. I'm convinced the\nopen sharing of knowledge at the data level can offer <em>A New\nKind of Science</em> (no hyperbole there!).</p>\n<p>There are plenty of other application domains that could benefit\nfrom a bit of Web-scale knowledge engineering. Ok, I'll name one\nmore bundle: the <strong>Arts</strong>.</p>\n<p>Ok, moving on to the <strong>Just-in-time</strong> mode of\nproblem solving, take a look at the following list (random stuff\nthat came off the top of my head when I woke up this morning).\nImagine how you would solve these problems now, and then think how\nyou might solve them with a thousand programmers at your beck and\ncall. Most of them need something considerably deeper than a\nkeyword/linkrank document search. I've dumped this list over on the\n<a href=\"http://esw.w3.org/ProblemsTheSemanticWebMaySolve\">ESW\nWiki</a>, additions and discussion welcome over there (I still\nhaven't implemented comments on this blog, so if you have a comment\nfor anything either <a href=\"mailto:danny.ayers@gmail.com\">mail\nme</a> or blog it (and mail me) or tweet or use Facebook...).<br></br>\n<br></br></p>\n<ul>\n<li>I'd like to upgrade the computer I use for video editing. My\nbudget is about 300 euro. What should I buy?</li>\n<li>Who should I get to make the soundtrack to my new film?</li>\n<li>I've bought an Ubuntu laptop to replace my old Apple, I'd like\nit to run applications that fulfil all the tasks I have on the old\nmachine. What do I need?</li>\n<li>Should HTML use namespace prefixes?</li>\n<li>Is there a political motivation behind Royal Weddings?</li>\n<li>Who should I vote for?</li>\n<li>Who might make a good (romantic) partner?</li>\n<li>I wish to sell my double glazing products in sub-Saharan\nAfrica, who should I contact?</li>\n<li>Who might make a good (business) partner there?</li>\n<li>I got a mail from someone claiming to be my cousin, asking for\na loan. Should I give them the loan?</li>\n<li>I've got an interesting rash. Should I see a doctor?</li>\n<li>I wish to enlarge my penis. What method is safe and\nreliable?</li>\n</ul>\n<p><em>(Sorry, couldn't resist the last one - but it's a valid\nexample of where you'd need good healthcare data alongside\nreputation and provenance information)</em></p>\n<p>PS. <a title=\"Dan Brickley\" href=\"http://danbri.org/words/\">danbri</a> points me to a short 1989/90\ndocument which contains a fairly similar list (<em>minus references\nto genitalia</em>) : <a href=\"http://www.w3.org/History/1989/proposal-msw.html\">Information\nManagement: A Proposal</a>, by a certain <a href=\"http://dig.csail.mit.edu/breadcrumbs/blog/4\">Tim Berners-Lee</a>.\nGo read it. <em>Now!<br></br></em></p>\n</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://dannyayers.com/2011/01/22/Some-Problems> <http://purl.org/dc/elements/1.1/creator> "Danny Ayers" .
<http://dannyayers.com/2011/01/22/Some-Problems> <http://purl.org/dc/elements/1.1/date> "2011-01-22T16:46:57Z" .
<http://dannyayers.com/2011/01/22/Some-Problems> <http://purl.org/dc/elements/1.1/relation> "http://dannyayers.com/" .
<http://dannyayers.com/2011/01/22/Some-Problems> <http://purl.org/dc/elements/1.1/source> "Raw Blog by Danny Ayers" .
<http://dannyayers.com/2011/01/22/Some-Problems> <http://purl.org/rss/1.0/description> "Georgi Kobilarov has a refreshing post, suggesting Making Linked Data work isnt the problem . I'm inclined to agree with most of what he says. The technology in itself isn't a solution to any problem, rather an enabler to solve problems. While the idea of serendipity is appealing, it isn't very good justification for a huge global commitment of resources. So what kind of problems do we, as living, social and technological organisms wish to solve? To start exploring this space I reckon there are (at least) two general modes of knowledge use. The first is relatively domain-specific, directed by ..." .
<http://dannyayers.com/2011/01/22/Some-Problems> <http://purl.org/rss/1.0/link> "http://dannyayers.com/2011/01/22/Some-Problems" .
<http://dannyayers.com/2011/01/22/Some-Problems> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<p>Georgi Kobilarov has a refreshing post, suggesting <a href=\n\"http://blog.georgikobilarov.com/2011/01/making-linked-data-work-isnt-the-problem/\">\nMaking Linked Data work isnt the problem</a>. I'm inclined to agree\nwith most of what he says. The technology in itself isn't a\nsolution to any problem, rather an enabler to solve problems. While\nthe idea of serendipity is appealing, it isn't very good\njustification for a huge global commitment of resources. So what\nkind of problems do we, as living, social and technological\norganisms wish to solve?<br />\n<br />\nTo start exploring this space I reckon there are (at least) two\ngeneral modes of knowledge use. The first is relatively\ndomain-specific, directed by a set of requirements associated with\na corresponding set of real-world tasks and operations. These I'd\nput under the umbrella of <strong>Applications</strong>, akin to\nthe computer applications we already use but augmented with\nknowledge engineering facilities and access to the Web of Data. As\na shortcut the starting point here is <a href=\n\"http://www.ninebynine.org/SWAD-E/Scenario-HomeNetwork/HomeNetwork/HomeNetwork-347.htm\">\nConnolly's Bane</a>: \"<em>The bane of my existence is doing things\nI know the computer could do for me.</em>\". But in general it goes\nfar further, in that there are plenty of beneficial things we don't\nalready do. A second mode would be ad hoc, fairly immediate,\nunplanned, call it <strong>Just-in-time</strong> problem solving,\nthe kind of thing that we currently turn to search engines\nfor.<br />\n<br />\nAs an example of the <strong>Applications</strong> mode, one of the\nearly drivers for the Web was <strong>e-commerce</strong>. I think\nI'm fairly safe in saying that only the surface of the potential\nthere has been scratched. There's a hint of what can be possible\nwith things like the individual-targetting of Google Ads and Amazon\nrecommendations. In this space the <a href=\n\"http://www.heppnetz.de/projects/goodrelations/\">GoodRelations</a>\nontology is a marvellous baseline. But what we're not really seeing\nyet is the whole supply chain from the manufacturer to consumer\nbeing integrated. Fairly loosely-coupled (as it is today) In one\ndirection there are the financial aspects (<em>\"follow the\nmoney\"</em>), in the other direction is all the transport,\nmanufacturing and processing that go from raw materials to\ndelivered finished product. Within those different parts of the\npipeline there are a whole host of problems relating to technology\ntied together by human and natural resources.<br />\n<br />\nAlongside this commercial world there are macroeconomic and\nmacrosocial systems, those areas traditionally covered by\n<strong>government</strong>. We're already seeing some movement\naround transparency with the various government data projects, but\nI think we're still a very long way from seeing genuinely informed\npolicy and decision making. Reflecting the darker side of\nadvertising right down to commercial spam and taking advantage of\ngeneral ignorance, good governance is seriously compromised by\nself-interest (of individuals and corporations) and misinformation.\nI recently heard a radio programme talking about the UK\nConservative Party's successful \"Broken Britain\" election campaign.\nAn aspect of this was that violent crime was perceived as being on\nthe increase. However the actual statistics suggest that in reality\nthis malaise had actually been declining (see <a href=\n\"http://www.guardian.co.uk/uk/2011/jan/20/murder-rate-lowest-12-years\">\nMurder rate lowest for 12 years</a> <em>\"Home Office figures show\noverall crime fell by 5% in England and Wales\"</em>). Politicians\nwill always lie, but damage is only done when they get away with it\nand aren't held to account with the facts. But I don't really want\nto suggest that prevention of political badness is the goal here,\nrather the encouragement and facilitation of goodness\n(<em>man</em>...).<br />\n<br />\nAnother huge area where there are countless problems to solve is\n<strong>science</strong>. While the Web has vastly improved\ninformation sharing and been a boon to research, I'm not sure the\nunderlying methodologies have changed that much. I'm convinced the\nopen sharing of knowledge at the data level can offer <em>A New\nKind of Science</em> (no hyperbole there!).</p>\n<p>There are plenty of other application domains that could benefit\nfrom a bit of Web-scale knowledge engineering. Ok, I'll name one\nmore bundle: the <strong>Arts</strong>.</p>\n<p>Ok, moving on to the <strong>Just-in-time</strong> mode of\nproblem solving, take a look at the following list (random stuff\nthat came off the top of my head when I woke up this morning).\nImagine how you would solve these problems now, and then think how\nyou might solve them with a thousand programmers at your beck and\ncall. Most of them need something considerably deeper than a\nkeyword/linkrank document search. I've dumped this list over on the\n<a href=\"http://esw.w3.org/ProblemsTheSemanticWebMaySolve\">ESW\nWiki</a>, additions and discussion welcome over there (I still\nhaven't implemented comments on this blog, so if you have a comment\nfor anything either <a href=\"mailto:danny.ayers@gmail.com\">mail\nme</a> or blog it (and mail me) or tweet or use Facebook...).<br />\n<br /></p>\n<ul>\n<li>I'd like to upgrade the computer I use for video editing. My\nbudget is about 300 euro. What should I buy?</li>\n<li>Who should I get to make the soundtrack to my new film?</li>\n<li>I've bought an Ubuntu laptop to replace my old Apple, I'd like\nit to run applications that fulfil all the tasks I have on the old\nmachine. What do I need?</li>\n<li>Should HTML use namespace prefixes?</li>\n<li>Is there a political motivation behind Royal Weddings?</li>\n<li>Who should I vote for?</li>\n<li>Who might make a good (romantic) partner?</li>\n<li>I wish to sell my double glazing products in sub-Saharan\nAfrica, who should I contact?</li>\n<li>Who might make a good (business) partner there?</li>\n<li>I got a mail from someone claiming to be my cousin, asking for\na loan. Should I give them the loan?</li>\n<li>I've got an interesting rash. Should I see a doctor?</li>\n<li>I wish to enlarge my penis. What method is safe and\nreliable?</li>\n</ul>\n<p><em>(Sorry, couldn't resist the last one - but it's a valid\nexample of where you'd need good healthcare data alongside\nreputation and provenance information)</em></p>\n<p>PS. <a title=\"Dan Brickley\" href=\n\"http://danbri.org/words/\">danbri</a> points me to a short 1989/90\ndocument which contains a fairly similar list (<em>minus references\nto genitalia</em>) : <a href=\n\"http://www.w3.org/History/1989/proposal-msw.html\">Information\nManagement: A Proposal</a>, by a certain <a href=\n\"http://dig.csail.mit.edu/breadcrumbs/blog/4\">Tim Berners-Lee</a>.\nGo read it. <em>Now!<br /></em></p>\n</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://dannyayers.com/2011/01/22/Some-Problems> <http://purl.org/rss/1.0/title> "Some Problems" .
<http://dannyayers.com/2011/01/22/Some-Problems> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://decentralyze.com/2011/01/28/can-we-use-lean-startup-methods-to-build-the-semantic-web/> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<p>I\u2019m disappointed in the pace of development of the Semantic Web,\nand I\u2019m optimistic that the Lean Startup ideas can help us move\nthings along faster.</p>\n<p>I\u2019ve been a fan of \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  stats.wordpress img removed by chumpologica  --></p>\n</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://decentralyze.com/2011/01/28/can-we-use-lean-startup-methods-to-build-the-semantic-web/> <http://purl.org/dc/elements/1.1/creator> "Sandro Hawke" .
<http://decentralyze.com/2011/01/28/can-we-use-lean-startup-methods-to-build-the-semantic-web/> <http://purl.org/dc/elements/1.1/date> "2011-01-28T13:17:20Z" .
<http://decentralyze.com/2011/01/28/can-we-use-lean-startup-methods-to-build-the-semantic-web/> <http://purl.org/dc/elements/1.1/relation> "http://decentralyze.com/" .
<http://decentralyze.com/2011/01/28/can-we-use-lean-startup-methods-to-build-the-semantic-web/> <http://purl.org/dc/elements/1.1/source> " Decentralyze \u2013 Programming the Data Cloud by Sandro Hawke" .
<http://decentralyze.com/2011/01/28/can-we-use-lean-startup-methods-to-build-the-semantic-web/> <http://purl.org/rss/1.0/description> "\n \n I\u2019m disappointed in the pace of development of the Semantic Web,\nand I\u2019m optimistic that the Lean Startup ideas can help us move\nthings along faster. \n I\u2019ve been a fan of \n  \n  \n  \n  \n  \n  \n  \n  \n \n" .
<http://decentralyze.com/2011/01/28/can-we-use-lean-startup-methods-to-build-the-semantic-web/> <http://purl.org/rss/1.0/link> "http://decentralyze.com/2011/01/28/can-we-use-lean-startup-methods-to-build-the-semantic-web/" .
<http://decentralyze.com/2011/01/28/can-we-use-lean-startup-methods-to-build-the-semantic-web/> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<p>I\u2019m disappointed in the pace of development of the Semantic Web,\nand I\u2019m optimistic that the Lean Startup ideas can help us move\nthings along faster.</p>\n<p>I\u2019ve been a fan of \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- stats.wordpress img removed by chumpologica --></p>\n</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://decentralyze.com/2011/01/28/can-we-use-lean-startup-methods-to-build-the-semantic-web/> <http://purl.org/rss/1.0/title> "Can we use Lean Startup methods to build the Semantic\nWeb?" .
<http://decentralyze.com/2011/01/28/can-we-use-lean-startup-methods-to-build-the-semantic-web/> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://decentralyze.com/2011/02/02/elevator-pitch-for-the-semantic-web/> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<p>SemanticWeb.com \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  stats.wordpress img removed by chumpologica  --></p>\n</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://decentralyze.com/2011/02/02/elevator-pitch-for-the-semantic-web/> <http://purl.org/dc/elements/1.1/creator> "Sandro Hawke" .
<http://decentralyze.com/2011/02/02/elevator-pitch-for-the-semantic-web/> <http://purl.org/dc/elements/1.1/date> "2011-02-02T15:03:40Z" .
<http://decentralyze.com/2011/02/02/elevator-pitch-for-the-semantic-web/> <http://purl.org/dc/elements/1.1/relation> "http://decentralyze.com/" .
<http://decentralyze.com/2011/02/02/elevator-pitch-for-the-semantic-web/> <http://purl.org/dc/elements/1.1/source> " Decentralyze \u2013 Programming the Data Cloud by Sandro Hawke" .
<http://decentralyze.com/2011/02/02/elevator-pitch-for-the-semantic-web/> <http://purl.org/rss/1.0/description> "\n \n SemanticWeb.com \n  \n  \n  \n  \n  \n  \n  \n  \n \n" .
<http://decentralyze.com/2011/02/02/elevator-pitch-for-the-semantic-web/> <http://purl.org/rss/1.0/link> "http://decentralyze.com/2011/02/02/elevator-pitch-for-the-semantic-web/" .
<http://decentralyze.com/2011/02/02/elevator-pitch-for-the-semantic-web/> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<p>SemanticWeb.com \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- stats.wordpress img removed by chumpologica --></p>\n</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://decentralyze.com/2011/02/02/elevator-pitch-for-the-semantic-web/> <http://purl.org/rss/1.0/title> "Elevator Pitch for the Semantic Web" .
<http://decentralyze.com/2011/02/02/elevator-pitch-for-the-semantic-web/> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://dublincore.org/news/2010/#dcmi-news-20110207-01> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">2011-02-07, As part of a recruitment exercise following the\nindependent incorporation as a not-for-profit Company limited by\nGuarantee in Singapore in December 2008, DCMI is soliciting\napplications for a number of positions in the Executive Office. The\n<a href=\"/news/communications/recruitment/2011-02/\">Executive\nRecruitment Call</a> is open until 6 March 2011.</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://dublincore.org/news/2010/#dcmi-news-20110207-01> <http://purl.org/dc/elements/1.1/creator> "Dublin Core Metadata Initiative" .
<http://dublincore.org/news/2010/#dcmi-news-20110207-01> <http://purl.org/dc/elements/1.1/date> "2011-02-07T23:59Z" .
<http://dublincore.org/news/2010/#dcmi-news-20110207-01> <http://purl.org/dc/elements/1.1/relation> "http://www.dublincore.org/" .
<http://dublincore.org/news/2010/#dcmi-news-20110207-01> <http://purl.org/dc/elements/1.1/source> "Dublin Core Metadata Initiative" .
<http://dublincore.org/news/2010/#dcmi-news-20110207-01> <http://purl.org/rss/1.0/description> "\n 2011-02-07, As part of a recruitment exercise following the\nindependent incorporation as a not-for-profit Company limited by\nGuarantee in Singapore in December 2008, DCMI is soliciting\napplications for a number of positions in the Executive Office. The\n Executive\nRecruitment Call  is open until 6 March 2011. \n" .
<http://dublincore.org/news/2010/#dcmi-news-20110207-01> <http://purl.org/rss/1.0/link> "http://dublincore.org/news/2010/#dcmi-news-20110207-01" .
<http://dublincore.org/news/2010/#dcmi-news-20110207-01> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>2011-02-07, As part of a recruitment exercise following the\nindependent incorporation as a not-for-profit Company limited by\nGuarantee in Singapore in December 2008, DCMI is soliciting\napplications for a number of positions in the Executive Office. The\n<a href=\"/news/communications/recruitment/2011-02/\">Executive\nRecruitment Call</a> is open until 6 March 2011.</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://dublincore.org/news/2010/#dcmi-news-20110207-01> <http://purl.org/rss/1.0/title> "DCMI is soliciting applications for Executive\nOfficers" .
<http://dublincore.org/news/2010/#dcmi-news-20110207-01> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://feedproxy.google.com/~r/Nodalities/~3/jxlMCwEZUW4/linked-spending-data-how-and-why-bother-pt2.php> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<p><img style=\"border-right-width: 0px;border-top-width: 0px;border-bottom-width: 0px;margin-left: 0px;border-left-width: 0px;margin-right: 0px\" title=\"linkedlocalgov\" border=\"0\" alt=\"linkedlocalgov\" align=\"right\" src=\"http://blogs.talis.com/nodalities/files/2011/01/linkedlocalgov.jpg\" width=\"345\" height=\"119\"></img>I started the <a href=\"http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt1.php\">\nprevious post</a> in this mini-series with an assumption \u2013\n..<em>working on the assumption that publishing this</em> [local\ngovernment spending] <em>data is a good thing.</em> That post\nattracted <a href=\"http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt1.php#comments\">\nseveral comments,</a> fortunately none challenging the\nassumption.\u00A0\u00A0 So learning from that experience I am going\nto start with another assumption in this post.\u00A0\n<strong>Publishing Local Authority data, such as local spending\ndata, as \u2018Linked Data\u2019 is also a good thing.</strong>\u00A0 Those\nnew to this mini-series, check back to the <a href=\"http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt1.php\">\nprevious post</a> for my reasoning behind the assertion.</p>\n<p>In this post I am going to be concentrating more on the\n<em>How</em> than the <em>Why Bother</em>.\u00A0</p>\n<p><a href=\"http://spending.lichfielddc.gov.uk/\"><img style=\"border-right-width: 0px;border-top-width: 0px;border-bottom-width: 0px;margin-left: 0px;border-left-width: 0px;margin-right: 0px\" title=\"home\" border=\"0\" alt=\"home\" align=\"left\" src=\"http://blogs.talis.com/nodalities/files/2011/01/home.jpg\" width=\"197\" height=\"133\"></img></a>To help with this I am going to use, some\nof the excellent work that <a href=\"http://www.pezholio.co.uk/\">Stuart Harrison</a> at <a href=\"http://www.lichfielddc.gov.uk\">Lichfield District Council</a> has\ndone in this area, as examples.\u00A0 Take a look at the spending\ndata part of their site: <a title=\"http://spending.lichfielddc.gov.uk/\" href=\"http://spending.lichfielddc.gov.uk/\">spending.lichfielddc.gov.uk/</a>.\u00A0\u00A0\nOn the surface navigating your way around the site looking at\ncouncil spend by type, subject, month, and supplier is the kind of\nexperience a user would expect. Great for a website displaying\ninformation about a single council.\u00A0</p>\n<p>However, it is more than a web site.\u00A0 Inspection of the\nDownload data tab shows that you can get your hands on the source\ndata in csv format.\u00A0 Here is one line, representing a line of\nexpenditure, from that data:</p>\n<p><font size=\"1\" face=\"Courier New\">\"http://statistics.data.gov.uk/doc/local-authority/41UD\",\"Lichfield\nDistrict\nCouncil\",\"2010-04-06\",\"7747\",\"http://spending.lichfielddc.gov.uk/spend/8605670\",\"120.00\",\"BRISTOW\n&amp; SUTOR\",\"401\",\"Revenue Collection\",\"Supplies &amp;\nServices\",\"Bailiff Fees\",\"\"</font></p>\n<p>\u2026 which represents the data displayed on this <a href=\"http://spending.lichfielddc.gov.uk/spend/8605670\">human readable\npage</a>:</p>\n<p><a href=\"http://spending.lichfielddc.gov.uk/spend/8605670\"><img style=\"border-right-width: 0px;float: none;border-top-width: 0px;border-bottom-width: 0px;margin-left: auto;border-left-width: 0px;margin-right: auto\" title=\"Lichfield District Council Spending Data - Details of payment number 8605670\" border=\"0\" alt=\"Lichfield District Council Spending Data - Details of payment number 8605670\" src=\"http://blogs.talis.com/nodalities/files/2011/01/LichfieldDistrictCouncilSpendingDataDetailsofpaymentnumber8605670.jpg\" width=\"180\" height=\"170\"></img></a><br></br>\nLooking through the csv, you can pick out the strings of characters\nfor information such as the date, supplier name, department name\netc.\u00A0 In addition you can pick out a couple of <a href=\"http://en.wikipedia.org/wiki/Uniform_Resource_Identifier\">URI</a>s:</p>\n<ul>\n<li><a href=\"http://statistics.data.gov.uk/doc/local-authority/41UD\">http://statistics.data.gov.uk/doc/local-authority/41UD</a>\n\u2013 The UK Government identifier for Lichfield DC</li>\n<li><a href=\"http://spending.lichfielddc.gov.uk/spend/8605670\">http://spending.lichfielddc.gov.uk/spend/8605670</a>\n\u2013\u00A0 Lichfield\u2019s identifier for this payment</li>\n</ul>\n<p><a href=\"http://blogs.talis.com/nodalities/files/2011/01/LinkedDataforLichfieldDistrictCouncil007Cstatistics.data_.gov_.uk_.jpg\">\n<img style=\"border-right-width: 0px;border-top-width: 0px;border-bottom-width: 0px;margin-left: 0px;border-left-width: 0px;margin-right: 0px\" title=\"Linked Data for Lichfield District Council %007C statistics.data.gov.uk\" border=\"0\" alt=\"Linked Data for Lichfield District Council %007C statistics.data.gov.uk\" align=\"right\" src=\"http://blogs.talis.com/nodalities/files/2011/01/LinkedDataforLichfieldDistrictCouncil007Cstatistics.data_.gov_.uk_thumb.jpg\" width=\"244\" height=\"130\"></img></a> In the context of csv, that\u2019s all\nthese URIs are, identifiers.\u00A0 However because they are http\nURIs you can click through to the address to get more\ninformation.\u00A0 If you do that with your web browser you get a\nhuman readable representation of the data.\u00A0 These sites also\nprovide access to the same data, formatted in RDF, for use by\ndevelopers.</p>\n<p><a href=\"http://blogs.talis.com/nodalities/files/2011/01/Sourceofhttp___spending.lichfielddc.gov_.uk_spend_8605670.rdf_.jpg\">\n<img style=\"border-bottom: 0px;border-left: 0px;margin-left: 0px;border-top: 0px;margin-right: 0px;border-right: 0px\" title=\"Source of http___spending.lichfielddc.gov.uk_spend_8605670.rdf\" border=\"0\" alt=\"Source of http___spending.lichfielddc.gov.uk_spend_8605670.rdf\" align=\"left\" src=\"http://blogs.talis.com/nodalities/files/2011/01/Sourceofhttp___spending.lichfielddc.gov_.uk_spend_8605670.rdf_thumb.jpg\" width=\"324\" height=\"106\"></img></a> You can see that data by adding\n\u2018.rdf\u2019 to the end of the address, thus: <a title=\"http://spending.lichfielddc.gov.uk/spend/8605670.rdf\" href=\"http://spending.lichfielddc.gov.uk/spend/8605670.rdf\">http://spending.lichfielddc.gov.uk/spend/8605670.rdf</a>\nand then selecting the \u2018view source\u2019 option of your browser for the\npage of gobbledegook that you get back.\u00A0\u00A0</p>\n<p>Inspecting the RDF, you will see that most things, except\ndescriptive labels and financial values, are are now identified as\nURIs such as <a title=\"http://spending.lichfielddc.gov.uk/subjective/bailiff-fees\" href=\"http://spending.lichfielddc.gov.uk/subjective/bailiff-fees\">http://spending.lichfielddc.gov.uk/subjective/bailiff-fees</a>\nand <a title=\"http://spending.lichfielddc.gov.uk/invoice/7747\" href=\"http://spending.lichfielddc.gov.uk/invoice/7747\">http://spending.lichfielddc.gov.uk/invoice/7747</a>.\u00A0\nAgain if you follow those links, you will get a human readable\nrepresentation of that resource, and the RDF behind it by adding a\n\u2018.rdf\u2019 suffix.</p>\n<p>The eagle-eyed, inspecting the RDF-XML for Lichfield payment\nnumber 8605670, will have noticed a couple of things.\u00A0\nFirstly, a liberal sprinkling of elements with names like\n<font face=\"Courier New\">payment:expenditureCategory</font> or\n<font face=\"Courier New\">payment:payment.</font> These come from\nthe <a href=\"http://data.gov.uk/resources/payments/reference\">Payments\nOntology</a> as published on data.gov.uk as the recommended way of\nencoding spending, and other payment associated data, in RDF.</p>\n<p>Secondly, you may have spotted that there is no date, or\nsupplier name or identifier.\u00A0 That is because those pieces of\ninformation are attributes associated with a payment \u2013 <a href=\"http://spending.lichfielddc.gov.uk/invoice/7747\">invoice number\n7747</a> in this case.</p>\n<p><a href=\"http://www.bbc.co.uk/nature/life/Whooper_Swan\"><img style=\"border-bottom: 0px;border-left: 0px;margin-left: 0px;border-top: 0px;margin-right: 0px;border-right: 0px\" title=\"BBC - Wildlife Finder - Whooper swan facts, pictures &amp; stunning videos\" border=\"0\" alt=\"BBC - Wildlife Finder - Whooper swan facts, pictures &amp; stunning videos\" align=\"left\" src=\"http://blogs.talis.com/nodalities/files/2011/01/BBCWildlifeFinderWhooperswanfactspicturesstunningvideos.jpg\" width=\"244\" height=\"205\"></img></a> Zooming out from the data for a\nmoment, and looking at the human readable form, you will see that\nmost things, like spend type, invoice number, supplier name, are\nclickable links, which take you through to relevant information\nabout those things \u2013 <a href=\"http://spending.lichfielddc.gov.uk/supplier/rma-design-ltd.html\">address\ndetails &amp; payments</a> for a supplier, <a href=\"http://spending.lichfielddc.gov.uk/type/supplies-services.html\">all\npayments for a category</a> etc.\u00A0 This intuitive natural\nnavigation style often comes as a positive consequence of thinking\nabout data as a set of linked resources instead of the traditional\nrows &amp; columns that we are used to.\u00A0 Another great example\nof this effect can be found on a site such as the <a href=\"http://www.bbc.co.uk/nature/life/Whooper_Swan\">BBC Wildlife\nFinder</a>.\u00A0 That is not to say that you could not have\ncreated such a site without even considering Linked Data, of course\nyou could.\u00A0 However, data modelled as a set of linked\nresources almost self-describes the ideal navigation paths for a\nuser interface to display it to a human.</p>\n<p>The Linked Data practice of modelling data, such as spending\ndata, as a set of linked resources and identifying those resources\nwith URIs [which if looked up will provide information about that\nresource] is equally applicable to those outside of an individual\nauthority.\u00A0 By being able to consume that data, whilst\nunderstanding the relationships within it and having confidence in\nthe authority and persistence of the identifiers within it, a\ndeveloper can approach the task of aggregating, comparing, and\nusing that data in their applications more easily.</p>\n<p>So, how do I (as a local authority) get my data from its raw\nflat csv format, in to RDF with suitable URIs and produce a site\nlike Lichfield\u2019s?\u00A0 The simple answer is that you may not have\nto \u2013 others may help you do some, if not all, of it.\u00A0\u00A0\nWith help from organisations such as <a href=\"http://www.esd.org.uk/esdtoolkit/default.aspx\">esd-toolkit</a>,\n<a href=\"http://openlylocal.com/\">OpenlyLocal</a>, <a href=\"http://whatis.spotlightonspend.org.uk/\">SpotlightOnSpend</a>, and\nwith projects such as the <a href=\"http://blogs.talis.com/platform-consulting/2010/11/12/adding-linked-data-value-to-local-government/\">\nxSpend project</a> we are working on with LGID, many of the\nconversion [from csv], data formatting processes, and aggregation\nare being addressed \u2013 maybe not as quickly or completely as we\nwould like, but they are.\u00A0 As to a human readable web view of\nyour data, you may be able to copy Stuart by taking up the offer of\na free Talis Platform Store and then running your own web server\nwith his code that he hopes to share as open source.\u00A0\nAlternatively it might be worth waiting for others to aggregate\nyour data and provide a way for your citizens to view your\ndata.</p>\n<p>As easy as that then! \u2013 Well not quite, there are some issues\nabout URI naming and creation, and how you bring the data together\nthat still do need addressing by those engaged in this.\u00A0 But\nthat is for Part 3\u2026.</p>\n<!--  feedburner img removed by chumpologica  --></div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://feedproxy.google.com/~r/Nodalities/~3/jxlMCwEZUW4/linked-spending-data-how-and-why-bother-pt2.php> <http://purl.org/dc/elements/1.1/creator> "Talis" .
<http://feedproxy.google.com/~r/Nodalities/~3/jxlMCwEZUW4/linked-spending-data-how-and-why-bother-pt2.php> <http://purl.org/dc/elements/1.1/date> "2011-01-28T16:39:20Z" .
<http://feedproxy.google.com/~r/Nodalities/~3/jxlMCwEZUW4/linked-spending-data-how-and-why-bother-pt2.php> <http://purl.org/dc/elements/1.1/relation> "http://blogs.talis.com/nodalities/" .
<http://feedproxy.google.com/~r/Nodalities/~3/jxlMCwEZUW4/linked-spending-data-how-and-why-bother-pt2.php> <http://purl.org/dc/elements/1.1/source> "Nodalities by Talis" .
<http://feedproxy.google.com/~r/Nodalities/~3/jxlMCwEZUW4/linked-spending-data-how-and-why-bother-pt2.php> <http://purl.org/rss/1.0/description> "I started the previous post in this mini-series with an assumption \u2013 .. working on the assumption that publishing this [local government spending] data is a good thing. That post attracted several comments, fortunately none challenging the assumption.&#160;&#160; So learning from that experience I am going to start with another assumption in this post.&#160; Publishing Local Authority data, such as local spending data, as \u2018Linked Data\u2019 is also a good thing. &#160; Those new to this mini-series, check back to the previous post for my reasoning behind the assertion. In this post I am going to be concentrating more on ..." .
<http://feedproxy.google.com/~r/Nodalities/~3/jxlMCwEZUW4/linked-spending-data-how-and-why-bother-pt2.php> <http://purl.org/rss/1.0/link> "http://feedproxy.google.com/~r/Nodalities/~3/jxlMCwEZUW4/linked-spending-data-how-and-why-bother-pt2.php" .
<http://feedproxy.google.com/~r/Nodalities/~3/jxlMCwEZUW4/linked-spending-data-how-and-why-bother-pt2.php> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<p><img style=\n\"border-right-width: 0px;border-top-width: 0px;border-bottom-width: 0px;margin-left: 0px;border-left-width: 0px;margin-right: 0px\"\ntitle=\"linkedlocalgov\" border=\"0\" alt=\"linkedlocalgov\" align=\n\"right\" src=\n\"http://blogs.talis.com/nodalities/files/2011/01/linkedlocalgov.jpg\"\nwidth=\"345\" height=\"119\" />I started the <a href=\n\"http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt1.php\">\nprevious post</a> in this mini-series with an assumption \u2013\n..<em>working on the assumption that publishing this</em> [local\ngovernment spending] <em>data is a good thing.</em> That post\nattracted <a href=\n\"http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt1.php#comments\">\nseveral comments,</a> fortunately none challenging the\nassumption.&#160;&#160; So learning from that experience I am going\nto start with another assumption in this post.&#160;\n<strong>Publishing Local Authority data, such as local spending\ndata, as \u2018Linked Data\u2019 is also a good thing.</strong>&#160; Those\nnew to this mini-series, check back to the <a href=\n\"http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt1.php\">\nprevious post</a> for my reasoning behind the assertion.</p>\n<p>In this post I am going to be concentrating more on the\n<em>How</em> than the <em>Why Bother</em>.&#160;</p>\n<p><a href=\"http://spending.lichfielddc.gov.uk/\"><img style=\n\"border-right-width: 0px;border-top-width: 0px;border-bottom-width: 0px;margin-left: 0px;border-left-width: 0px;margin-right: 0px\"\ntitle=\"home\" border=\"0\" alt=\"home\" align=\"left\" src=\n\"http://blogs.talis.com/nodalities/files/2011/01/home.jpg\" width=\n\"197\" height=\"133\" /></a>To help with this I am going to use, some\nof the excellent work that <a href=\n\"http://www.pezholio.co.uk/\">Stuart Harrison</a> at <a href=\n\"http://www.lichfielddc.gov.uk\">Lichfield District Council</a> has\ndone in this area, as examples.&#160; Take a look at the spending\ndata part of their site: <a title=\n\"http://spending.lichfielddc.gov.uk/\" href=\n\"http://spending.lichfielddc.gov.uk/\">spending.lichfielddc.gov.uk/</a>.&#160;&#160;\nOn the surface navigating your way around the site looking at\ncouncil spend by type, subject, month, and supplier is the kind of\nexperience a user would expect. Great for a website displaying\ninformation about a single council.&#160;</p>\n<p>However, it is more than a web site.&#160; Inspection of the\nDownload data tab shows that you can get your hands on the source\ndata in csv format.&#160; Here is one line, representing a line of\nexpenditure, from that data:</p>\n<p><font size=\"1\" face=\n\"Courier New\">\"http://statistics.data.gov.uk/doc/local-authority/41UD\",\"Lichfield\nDistrict\nCouncil\",\"2010-04-06\",\"7747\",\"http://spending.lichfielddc.gov.uk/spend/8605670\",\"120.00\",\"BRISTOW\n&amp; SUTOR\",\"401\",\"Revenue Collection\",\"Supplies &amp;\nServices\",\"Bailiff Fees\",\"\"</font></p>\n<p>\u2026 which represents the data displayed on this <a href=\n\"http://spending.lichfielddc.gov.uk/spend/8605670\">human readable\npage</a>:</p>\n<p><a href=\n\"http://spending.lichfielddc.gov.uk/spend/8605670\"><img style=\n\"border-right-width: 0px;float: none;border-top-width: 0px;border-bottom-width: 0px;margin-left: auto;border-left-width: 0px;margin-right: auto\"\ntitle=\n\"Lichfield District Council Spending Data - Details of payment number 8605670\"\nborder=\"0\" alt=\n\"Lichfield District Council Spending Data - Details of payment number 8605670\"\nsrc=\n\"http://blogs.talis.com/nodalities/files/2011/01/LichfieldDistrictCouncilSpendingDataDetailsofpaymentnumber8605670.jpg\"\nwidth=\"180\" height=\"170\" /></a><br />\nLooking through the csv, you can pick out the strings of characters\nfor information such as the date, supplier name, department name\netc.&#160; In addition you can pick out a couple of <a href=\n\"http://en.wikipedia.org/wiki/Uniform_Resource_Identifier\">URI</a>s:</p>\n<ul>\n<li><a href=\n\"http://statistics.data.gov.uk/doc/local-authority/41UD\">http://statistics.data.gov.uk/doc/local-authority/41UD</a>\n\u2013 The UK Government identifier for Lichfield DC</li>\n<li><a href=\n\"http://spending.lichfielddc.gov.uk/spend/8605670\">http://spending.lichfielddc.gov.uk/spend/8605670</a>\n\u2013&#160; Lichfield\u2019s identifier for this payment</li>\n</ul>\n<p><a href=\n\"http://blogs.talis.com/nodalities/files/2011/01/LinkedDataforLichfieldDistrictCouncil007Cstatistics.data_.gov_.uk_.jpg\">\n<img style=\n\"border-right-width: 0px;border-top-width: 0px;border-bottom-width: 0px;margin-left: 0px;border-left-width: 0px;margin-right: 0px\"\ntitle=\n\"Linked Data for Lichfield District Council %007C statistics.data.gov.uk\"\nborder=\"0\" alt=\n\"Linked Data for Lichfield District Council %007C statistics.data.gov.uk\"\nalign=\"right\" src=\n\"http://blogs.talis.com/nodalities/files/2011/01/LinkedDataforLichfieldDistrictCouncil007Cstatistics.data_.gov_.uk_thumb.jpg\"\nwidth=\"244\" height=\"130\" /></a> In the context of csv, that\u2019s all\nthese URIs are, identifiers.&#160; However because they are http\nURIs you can click through to the address to get more\ninformation.&#160; If you do that with your web browser you get a\nhuman readable representation of the data.&#160; These sites also\nprovide access to the same data, formatted in RDF, for use by\ndevelopers.</p>\n<p><a href=\n\"http://blogs.talis.com/nodalities/files/2011/01/Sourceofhttp___spending.lichfielddc.gov_.uk_spend_8605670.rdf_.jpg\">\n<img style=\n\"border-bottom: 0px;border-left: 0px;margin-left: 0px;border-top: 0px;margin-right: 0px;border-right: 0px\"\ntitle=\n\"Source of http___spending.lichfielddc.gov.uk_spend_8605670.rdf\"\nborder=\"0\" alt=\n\"Source of http___spending.lichfielddc.gov.uk_spend_8605670.rdf\"\nalign=\"left\" src=\n\"http://blogs.talis.com/nodalities/files/2011/01/Sourceofhttp___spending.lichfielddc.gov_.uk_spend_8605670.rdf_thumb.jpg\"\nwidth=\"324\" height=\"106\" /></a> You can see that data by adding\n\u2018.rdf\u2019 to the end of the address, thus: <a title=\n\"http://spending.lichfielddc.gov.uk/spend/8605670.rdf\" href=\n\"http://spending.lichfielddc.gov.uk/spend/8605670.rdf\">http://spending.lichfielddc.gov.uk/spend/8605670.rdf</a>\nand then selecting the \u2018view source\u2019 option of your browser for the\npage of gobbledegook that you get back.&#160;&#160;</p>\n<p>Inspecting the RDF, you will see that most things, except\ndescriptive labels and financial values, are are now identified as\nURIs such as <a title=\n\"http://spending.lichfielddc.gov.uk/subjective/bailiff-fees\" href=\n\"http://spending.lichfielddc.gov.uk/subjective/bailiff-fees\">http://spending.lichfielddc.gov.uk/subjective/bailiff-fees</a>\nand <a title=\"http://spending.lichfielddc.gov.uk/invoice/7747\"\nhref=\"http://spending.lichfielddc.gov.uk/invoice/7747\">http://spending.lichfielddc.gov.uk/invoice/7747</a>.&#160;\nAgain if you follow those links, you will get a human readable\nrepresentation of that resource, and the RDF behind it by adding a\n\u2018.rdf\u2019 suffix.</p>\n<p>The eagle-eyed, inspecting the RDF-XML for Lichfield payment\nnumber 8605670, will have noticed a couple of things.&#160;\nFirstly, a liberal sprinkling of elements with names like\n<font face=\"Courier New\">payment:expenditureCategory</font> or\n<font face=\"Courier New\">payment:payment.</font> These come from\nthe <a href=\n\"http://data.gov.uk/resources/payments/reference\">Payments\nOntology</a> as published on data.gov.uk as the recommended way of\nencoding spending, and other payment associated data, in RDF.</p>\n<p>Secondly, you may have spotted that there is no date, or\nsupplier name or identifier.&#160; That is because those pieces of\ninformation are attributes associated with a payment \u2013 <a href=\n\"http://spending.lichfielddc.gov.uk/invoice/7747\">invoice number\n7747</a> in this case.</p>\n<p><a href=\n\"http://www.bbc.co.uk/nature/life/Whooper_Swan\"><img style=\n\"border-bottom: 0px;border-left: 0px;margin-left: 0px;border-top: 0px;margin-right: 0px;border-right: 0px\"\ntitle=\n\"BBC - Wildlife Finder - Whooper swan facts, pictures &amp; stunning videos\"\nborder=\"0\" alt=\n\"BBC - Wildlife Finder - Whooper swan facts, pictures &amp; stunning videos\"\nalign=\"left\" src=\n\"http://blogs.talis.com/nodalities/files/2011/01/BBCWildlifeFinderWhooperswanfactspicturesstunningvideos.jpg\"\nwidth=\"244\" height=\"205\" /></a> Zooming out from the data for a\nmoment, and looking at the human readable form, you will see that\nmost things, like spend type, invoice number, supplier name, are\nclickable links, which take you through to relevant information\nabout those things \u2013 <a href=\n\"http://spending.lichfielddc.gov.uk/supplier/rma-design-ltd.html\">address\ndetails &amp; payments</a> for a supplier, <a href=\n\"http://spending.lichfielddc.gov.uk/type/supplies-services.html\">all\npayments for a category</a> etc.&#160; This intuitive natural\nnavigation style often comes as a positive consequence of thinking\nabout data as a set of linked resources instead of the traditional\nrows &amp; columns that we are used to.&#160; Another great example\nof this effect can be found on a site such as the <a href=\n\"http://www.bbc.co.uk/nature/life/Whooper_Swan\">BBC Wildlife\nFinder</a>.&#160; That is not to say that you could not have\ncreated such a site without even considering Linked Data, of course\nyou could.&#160; However, data modelled as a set of linked\nresources almost self-describes the ideal navigation paths for a\nuser interface to display it to a human.</p>\n<p>The Linked Data practice of modelling data, such as spending\ndata, as a set of linked resources and identifying those resources\nwith URIs [which if looked up will provide information about that\nresource] is equally applicable to those outside of an individual\nauthority.&#160; By being able to consume that data, whilst\nunderstanding the relationships within it and having confidence in\nthe authority and persistence of the identifiers within it, a\ndeveloper can approach the task of aggregating, comparing, and\nusing that data in their applications more easily.</p>\n<p>So, how do I (as a local authority) get my data from its raw\nflat csv format, in to RDF with suitable URIs and produce a site\nlike Lichfield\u2019s?&#160; The simple answer is that you may not have\nto \u2013 others may help you do some, if not all, of it.&#160;&#160;\nWith help from organisations such as <a href=\n\"http://www.esd.org.uk/esdtoolkit/default.aspx\">esd-toolkit</a>,\n<a href=\"http://openlylocal.com/\">OpenlyLocal</a>, <a href=\n\"http://whatis.spotlightonspend.org.uk/\">SpotlightOnSpend</a>, and\nwith projects such as the <a href=\n\"http://blogs.talis.com/platform-consulting/2010/11/12/adding-linked-data-value-to-local-government/\">\nxSpend project</a> we are working on with LGID, many of the\nconversion [from csv], data formatting processes, and aggregation\nare being addressed \u2013 maybe not as quickly or completely as we\nwould like, but they are.&#160; As to a human readable web view of\nyour data, you may be able to copy Stuart by taking up the offer of\na free Talis Platform Store and then running your own web server\nwith his code that he hopes to share as open source.&#160;\nAlternatively it might be worth waiting for others to aggregate\nyour data and provide a way for your citizens to view your\ndata.</p>\n<p>As easy as that then! \u2013 Well not quite, there are some issues\nabout URI naming and creation, and how you bring the data together\nthat still do need addressing by those engaged in this.&#160; But\nthat is for Part 3\u2026.</p>\n<!-- feedburner img removed by chumpologica --></div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://feedproxy.google.com/~r/Nodalities/~3/jxlMCwEZUW4/linked-spending-data-how-and-why-bother-pt2.php> <http://purl.org/rss/1.0/title> "Linked Spending Data \u2013 How and Why Bother Pt2" .
<http://feedproxy.google.com/~r/Nodalities/~3/jxlMCwEZUW4/linked-spending-data-how-and-why-bother-pt2.php> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://feedproxy.google.com/~r/Nodalities/~3/qxI6zmzBTeU/linked-spending-data-how-and-why-bother-pt1.php> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<p><img style=\"border-right-width: 0px;border-top-width: 0px;border-bottom-width: 0px;margin-left: 0px;border-left-width: 0px;margin-right: 0px\" title=\"linkedlocalgov\" border=\"0\" alt=\"linkedlocalgov\" align=\"right\" src=\"http://blogs.talis.com/nodalities/files/2011/01/linkedlocalgov.jpg\" width=\"345\" height=\"119\"></img>National Government instructing the 300+\nUK Local Authorities to publish \u201C<em>New items of local government\nspending over \u00A3500 to be published on a council-by-council basis\nfrom January 2011</em>\u201D has had the proponents of both open, and\nclosed, data excited over the last few months.\u00A0 For this mini\nseries of posts I am working on the assumption that publishing this\ndata is a good thing, because I want to move on and assert that\n[when publishing] one format/method to make this data available\nshould be <a href=\"http://linkeddata.org/\">Linked Data</a>.</p>\n<p>This immediately brings me to the <strong>Why Bother</strong>?\nbit. This itself breaks in to two connected questions \u2013 <em>Why\nbother publishing any local authority data as Linked Data?</em> and\n<em>Why bother using the, unexciting simplistic, spending data as a\na place to start?</em>\u00A0</p>\n<p>I believe that spending data is a great place to start, both for\npublishing local government data and for making such data\nlinked.\u00A0 Someone at national level was quite astute choosing\nspending as a starting point.\u00A0 To comply with the instruction\nall an authority has to do is produce a file containing five basic\nelements for each payment transaction: An Id, a date, a\ncategory,\u00A0 a payee, and an amount.\u00A0 At a very basic level\nit is very easy to measure if an authority has done that or\nnot.</p>\n<p><a href=\"http://data.gov.uk/blog/local-spending-data-guidance\">Guidance\nfrom data.gov.uk</a> expands on this a little by mandating the\nfollowing:</p>\n<table border=\"0\" cellspacing=\"0\" cellpadding=\"2\" width=\"574\">\n<tbody>\n<tr>\n<td valign=\"top\" width=\"25\">\u00A0</td>\n<td valign=\"top\" width=\"174\">Body</td>\n<td valign=\"top\" width=\"373\">This should be the URI that represents\n(<em>or more properly \u2018identifies\u2019 \u2013 see below</em>) the local\nauthority at statistics.data.gov.uk.<br></br>\neg. <a title=\"http://statistics.data.gov.uk/id/local-authority-district/00CN\" href=\"http://statistics.data.gov.uk/id/local-authority-district/00CN\">http://statistics.data.gov.uk/id/local-authority-district/00CN</a></td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"25\">\u00A0</td>\n<td valign=\"top\" width=\"174\">Date</td>\n<td valign=\"top\" width=\"373\">Should ideally be the payment date as\nrecorded in purchase or general ledger</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"25\">\u00A0</td>\n<td valign=\"top\" width=\"174\">Transaction number</td>\n<td valign=\"top\" width=\"373\">To identify within authority\u2019s system,\nfor future reference</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"25\">\u00A0</td>\n<td valign=\"top\" width=\"174\">Amount</td>\n<td valign=\"top\" width=\"373\">In Sterling recorded in finance\nsystem</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"25\">\u00A0</td>\n<td valign=\"top\" width=\"174\">Supplier Details</td>\n<td valign=\"top\" width=\"373\">Name and individual authority id for\nsupplier plus where possible Companies House, Charity Registration,\nor other recognised identifier</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"25\">\u00A0</td>\n<td valign=\"top\" width=\"174\">Expense Area</td>\n<td valign=\"top\" width=\"373\">The part of the authority that spent\nthe amount</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"25\">\u00A0</td>\n<td valign=\"top\" width=\"174\">Service Categorization</td>\n<td valign=\"top\" width=\"373\">\n<p align=\"left\">Depending on the accounts system this may be easy\nor quite difficult. There are two candidates for categorization \u2013\nCIPFA\u2019s BVACOP classification and the Proclass procurement\nclassification system.</p>\n</td>\n</tr>\n</tbody>\n</table>\n<p>\u2026 a little more onerous, possibly around the areas of\nidentifying company numbers and Service Categorization, but not\nmuch room for discussion/interpretation.</p>\n<p>As to the file formats to publish data, the <a href=\"http://data.gov.uk/blog/local-spending-data-guidance\">same advice\nmandates</a>: <em>The files are to be published in CSV file format\n-</em> supplemented by \u2013 <em>Authorities may wish to publish the\ndata in additional formats as well as the CSV files (e.g. linked\ndata, XML, or PDFs for casual browsers). There is no reason why\nthey should not do this, but this is not a substitute for the CSV\nfiles.</em></p>\n<p>So fairy clear, and measurable, then. You either have published\nyour required basic elements of data in a CSV format file, or you\nhave not.\u00A0 Couple this with the political ambitions and drive\nbehind the <a href=\"http://www.number10.gov.uk/news/latest-news/2010/10/transparency-agenda-forges-ahead-56270\">\nGovernment\u2019s Transparency Agenda</a>, and local authorities will\nhave difficulty in not delivering this.\u00A0 Although <a href=\"http://www.guardian.co.uk/news/datablog/2010/sep/10/local-council-spending-over-500-list\">\nsome are being a bit tardy</a> and others seem <a href=\"http://www.birmingham.gov.uk/payment-data\">reticent to publish in\nformats other than pdf</a>.</p>\n<p>OK so why bother with applying Linked Data techniques to this\n[boring] spending data?\u00A0 Well, precisely because it is simple\ndata, it is comparatively easy to do, and because everybody is\npublishing this data the benefits of linking should soon become\napparent.\u00A0\u00A0 Linked Data is all about identifying things\nand concepts, giving them a globally addressable identifiers (URIs)\nand then describing the relationships between them.\u00A0\u00A0</p>\n<p>For those new to Linked Data, the use of URIs as identifiers\noften causes confusion.\u00A0\u00A0 A URI, such as\u00A0\n<em>http://statistics.data.gov.uk/id/local-authority-district/00CN</em>,\nis a string of characters that is as much an identifier as the\npayroll number on your pay-check, or a barcode on a can of\nbeans.\u00A0 It has couple of attributes that make it different\nfrom traditional identifiers.\u00A0 Firstly, the first part of it\nis created from the Internet domain name of the organisation that\npublish the identifier.\u00A0 This means that it can be globally\nunique. Theoretically you could have the same payroll number as the\nthe barcode number on my can of beans \u2013 adding the domain avoids\nany possibility of confusion.\u00A0 Secondly, because the domain is\nprefixed by <em>http://</em> it gives the publisher the ability to\nprovide information about the thing identified, using well\nestablished web technologies.\u00A0 In this particular example,\n<em><a href=\"http://statistics.data.gov.uk/id/local-authority-district/00CN\">http://statistics.data.gov.uk/id/local-authority-district/00CN</a></em>\nis the identifier for Birmingham City Council, if you click on it\n[using it as an internet address] data.gov.uk will supply you\ninformation about it \u2013 name, location, type of authority etc.</p>\n<p>Following this approach, creating URI identifiers for suppliers,\ncategories, and individual payments and defining the relationships\nbetween them using the <a href=\"http://data.gov.uk/resources/payments/reference\">Payments\nOntology</a> (more on this when I come on to the\n<em>How</em>)\u00A0 leads to a Linked Data representation of the\ndata.\u00A0 In technical terms a comparatively easy step using\nscripts etc.</p>\n<p>By publishing Linked Spending Data and loading it in to a Linked\nData store, as <a href=\"http://blogs.talis.com/platform-consulting/2011/01/17/lichfield-dc-opens-up-spending-data/\">\nLichfield DC have done</a>, it becomes possible to query it, to\nidentifies things like all payments for a supplier; or suppliers\nfor a category, etc.</p>\n<p>If you then load data for several authorities in to an aggregate\nstore, <a href=\"http://blogs.talis.com/platform-consulting/2010/11/12/adding-linked-data-value-to-local-government/\">\nas we are doing in partnership with LGID</a>, those queries can\nidentify patterns or comparisons across authorities.\u00A0 Which\nbrings me to \u2026.</p>\n<p><em><a href=\"http://blogs.talis.com/nodalities/files/2011/01/linkeddata_blue.jpg\">\n<img style=\"border-right-width: 0px;border-top-width: 0px;border-bottom-width: 0px;margin-left: 0px;border-left-width: 0px;margin-right: 0px\" title=\"linkeddata_blue\" border=\"0\" alt=\"linkeddata_blue\" align=\"left\" src=\"http://blogs.talis.com/nodalities/files/2011/01/linkeddata_blue_thumb.jpg\" width=\"106\" height=\"116\"></img></a> Why bother publishing any local\nauthority data as Linked Data?</em>\u00A0 Publishing as Linked Data\nenables an authority\u2019s data to be meshed with data from other\nauthorities and other sources such as national government.\u00A0\nFor example, the data held at statistics.data.gov.uk includes which\ncounty an authority is located within.\u00A0 By using that data as\npart of a query, it would for instance be possible to identify the\ntotal spend, by category, for all authorities in a county such as\nthe West Midlands.\u00A0\u00A0</p>\n<p>As more authority data sets are published, sharing the same\nidentifiers for authority category etc., they will naturally link\ntogether, enabling the natural navigation of the information\nbetween council departments, services, costs, suppliers, etc.\u00A0\nOnce this step has been taken and the dust settles a bit, this\nfoundation of linked data should become an open data\u00A0 platform\nfor innovating development and the publishing of other data that\nwill link in with this basic but important financial data.</p>\n<p>There are however some more technical issues, URI naming,\naggregation, etc.,\u00A0 to be overcome or at least addressed in\nthe short term to get us to that foundation.\u00A0 I will cover\nthese in part 2 of this series.</p>\n<!--  feedburner img removed by chumpologica  --></div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://feedproxy.google.com/~r/Nodalities/~3/qxI6zmzBTeU/linked-spending-data-how-and-why-bother-pt1.php> <http://purl.org/dc/elements/1.1/creator> "Talis" .
<http://feedproxy.google.com/~r/Nodalities/~3/qxI6zmzBTeU/linked-spending-data-how-and-why-bother-pt1.php> <http://purl.org/dc/elements/1.1/date> "2011-01-21T14:52:06Z" .
<http://feedproxy.google.com/~r/Nodalities/~3/qxI6zmzBTeU/linked-spending-data-how-and-why-bother-pt1.php> <http://purl.org/dc/elements/1.1/relation> "http://blogs.talis.com/nodalities/" .
<http://feedproxy.google.com/~r/Nodalities/~3/qxI6zmzBTeU/linked-spending-data-how-and-why-bother-pt1.php> <http://purl.org/dc/elements/1.1/source> "Nodalities by Talis" .
<http://feedproxy.google.com/~r/Nodalities/~3/qxI6zmzBTeU/linked-spending-data-how-and-why-bother-pt1.php> <http://purl.org/rss/1.0/description> "National Government instructing the 300+ UK Local Authorities to publish \u201C New items of local government spending over \u00A3500 to be published on a council-by-council basis from January 2011 \u201D has had the proponents of both open, and closed, data excited over the last few months.&#160; For this mini series of posts I am working on the assumption that publishing this data is a good thing, because I want to move on and assert that [when publishing] one format/method to make this data available should be Linked Data . This immediately brings me to the Why Bother ? bit. This ..." .
<http://feedproxy.google.com/~r/Nodalities/~3/qxI6zmzBTeU/linked-spending-data-how-and-why-bother-pt1.php> <http://purl.org/rss/1.0/link> "http://feedproxy.google.com/~r/Nodalities/~3/qxI6zmzBTeU/linked-spending-data-how-and-why-bother-pt1.php" .
<http://feedproxy.google.com/~r/Nodalities/~3/qxI6zmzBTeU/linked-spending-data-how-and-why-bother-pt1.php> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<p><img style=\n\"border-right-width: 0px;border-top-width: 0px;border-bottom-width: 0px;margin-left: 0px;border-left-width: 0px;margin-right: 0px\"\ntitle=\"linkedlocalgov\" border=\"0\" alt=\"linkedlocalgov\" align=\n\"right\" src=\n\"http://blogs.talis.com/nodalities/files/2011/01/linkedlocalgov.jpg\"\nwidth=\"345\" height=\"119\" />National Government instructing the 300+\nUK Local Authorities to publish \u201C<em>New items of local government\nspending over \u00A3500 to be published on a council-by-council basis\nfrom January 2011</em>\u201D has had the proponents of both open, and\nclosed, data excited over the last few months.&#160; For this mini\nseries of posts I am working on the assumption that publishing this\ndata is a good thing, because I want to move on and assert that\n[when publishing] one format/method to make this data available\nshould be <a href=\"http://linkeddata.org/\">Linked Data</a>.</p>\n<p>This immediately brings me to the <strong>Why Bother</strong>?\nbit. This itself breaks in to two connected questions \u2013 <em>Why\nbother publishing any local authority data as Linked Data?</em> and\n<em>Why bother using the, unexciting simplistic, spending data as a\na place to start?</em>&#160;</p>\n<p>I believe that spending data is a great place to start, both for\npublishing local government data and for making such data\nlinked.&#160; Someone at national level was quite astute choosing\nspending as a starting point.&#160; To comply with the instruction\nall an authority has to do is produce a file containing five basic\nelements for each payment transaction: An Id, a date, a\ncategory,&#160; a payee, and an amount.&#160; At a very basic level\nit is very easy to measure if an authority has done that or\nnot.</p>\n<p><a href=\n\"http://data.gov.uk/blog/local-spending-data-guidance\">Guidance\nfrom data.gov.uk</a> expands on this a little by mandating the\nfollowing:</p>\n<table border=\"0\" cellspacing=\"0\" cellpadding=\"2\" width=\"574\">\n<tbody>\n<tr>\n<td valign=\"top\" width=\"25\">&#160;</td>\n<td valign=\"top\" width=\"174\">Body</td>\n<td valign=\"top\" width=\"373\">This should be the URI that represents\n(<em>or more properly \u2018identifies\u2019 \u2013 see below</em>) the local\nauthority at statistics.data.gov.uk.<br />\neg. <a title=\n\"http://statistics.data.gov.uk/id/local-authority-district/00CN\"\nhref=\n\"http://statistics.data.gov.uk/id/local-authority-district/00CN\">http://statistics.data.gov.uk/id/local-authority-district/00CN</a></td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"25\">&#160;</td>\n<td valign=\"top\" width=\"174\">Date</td>\n<td valign=\"top\" width=\"373\">Should ideally be the payment date as\nrecorded in purchase or general ledger</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"25\">&#160;</td>\n<td valign=\"top\" width=\"174\">Transaction number</td>\n<td valign=\"top\" width=\"373\">To identify within authority\u2019s system,\nfor future reference</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"25\">&#160;</td>\n<td valign=\"top\" width=\"174\">Amount</td>\n<td valign=\"top\" width=\"373\">In Sterling recorded in finance\nsystem</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"25\">&#160;</td>\n<td valign=\"top\" width=\"174\">Supplier Details</td>\n<td valign=\"top\" width=\"373\">Name and individual authority id for\nsupplier plus where possible Companies House, Charity Registration,\nor other recognised identifier</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"25\">&#160;</td>\n<td valign=\"top\" width=\"174\">Expense Area</td>\n<td valign=\"top\" width=\"373\">The part of the authority that spent\nthe amount</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"25\">&#160;</td>\n<td valign=\"top\" width=\"174\">Service Categorization</td>\n<td valign=\"top\" width=\"373\">\n<p align=\"left\">Depending on the accounts system this may be easy\nor quite difficult. There are two candidates for categorization \u2013\nCIPFA\u2019s BVACOP classification and the Proclass procurement\nclassification system.</p>\n</td>\n</tr>\n</tbody>\n</table>\n<p>\u2026 a little more onerous, possibly around the areas of\nidentifying company numbers and Service Categorization, but not\nmuch room for discussion/interpretation.</p>\n<p>As to the file formats to publish data, the <a href=\n\"http://data.gov.uk/blog/local-spending-data-guidance\">same advice\nmandates</a>: <em>The files are to be published in CSV file format\n-</em> supplemented by \u2013 <em>Authorities may wish to publish the\ndata in additional formats as well as the CSV files (e.g. linked\ndata, XML, or PDFs for casual browsers). There is no reason why\nthey should not do this, but this is not a substitute for the CSV\nfiles.</em></p>\n<p>So fairy clear, and measurable, then. You either have published\nyour required basic elements of data in a CSV format file, or you\nhave not.&#160; Couple this with the political ambitions and drive\nbehind the <a href=\n\"http://www.number10.gov.uk/news/latest-news/2010/10/transparency-agenda-forges-ahead-56270\">\nGovernment\u2019s Transparency Agenda</a>, and local authorities will\nhave difficulty in not delivering this.&#160; Although <a href=\n\"http://www.guardian.co.uk/news/datablog/2010/sep/10/local-council-spending-over-500-list\">\nsome are being a bit tardy</a> and others seem <a href=\n\"http://www.birmingham.gov.uk/payment-data\">reticent to publish in\nformats other than pdf</a>.</p>\n<p>OK so why bother with applying Linked Data techniques to this\n[boring] spending data?&#160; Well, precisely because it is simple\ndata, it is comparatively easy to do, and because everybody is\npublishing this data the benefits of linking should soon become\napparent.&#160;&#160; Linked Data is all about identifying things\nand concepts, giving them a globally addressable identifiers (URIs)\nand then describing the relationships between them.&#160;&#160;</p>\n<p>For those new to Linked Data, the use of URIs as identifiers\noften causes confusion.&#160;&#160; A URI, such as&#160;\n<em>http://statistics.data.gov.uk/id/local-authority-district/00CN</em>,\nis a string of characters that is as much an identifier as the\npayroll number on your pay-check, or a barcode on a can of\nbeans.&#160; It has couple of attributes that make it different\nfrom traditional identifiers.&#160; Firstly, the first part of it\nis created from the Internet domain name of the organisation that\npublish the identifier.&#160; This means that it can be globally\nunique. Theoretically you could have the same payroll number as the\nthe barcode number on my can of beans \u2013 adding the domain avoids\nany possibility of confusion.&#160; Secondly, because the domain is\nprefixed by <em>http://</em> it gives the publisher the ability to\nprovide information about the thing identified, using well\nestablished web technologies.&#160; In this particular example,\n<em><a href=\n\"http://statistics.data.gov.uk/id/local-authority-district/00CN\">http://statistics.data.gov.uk/id/local-authority-district/00CN</a></em>\nis the identifier for Birmingham City Council, if you click on it\n[using it as an internet address] data.gov.uk will supply you\ninformation about it \u2013 name, location, type of authority etc.</p>\n<p>Following this approach, creating URI identifiers for suppliers,\ncategories, and individual payments and defining the relationships\nbetween them using the <a href=\n\"http://data.gov.uk/resources/payments/reference\">Payments\nOntology</a> (more on this when I come on to the\n<em>How</em>)&#160; leads to a Linked Data representation of the\ndata.&#160; In technical terms a comparatively easy step using\nscripts etc.</p>\n<p>By publishing Linked Spending Data and loading it in to a Linked\nData store, as <a href=\n\"http://blogs.talis.com/platform-consulting/2011/01/17/lichfield-dc-opens-up-spending-data/\">\nLichfield DC have done</a>, it becomes possible to query it, to\nidentifies things like all payments for a supplier; or suppliers\nfor a category, etc.</p>\n<p>If you then load data for several authorities in to an aggregate\nstore, <a href=\n\"http://blogs.talis.com/platform-consulting/2010/11/12/adding-linked-data-value-to-local-government/\">\nas we are doing in partnership with LGID</a>, those queries can\nidentify patterns or comparisons across authorities.&#160; Which\nbrings me to \u2026.</p>\n<p><em><a href=\n\"http://blogs.talis.com/nodalities/files/2011/01/linkeddata_blue.jpg\">\n<img style=\n\"border-right-width: 0px;border-top-width: 0px;border-bottom-width: 0px;margin-left: 0px;border-left-width: 0px;margin-right: 0px\"\ntitle=\"linkeddata_blue\" border=\"0\" alt=\"linkeddata_blue\" align=\n\"left\" src=\n\"http://blogs.talis.com/nodalities/files/2011/01/linkeddata_blue_thumb.jpg\"\nwidth=\"106\" height=\"116\" /></a> Why bother publishing any local\nauthority data as Linked Data?</em>&#160; Publishing as Linked Data\nenables an authority\u2019s data to be meshed with data from other\nauthorities and other sources such as national government.&#160;\nFor example, the data held at statistics.data.gov.uk includes which\ncounty an authority is located within.&#160; By using that data as\npart of a query, it would for instance be possible to identify the\ntotal spend, by category, for all authorities in a county such as\nthe West Midlands.&#160;&#160;</p>\n<p>As more authority data sets are published, sharing the same\nidentifiers for authority category etc., they will naturally link\ntogether, enabling the natural navigation of the information\nbetween council departments, services, costs, suppliers, etc.&#160;\nOnce this step has been taken and the dust settles a bit, this\nfoundation of linked data should become an open data&#160; platform\nfor innovating development and the publishing of other data that\nwill link in with this basic but important financial data.</p>\n<p>There are however some more technical issues, URI naming,\naggregation, etc.,&#160; to be overcome or at least addressed in\nthe short term to get us to that foundation.&#160; I will cover\nthese in part 2 of this series.</p>\n<!-- feedburner img removed by chumpologica --></div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://feedproxy.google.com/~r/Nodalities/~3/qxI6zmzBTeU/linked-spending-data-how-and-why-bother-pt1.php> <http://purl.org/rss/1.0/title> "Linked Spending Data \u2013 How and Why Bother Pt1" .
<http://feedproxy.google.com/~r/Nodalities/~3/qxI6zmzBTeU/linked-spending-data-how-and-why-bother-pt1.php> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://jeenbroekstra.blogspot.com/2011/02/implementing-sparql-11-query-first.html> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">I am currently in the middle of implementing <a href=\"http://www.w3.org/TR/sparql11-query/\">SPARQL 1.1 Query\nLanguage</a> into Sesame 2 (code can be found in <a href=\"http://repo.aduna-software.org/websvn/listing.php?repname=aduna&amp;path=%2Forg.openrdf%2Fsesame%2Fbranches%2F2.4%2F\">\nSesame's subversion repository, branch 2.4</a>). The current\nworking draft specifies a number of new features for SPARQL, and I\nwill briefly make some points about the features I have implemented\nthus far, noting problems I encountered or where the current\nworking draft was unclear to me.<br></br>\n<br></br>\n<b>1. Expressions in SELECT</b><br></br>\n<br></br>\nThis new feature was fairly straightforward to implement, mainly as\nSesame already had support for it in its query algebra. I only\nneeded to adapt the parser.<br></br>\n<br></br>\n<b>2. Negation</b><br></br>\n<br></br>\nIn <a href=\"http://www.w3.org/TR/sparql11-query/#negation\">section\n8</a> two additional operators are introduced, both of which can be\nused to express negation. They are (NOT) EXISTS, and MINUS.\nImplementation of the EXISTS function again was quite\nstraightforward, Sesame already having algebraic support for\nit.<br></br>\n<br></br>\nThe definition of MINUS in SPARQL gave me some headaches, however.\nIn Sesame's native query language <a href=\"http://www.openrdf.org/doc/sesame2/users/ch09.html\">SeRQL</a>, the\nMINUS operator is a set operator operating on collections of\ntriples - that is, the result of <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">{A} MINUS\n{B}</span> is the set of all triples matching A, minus all triples\nmatching B. In SPARQL, however, MINUS is defined in terms of\u00A0\ncompatible solutions. This means that Sesame's own algebra operator\nfor MINUS can not simply be reused for SPARQL. However, it also\nseems that SPARQL's definition of MINUS makes it, for all practical\npurposes, exactly equivalent to using a NOT EXISTS filter. To see\nwhy this is, we have to take a look at the definitions of both\noperators.<br></br>\n<br></br>\nIn <a href=\"http://www.w3.org/TR/sparql11-query/#neg-notexists-minus\">section\n8.3</a> , the difference between NOT EXISTS and MINUS is explained,\nwith a number of examples. This explanation shows that when the\nright-hand side pattern shares no variables with the left-hand\npattern, the outcome is different. However, what is also apparent\nfrom this explanation that when a MINUS operator is used and no\nshared variables exist between the two patterns, the MINUS operator\neffectively does nothing.<br></br>\n<br></br>\nThis also follows if we look at\u00A0 the definition of MINUS in\nthe <a href=\"http://www.w3.org/TR/sparql11-query/#sparqlAlgebra\">SPARQL\nalgebra</a> and the definition of compatible solutions in <a href=\"http://www.w3.org/TR/sparql11-query/#BasicGraphPattern\">section\n17.3</a>: by definition any two solutions \u00B5 and \u00B5' which share no\nvariables v are compatible. So the outcome of any such query would\nbe exactly the same as if the MINUS were not there. This leaves us\nwith two scenarios:<br></br>\n<ol>\n<li>the two patterns share a variable, in this case the MINUS can\nbe replaced with a NOT EXISTS;</li>\n<li>the two patterns do not share a variable, in this case the\nMINUS can be ignored.</li>\n</ol>\nAll in all it seems to me that MINUS as currently defined does not\nadd additional expressivity to the language and is only a syntactic\nvariant. If that is intended, that might be useful to clarify in\nthe working draft.<br></br>\n<br></br>\n<b>3. Subqueries</b><br></br>\n<br></br>\nSesame already having basic support for this in the algebra, again\nthis was rather simple to add, as it only required me to tweak the\nSPARQL parser. I will probably need to test it further\nthough.<br></br>\n<br></br>\n<b>4. Aggregates</b><br></br>\n<br></br>\nFortunately for me, it turns out that basic support for aggregate\nfunctions had been added to Sesame's algebra earlier, courtesy of\nDavid Huynh. It required a bit of tweaking to be compatible with\nSPARQL's definitions, but the framework was already there, ready\nfor me to extend.<br></br>\n<br></br>\nThere are a number of things unclear in the working draft however,\nregarding the expected behaviour of aggregate functions.<br></br>\n<br></br>\nThe first problem has to do with datatypes. Most examples take it\nas given that all input to, say, a SUM operator will be numeric\nvalues. It is not clearly stated what the expected behaviour is if\na particular variable binding turns out to be non-numeric value. As\na case in point, SUM is formally defined in terms of the XPath\nfunction op:numeric-add. This function explicitly states that it\noperates only on specific numeric types. No mention is made\nhowever, of expected behaviour when one operand is not a numeric\ntype (section 16.3 of the SPARQL WD does mention that a type error\nresults for incompatible operands, but it is not clear if this also\napplies to aggregate functions). Moreover, it is not clearly stated\nhow a type error in an aggregate function should influence the\nresult. I can see a number of possible scenarios, when a type error\noccurs during evaluation of an aggregate function:<br></br>\n<ol>\n<li>the entire query fails with an error;</li>\n<li>the incompatible operand value is ignored and evaluation\ncontinues;</li>\n<li>the aggregate operator fails silently, returning 0.</li>\n</ol>\n<br></br>\nFrom a usability perspective, I would probably have a preference\nfor option 2, although I note that in other mathematical operators\n(+, -, *, etc.) Sesame's interpretation currently is that an\nincompatible operand results in a failed query.<br></br>\n<br></br>\nAnother problem with the definition of aggregates, or more in\ngeneral with aggregates in combination with several other features,\nis that it is not always clearly defined how they should interact\n(disclaimer: perhaps it is properly defined in <a href=\"http://www.w3.org/TR/sparql11-query/#defn_algGroupBy\">section\n10.2</a>, but I'm having a hard time following the definitions\nthere). For example, what happens when we apply an ORDER BY on a\ngraph pattern that already has a GROUP BY and an aggregate\nfunction? For example, take the following data set:<br></br>\n<br></br>\n<div style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">:org1\n:affiliates :auth1, :auth2 .<br></br>\n:auth1 :name \"John\" .<br></br>\n:auth2 :name \"Paul\" .<br></br>\n:org2 :affiliates :auth3 .<br></br>\n:auth3 :name \"Ringo\" .</div>\n<br></br>\nAnd the following query:<br></br>\n<br></br>\n<span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">SELECT\n(GROUP_CONCAT(?name) AS ?names)</span><br></br>\n<span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">WHERE\n{</span><br></br>\n<span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">\u00A0\n?org :affiliates ?auth .</span><br></br>\n<span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">\u00A0\n?auth :name ?name.</span><br></br>\n<span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">}</span><br></br>\n\n<span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">GROUP BY\n?org</span><br></br>\n<span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">ORDER BY\nASC(str(?name))</span><br></br>\n<div style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\"></div>\n<br></br>\nMy intuitive understanding would be that the result of this query\nwould be:<br></br>\n<br></br>\n<div style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">\n<u>?names\u00A0\u00A0\u00A0\u00A0\u00A0</u></div>\n<div style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">\n\"Ringo\"<br></br>\n\"John Paul\"</div>\n<div style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\"></div>\n<br></br>\nThat is: the ordering is applied to the intermediate result of the\ngrouping, thus supplying the aggregate operator (in this case,\nGROUP_CONCAT) with an ordered sequence (which makes sure that we\nget a concatenated string \"John Paul\" rather than \"Paul John\"). But\nit is not completely clear to me from the working draft if the\nORDER BY clause should be applied to a grouping in this\nfashion.<br></br>\n<br></br>\nThese are my findings thus far. I have not yet started on property\npaths or federated query. In the mean time, I would welcome any\nfeedback on my notes, including feedback that tells me I should\nhave read section so-and-so and it's all clear as glass if I had\njust taken the time to study it properly :)<br></br>\n<br></br>\nAlso, this: in the course of this work I have written several\nDAWG-Manifest style unit tests to check conformance as I saw it.\nThey can be found in Sesame's SVN repository, and I'd be happy to\nlet them be reused.<br></br>\n<br></br>\n<br></br>\n<div class=\"blogger-post-footer\"><img width=\"1\" height=\"1\" src=\"https://blogger.googleusercontent.com/tracker/8989580-7517732275545081726?l=jeenbroekstra.blogspot.com\" alt=\"\"></img></div>\n<!--  feedburner img removed by chumpologica  --></div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://jeenbroekstra.blogspot.com/2011/02/implementing-sparql-11-query-first.html> <http://purl.org/dc/elements/1.1/creator> "Jeen Broekstra" .
<http://jeenbroekstra.blogspot.com/2011/02/implementing-sparql-11-query-first.html> <http://purl.org/dc/elements/1.1/date> "2011-02-05T04:03Z" .
<http://jeenbroekstra.blogspot.com/2011/02/implementing-sparql-11-query-first.html> <http://purl.org/dc/elements/1.1/relation> "http://jeenbroekstra.blogspot.com/" .
<http://jeenbroekstra.blogspot.com/2011/02/implementing-sparql-11-query-first.html> <http://purl.org/dc/elements/1.1/source> "The Seer by Jeen Broekstra" .
<http://jeenbroekstra.blogspot.com/2011/02/implementing-sparql-11-query-first.html> <http://purl.org/rss/1.0/description> "I am currently in the middle of implementing SPARQL 1.1 Query Language into Sesame 2 (code can be found in Sesame's subversion repository, branch 2.4 ). The current working draft specifies a number of new features for SPARQL, and I will briefly make some points about the features I have implemented thus far, noting problems I encountered or where the current working draft was unclear to me. 1. Expressions in SELECT This new feature was fairly straightforward to implement, mainly as Sesame already had support for it in its query algebra. I only needed to adapt the parser. 2. Negation ..." .
<http://jeenbroekstra.blogspot.com/2011/02/implementing-sparql-11-query-first.html> <http://purl.org/rss/1.0/link> "http://jeenbroekstra.blogspot.com/2011/02/implementing-sparql-11-query-first.html" .
<http://jeenbroekstra.blogspot.com/2011/02/implementing-sparql-11-query-first.html> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>I am currently in the middle of implementing <a href=\n\"http://www.w3.org/TR/sparql11-query/\">SPARQL 1.1 Query\nLanguage</a> into Sesame 2 (code can be found in <a href=\n\"http://repo.aduna-software.org/websvn/listing.php?repname=aduna&amp;path=%2Forg.openrdf%2Fsesame%2Fbranches%2F2.4%2F\">\nSesame's subversion repository, branch 2.4</a>). The current\nworking draft specifies a number of new features for SPARQL, and I\nwill briefly make some points about the features I have implemented\nthus far, noting problems I encountered or where the current\nworking draft was unclear to me.<br />\n<br />\n<b>1. Expressions in SELECT</b><br />\n<br />\nThis new feature was fairly straightforward to implement, mainly as\nSesame already had support for it in its query algebra. I only\nneeded to adapt the parser.<br />\n<br />\n<b>2. Negation</b><br />\n<br />\nIn <a href=\"http://www.w3.org/TR/sparql11-query/#negation\">section\n8</a> two additional operators are introduced, both of which can be\nused to express negation. They are (NOT) EXISTS, and MINUS.\nImplementation of the EXISTS function again was quite\nstraightforward, Sesame already having algebraic support for\nit.<br />\n<br />\nThe definition of MINUS in SPARQL gave me some headaches, however.\nIn Sesame's native query language <a href=\n\"http://www.openrdf.org/doc/sesame2/users/ch09.html\">SeRQL</a>, the\nMINUS operator is a set operator operating on collections of\ntriples - that is, the result of <span style=\n\"font-family: &quot;Courier New&quot;,Courier,monospace;\">{A} MINUS\n{B}</span> is the set of all triples matching A, minus all triples\nmatching B. In SPARQL, however, MINUS is defined in terms of&#160;\ncompatible solutions. This means that Sesame's own algebra operator\nfor MINUS can not simply be reused for SPARQL. However, it also\nseems that SPARQL's definition of MINUS makes it, for all practical\npurposes, exactly equivalent to using a NOT EXISTS filter. To see\nwhy this is, we have to take a look at the definitions of both\noperators.<br />\n<br />\nIn <a href=\n\"http://www.w3.org/TR/sparql11-query/#neg-notexists-minus\">section\n8.3</a> , the difference between NOT EXISTS and MINUS is explained,\nwith a number of examples. This explanation shows that when the\nright-hand side pattern shares no variables with the left-hand\npattern, the outcome is different. However, what is also apparent\nfrom this explanation that when a MINUS operator is used and no\nshared variables exist between the two patterns, the MINUS operator\neffectively does nothing.<br />\n<br />\nThis also follows if we look at&#160; the definition of MINUS in\nthe <a href=\n\"http://www.w3.org/TR/sparql11-query/#sparqlAlgebra\">SPARQL\nalgebra</a> and the definition of compatible solutions in <a href=\n\"http://www.w3.org/TR/sparql11-query/#BasicGraphPattern\">section\n17.3</a>: by definition any two solutions \u00B5 and \u00B5' which share no\nvariables v are compatible. So the outcome of any such query would\nbe exactly the same as if the MINUS were not there. This leaves us\nwith two scenarios:<br />\n<ol>\n<li>the two patterns share a variable, in this case the MINUS can\nbe replaced with a NOT EXISTS;</li>\n<li>the two patterns do not share a variable, in this case the\nMINUS can be ignored.</li>\n</ol>\nAll in all it seems to me that MINUS as currently defined does not\nadd additional expressivity to the language and is only a syntactic\nvariant. If that is intended, that might be useful to clarify in\nthe working draft.<br />\n<br />\n<b>3. Subqueries</b><br />\n<br />\nSesame already having basic support for this in the algebra, again\nthis was rather simple to add, as it only required me to tweak the\nSPARQL parser. I will probably need to test it further\nthough.<br />\n<br />\n<b>4. Aggregates</b><br />\n<br />\nFortunately for me, it turns out that basic support for aggregate\nfunctions had been added to Sesame's algebra earlier, courtesy of\nDavid Huynh. It required a bit of tweaking to be compatible with\nSPARQL's definitions, but the framework was already there, ready\nfor me to extend.<br />\n<br />\nThere are a number of things unclear in the working draft however,\nregarding the expected behaviour of aggregate functions.<br />\n<br />\nThe first problem has to do with datatypes. Most examples take it\nas given that all input to, say, a SUM operator will be numeric\nvalues. It is not clearly stated what the expected behaviour is if\na particular variable binding turns out to be non-numeric value. As\na case in point, SUM is formally defined in terms of the XPath\nfunction op:numeric-add. This function explicitly states that it\noperates only on specific numeric types. No mention is made\nhowever, of expected behaviour when one operand is not a numeric\ntype (section 16.3 of the SPARQL WD does mention that a type error\nresults for incompatible operands, but it is not clear if this also\napplies to aggregate functions). Moreover, it is not clearly stated\nhow a type error in an aggregate function should influence the\nresult. I can see a number of possible scenarios, when a type error\noccurs during evaluation of an aggregate function:<br />\n<ol>\n<li>the entire query fails with an error;</li>\n<li>the incompatible operand value is ignored and evaluation\ncontinues;</li>\n<li>the aggregate operator fails silently, returning 0.</li>\n</ol>\n<br />\nFrom a usability perspective, I would probably have a preference\nfor option 2, although I note that in other mathematical operators\n(+, -, *, etc.) Sesame's interpretation currently is that an\nincompatible operand results in a failed query.<br />\n<br />\nAnother problem with the definition of aggregates, or more in\ngeneral with aggregates in combination with several other features,\nis that it is not always clearly defined how they should interact\n(disclaimer: perhaps it is properly defined in <a href=\n\"http://www.w3.org/TR/sparql11-query/#defn_algGroupBy\">section\n10.2</a>, but I'm having a hard time following the definitions\nthere). For example, what happens when we apply an ORDER BY on a\ngraph pattern that already has a GROUP BY and an aggregate\nfunction? For example, take the following data set:<br />\n<br />\n<div style=\n\"font-family: &quot;Courier New&quot;,Courier,monospace;\">:org1\n:affiliates :auth1, :auth2 .<br />\n:auth1 :name \"John\" .<br />\n:auth2 :name \"Paul\" .<br />\n:org2 :affiliates :auth3 .<br />\n:auth3 :name \"Ringo\" .</div>\n<br />\nAnd the following query:<br />\n<br />\n<span style=\n\"font-family: &quot;Courier New&quot;,Courier,monospace;\">SELECT\n(GROUP_CONCAT(?name) AS ?names)</span><br />\n<span style=\n\"font-family: &quot;Courier New&quot;,Courier,monospace;\">WHERE\n{</span><br />\n<span style=\n\"font-family: &quot;Courier New&quot;,Courier,monospace;\">&#160;\n?org :affiliates ?auth .</span><br />\n<span style=\n\"font-family: &quot;Courier New&quot;,Courier,monospace;\">&#160;\n?auth :name ?name.</span><br />\n<span style=\n\"font-family: &quot;Courier New&quot;,Courier,monospace;\">}</span><br />\n\n<span style=\n\"font-family: &quot;Courier New&quot;,Courier,monospace;\">GROUP BY\n?org</span><br />\n<span style=\n\"font-family: &quot;Courier New&quot;,Courier,monospace;\">ORDER BY\nASC(str(?name))</span><br />\n<div style=\n\"font-family: &quot;Courier New&quot;,Courier,monospace;\"></div>\n<br />\nMy intuitive understanding would be that the result of this query\nwould be:<br />\n<br />\n<div style=\n\"font-family: &quot;Courier New&quot;,Courier,monospace;\">\n<u>?names&#160;&#160;&#160;&#160;&#160;</u></div>\n<div style=\n\"font-family: &quot;Courier New&quot;,Courier,monospace;\">\n\"Ringo\"<br />\n\"John Paul\"</div>\n<div style=\n\"font-family: &quot;Courier New&quot;,Courier,monospace;\"></div>\n<br />\nThat is: the ordering is applied to the intermediate result of the\ngrouping, thus supplying the aggregate operator (in this case,\nGROUP_CONCAT) with an ordered sequence (which makes sure that we\nget a concatenated string \"John Paul\" rather than \"Paul John\"). But\nit is not completely clear to me from the working draft if the\nORDER BY clause should be applied to a grouping in this\nfashion.<br />\n<br />\nThese are my findings thus far. I have not yet started on property\npaths or federated query. In the mean time, I would welcome any\nfeedback on my notes, including feedback that tells me I should\nhave read section so-and-so and it's all clear as glass if I had\njust taken the time to study it properly :)<br />\n<br />\nAlso, this: in the course of this work I have written several\nDAWG-Manifest style unit tests to check conformance as I saw it.\nThey can be found in Sesame's SVN repository, and I'd be happy to\nlet them be reused.<br />\n<br />\n<br />\n<div class=\"blogger-post-footer\"><img width='1' height='1' src=\n'https://blogger.googleusercontent.com/tracker/8989580-7517732275545081726?l=jeenbroekstra.blogspot.com'\nalt='' /></div>\n<!-- feedburner img removed by chumpologica --></div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://jeenbroekstra.blogspot.com/2011/02/implementing-sparql-11-query-first.html> <http://purl.org/rss/1.0/title> "Implementing SPARQL 1.1 Query - first findings" .
<http://jeenbroekstra.blogspot.com/2011/02/implementing-sparql-11-query-first.html> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://norman.walsh.name//2011/01/30/shortform> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">The week in review, 140 characters at a time. This week, 32\nmessages in 31 conversations. (With 6 favorites.)</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://norman.walsh.name//2011/01/30/shortform> <http://purl.org/dc/elements/1.1/creator> "Norm Walsh" .
<http://norman.walsh.name//2011/01/30/shortform> <http://purl.org/dc/elements/1.1/date> "2011-02-04T17:06:47Z" .
<http://norman.walsh.name//2011/01/30/shortform> <http://purl.org/dc/elements/1.1/relation> "http://norman.walsh.name/" .
<http://norman.walsh.name//2011/01/30/shortform> <http://purl.org/dc/elements/1.1/source> "Norm Walsh" .
<http://norman.walsh.name//2011/01/30/shortform> <http://purl.org/rss/1.0/description> "\n The week in review, 140 characters at a time. This week, 32\nmessages in 31 conversations. (With 6 favorites.) \n" .
<http://norman.walsh.name//2011/01/30/shortform> <http://purl.org/rss/1.0/link> "http://norman.walsh.name//2011/01/30/shortform" .
<http://norman.walsh.name//2011/01/30/shortform> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>The week in review, 140 characters at a time. This week, 32\nmessages in 31 conversations. (With 6 favorites.)</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://norman.walsh.name//2011/01/30/shortform> <http://purl.org/rss/1.0/title> "The short-form week of 24\u201330 Jan 2011" .
<http://norman.walsh.name//2011/01/30/shortform> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://norman.walsh.name//2011/02/02/shortform> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">I'm fairly obsessive about my data. Usually I'm content to\nstop at the point where I have a copy, but in the case of tweets,\nperhaps you should have a copy too.</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://norman.walsh.name//2011/02/02/shortform> <http://purl.org/dc/elements/1.1/creator> "Norm Walsh" .
<http://norman.walsh.name//2011/02/02/shortform> <http://purl.org/dc/elements/1.1/date> "2011-02-03T00:28:48Z" .
<http://norman.walsh.name//2011/02/02/shortform> <http://purl.org/dc/elements/1.1/relation> "http://norman.walsh.name/" .
<http://norman.walsh.name//2011/02/02/shortform> <http://purl.org/dc/elements/1.1/source> "Norm Walsh" .
<http://norman.walsh.name//2011/02/02/shortform> <http://purl.org/rss/1.0/description> "\n I'm fairly obsessive about my data. Usually I'm content to\nstop at the point where I have a copy, but in the case of tweets,\nperhaps you should have a copy too. \n" .
<http://norman.walsh.name//2011/02/02/shortform> <http://purl.org/rss/1.0/link> "http://norman.walsh.name//2011/02/02/shortform" .
<http://norman.walsh.name//2011/02/02/shortform> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>I'm fairly obsessive about my data. Usually I'm content to\nstop at the point where I have a copy, but in the case of tweets,\nperhaps you should have a copy too.</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://norman.walsh.name//2011/02/02/shortform> <http://purl.org/rss/1.0/title> "Short-form fragments" .
<http://norman.walsh.name//2011/02/02/shortform> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://norman.walsh.name//2011/02/03/snowsnowsnow> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">Snow. Snow and snow. Snow, snow, snow, and snow. Snow with\nsnow. Snow, snow, snow, snow, snow, snow, spam, and snow. With\napologies to Monty Python.</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://norman.walsh.name//2011/02/03/snowsnowsnow> <http://purl.org/dc/elements/1.1/creator> "Norm Walsh" .
<http://norman.walsh.name//2011/02/03/snowsnowsnow> <http://purl.org/dc/elements/1.1/date> "2011-02-03T18:34:47Z" .
<http://norman.walsh.name//2011/02/03/snowsnowsnow> <http://purl.org/dc/elements/1.1/relation> "http://norman.walsh.name/" .
<http://norman.walsh.name//2011/02/03/snowsnowsnow> <http://purl.org/dc/elements/1.1/source> "Norm Walsh" .
<http://norman.walsh.name//2011/02/03/snowsnowsnow> <http://purl.org/rss/1.0/description> "\n Snow. Snow and snow. Snow, snow, snow, and snow. Snow with\nsnow. Snow, snow, snow, snow, snow, snow, spam, and snow. With\napologies to Monty Python. \n" .
<http://norman.walsh.name//2011/02/03/snowsnowsnow> <http://purl.org/rss/1.0/link> "http://norman.walsh.name//2011/02/03/snowsnowsnow" .
<http://norman.walsh.name//2011/02/03/snowsnowsnow> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>Snow. Snow and snow. Snow, snow, snow, and snow. Snow with\nsnow. Snow, snow, snow, snow, snow, snow, spam, and snow. With\napologies to Monty Python.</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://norman.walsh.name//2011/02/03/snowsnowsnow> <http://purl.org/rss/1.0/title> "Snow!" .
<http://norman.walsh.name//2011/02/03/snowsnowsnow> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://norman.walsh.name//2011/02/06/shortform> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">The week in review, 140 characters at a time. This week, 68\nmessages in 65 conversations. (With 12 favorites.)</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://norman.walsh.name//2011/02/06/shortform> <http://purl.org/dc/elements/1.1/creator> "Norm Walsh" .
<http://norman.walsh.name//2011/02/06/shortform> <http://purl.org/dc/elements/1.1/date> "2011-02-07T14:07:40Z" .
<http://norman.walsh.name//2011/02/06/shortform> <http://purl.org/dc/elements/1.1/relation> "http://norman.walsh.name/" .
<http://norman.walsh.name//2011/02/06/shortform> <http://purl.org/dc/elements/1.1/source> "Norm Walsh" .
<http://norman.walsh.name//2011/02/06/shortform> <http://purl.org/rss/1.0/description> "\n The week in review, 140 characters at a time. This week, 68\nmessages in 65 conversations. (With 12 favorites.) \n" .
<http://norman.walsh.name//2011/02/06/shortform> <http://purl.org/rss/1.0/link> "http://norman.walsh.name//2011/02/06/shortform" .
<http://norman.walsh.name//2011/02/06/shortform> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>The week in review, 140 characters at a time. This week, 68\nmessages in 65 conversations. (With 12 favorites.)</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://norman.walsh.name//2011/02/06/shortform> <http://purl.org/rss/1.0/title> "The short-form week of 31 Jan\u20136 Feb 2011" .
<http://norman.walsh.name//2011/02/06/shortform> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://planetrdf.com/> <http://purl.org/dc/elements/1.1/date> "2011-02-08T13:05:57.05Z" .
<http://planetrdf.com/> <http://purl.org/rss/1.0/description> "It's triples all the way down" .
<http://planetrdf.com/> <http://purl.org/rss/1.0/items> _:g82518540 .
<http://planetrdf.com/> <http://purl.org/rss/1.0/items> _:g83020610 .
<http://planetrdf.com/> <http://purl.org/rss/1.0/items> _:g90146890 .
<http://planetrdf.com/> <http://purl.org/rss/1.0/link> "http://planetrdf.com/" .
<http://planetrdf.com/> <http://purl.org/rss/1.0/title> "Planet RDF" .
<http://planetrdf.com/> <http://webns.net/mvcb/generatorAgent> <http://www.mnot.net/python/RSS.py?version=0.44> .
<http://planetrdf.com/> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/channel> .
<http://rdfa.info/2011/01/25/flickr-uses-rdfa/> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<p>This happened some time ago, but we forgot to mention it. Flickr\nexpresses information about images and the licenses associated with\nthose images using RDFa. In fact, Flickr was one of the first\nservices to adopt RDFa and use it to express metadata about the\ncontents of the web page.</p>\n</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://rdfa.info/2011/01/25/flickr-uses-rdfa/> <http://purl.org/dc/elements/1.1/creator> "RDFa" .
<http://rdfa.info/2011/01/25/flickr-uses-rdfa/> <http://purl.org/dc/elements/1.1/date> "2011-01-25T01:25:57Z" .
<http://rdfa.info/2011/01/25/flickr-uses-rdfa/> <http://purl.org/dc/elements/1.1/relation> "http://rdfa.info/" .
<http://rdfa.info/2011/01/25/flickr-uses-rdfa/> <http://purl.org/dc/elements/1.1/source> "RDFa" .
<http://rdfa.info/2011/01/25/flickr-uses-rdfa/> <http://purl.org/rss/1.0/description> "\n \n This happened some time ago, but we forgot to mention it. Flickr\nexpresses information about images and the licenses associated with\nthose images using RDFa. In fact, Flickr was one of the first\nservices to adopt RDFa and use it to express metadata about the\ncontents of the web page. \n \n" .
<http://rdfa.info/2011/01/25/flickr-uses-rdfa/> <http://purl.org/rss/1.0/link> "http://rdfa.info/2011/01/25/flickr-uses-rdfa/" .
<http://rdfa.info/2011/01/25/flickr-uses-rdfa/> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<p>This happened some time ago, but we forgot to mention it. Flickr\nexpresses information about images and the licenses associated with\nthose images using RDFa. In fact, Flickr was one of the first\nservices to adopt RDFa and use it to express metadata about the\ncontents of the web page.</p>\n</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://rdfa.info/2011/01/25/flickr-uses-rdfa/> <http://purl.org/rss/1.0/title> "Flickr uses RDFa" .
<http://rdfa.info/2011/01/25/flickr-uses-rdfa/> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://rdfa.info/2011/01/26/rdfa-grows/> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<p>New research released by Yahoo! shows that RDFa demonstrated\nexplosive growth in 2010. In fact, RDFa is the fastest growing data\nmarkup format on the Web, and is used on more than 430 million web\npages. It accounts for roughly 3.6% of the all of the Web pages on\nthe Internet. How much did RDFa grow last year? 510% \u2013 you can bet\nthat this year will show even stronger growth as people start to\nrealize the search engine advantage that RDFa gives web content\npublishers.</p>\n<p>You can learn more about this cutting edge research by Peter\nMika at Yahoo! <a href=\"http://tripletalk.wordpress.com/2011/01/25/rdfa-deployment-across-the-web/\">\non his personal blog</a>.</p>\n</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://rdfa.info/2011/01/26/rdfa-grows/> <http://purl.org/dc/elements/1.1/creator> "RDFa" .
<http://rdfa.info/2011/01/26/rdfa-grows/> <http://purl.org/dc/elements/1.1/date> "2011-01-26T01:39Z" .
<http://rdfa.info/2011/01/26/rdfa-grows/> <http://purl.org/dc/elements/1.1/relation> "http://rdfa.info/" .
<http://rdfa.info/2011/01/26/rdfa-grows/> <http://purl.org/dc/elements/1.1/source> "RDFa" .
<http://rdfa.info/2011/01/26/rdfa-grows/> <http://purl.org/rss/1.0/description> "New research released by Yahoo! shows that RDFa demonstrated explosive growth in 2010. In fact, RDFa is the fastest growing data markup format on the Web, and is used on more than 430 million web pages. It accounts for roughly 3.6% of the all of the Web pages on the Internet. How much did RDFa grow last year? 510% \u2013 you can bet that this year will show even stronger growth as people start to realize the search engine advantage that RDFa gives web content publishers. You can learn more about this cutting edge research by Peter Mika at Yahoo! ..." .
<http://rdfa.info/2011/01/26/rdfa-grows/> <http://purl.org/rss/1.0/link> "http://rdfa.info/2011/01/26/rdfa-grows/" .
<http://rdfa.info/2011/01/26/rdfa-grows/> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<p>New research released by Yahoo! shows that RDFa demonstrated\nexplosive growth in 2010. In fact, RDFa is the fastest growing data\nmarkup format on the Web, and is used on more than 430 million web\npages. It accounts for roughly 3.6% of the all of the Web pages on\nthe Internet. How much did RDFa grow last year? 510% \u2013 you can bet\nthat this year will show even stronger growth as people start to\nrealize the search engine advantage that RDFa gives web content\npublishers.</p>\n<p>You can learn more about this cutting edge research by Peter\nMika at Yahoo! <a href=\n\"http://tripletalk.wordpress.com/2011/01/25/rdfa-deployment-across-the-web/\">\non his personal blog</a>.</p>\n</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://rdfa.info/2011/01/26/rdfa-grows/> <http://purl.org/rss/1.0/title> "RDFa Experiences Explosive Growth" .
<http://rdfa.info/2011/01/26/rdfa-grows/> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://tomheath.com/blog/2011/01/the-linked-data-book-draft-table-of-contents/> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<p>Chris Bizer and I have been working over the last few months on\na book capturing the state of the art in <a title=\"Linked Data\" href=\"http://linkeddata.org/\">Linked Data</a>. The book will be\npublished shortly as an e-book and in hard copy by <a title=\"Morgan &amp; Claypool\" href=\"http://www.morganclaypool.com/\">Morgan &amp; Claypool</a>, as part\nof the series <a title=\"Synthesis Lectures in Web Engineering\" href=\"http://www.morganclaypool.com/page/wbe\">Synthesis Lectures in\nWeb Engineering</a>, edited by Jim Hendler and Frank van Harmelen.\nThere will also be an HTML version available free of charge on the\nWeb.</p>\n<p>I\u2019ve been asked about the contents, so thought I\u2019d reproduce the\ntable of contents here. This is the structure as we sent it to the\npublisher \u2014 the final structure my vary a little but changes will\nlikely be superficial. <a title=\"Linked Data Book\" href=\"http://www.amazon.co.uk/Linked-Data-Synthesis-Lectures-Engineering/dp/1608454304/\">\nRegister at Amazon</a> to receive an update when the book is\nreleased.</p>\n<ul>\n<li>Overview</li>\n<li>Contents</li>\n<li>List of Figures</li>\n<li>Acknowledgements</li>\n<li>Introduction\n<ul>\n<li>The Data Deluge</li>\n<li>The Rationale for Linked Data\n<ul>\n<li>Structure Enables Sophisticated Processing</li>\n<li>Hyperlinks Connect Distributed Data</li>\n</ul>\n</li>\n<li>From Data Islands to a Global Data Space</li>\n<li>Structure of this book</li>\n<li>Intended Audience</li>\n<li>Introducing <em>Big Lynx Productions</em></li>\n</ul>\n</li>\n<li>Principles of Linked Data\n<ul>\n<li>The Principles in a Nutshell</li>\n<li>Naming Things with URIs</li>\n<li>Making URIs Defererencable\n<ul>\n<li>URIs</li>\n<li>Hash URIs</li>\n<li>Hash versus</li>\n</ul>\n</li>\n<li>Providing Useful RDF Information\n<ul>\n<li>The RDF Data Model\n<ul>\n<li>Benefits of using the RDF Data Model in the Linked Data\nContext</li>\n<li>RDF Features Best Avoided in the Linked Data Context</li>\n</ul>\n</li>\n<li>RDF Serialization Formats\n<ul>\n<li>RDF/XML</li>\n<li>RDFa</li>\n<li>Turtle</li>\n<li>N-Triples</li>\n<li>RDF/JSON</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Including Links to other Things\n<ul>\n<li>Relationship Links</li>\n<li>Identity Links</li>\n<li>Vocabulary Links</li>\n</ul>\n</li>\n<li>Conclusions</li>\n</ul>\n</li>\n<li>The Web of Data\n<ul>\n<li>Bootstrapping the Web of Data</li>\n<li>Topology of the Web of Data\n<ul>\n<li>Cross-Domain Data</li>\n<li>Geographic Data</li>\n<li>Media</li>\n<li>Government Data</li>\n<li>Libraries and Education</li>\n<li>Life Sciences</li>\n<li>Retail and Commerce</li>\n<li>User Generated Content and Social Media</li>\n</ul>\n</li>\n<li>Conclusions</li>\n</ul>\n</li>\n<li>Linked Data Design Considerations\n<ul>\n<li>Using URIs as Names for Things\n<ul>\n<li>Minting HTTP URIs</li>\n<li>Guidelines for Creating Cool URIs\n<ul>\n<li>Keep out of namespaces you do not control</li>\n<li>Abstract away from implementation details</li>\n<li>Use Natural Keys within URIs</li>\n</ul>\n</li>\n<li>Example URIs</li>\n</ul>\n</li>\n<li>Describing Things with RDF\n<ul>\n<li>Literal Triples and Outgoing Links</li>\n<li>Incoming Links</li>\n<li>Triples that Describe Related Resources</li>\n<li>Triples that Describe the Description</li>\n</ul>\n</li>\n<li>Publishing Data about Data\n<ul>\n<li>Describing a Data Set\n<ul>\n<li>Semantic Sitemaps</li>\n<li>voiD Descriptions</li>\n</ul>\n</li>\n<li>Provenance Metadata</li>\n<li>Licenses, Waivers and Norms for Data\n<ul>\n<li>Licenses vs. Waivers</li>\n<li>Applying Licenses to Copyrightable Material</li>\n<li>Non-copyrightable Material</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Choosing and Using Vocabularies\n<ul>\n<li>SKOS, RDFS and OWL</li>\n<li>RDFS Basics\n<ul>\n<li>Annotations in RDFS</li>\n<li>Relating Classes and Properties</li>\n</ul>\n</li>\n<li>A Little OWL</li>\n<li>Reusing Existing Terms</li>\n<li>Selecting Vocabularies</li>\n<li>Defining Terms</li>\n</ul>\n</li>\n<li>Making Links with RDF\n<ul>\n<li>Making Links within a Data Set\n<ul>\n<li>Publishing Incoming and Outgoing Links</li>\n</ul>\n</li>\n<li>Making Links with External Data Sources\n<ul>\n<li>Choosing External Linking Targets</li>\n<li>Choosing Predicates for Linking</li>\n</ul>\n</li>\n<li>Setting RDF Links Manually</li>\n<li>Auto-generating RDF Links\n<ul>\n<li>Key-based Approaches</li>\n<li>Similarity-based Approaches</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Recipes for Publishing Linked Data\n<ul>\n<li>Linked Data Publishing Patterns\n<ul>\n<li>Patterns in a Nutshell\n<ul>\n<li>From Queryable Structured Data to Linked Data</li>\n<li>From Static Structured Data to Linked Data</li>\n<li>From Text Documents to Linked Data</li>\n</ul>\n</li>\n<li>Additional Considerations\n<ul>\n<li>Data Volume: How much data needs to be served?</li>\n<li>Data Dynamism: How often does the data change?</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>The Recipes\n<ul>\n<li>Serving Linked Data as Static RDF/XML Files\n<ul>\n<li>Hosting and Naming Static RDF Files</li>\n<li>Server-Side Configuration: MIME Types</li>\n<li>Making RDF Discoverable from HTML</li>\n</ul>\n</li>\n<li>Serving Linked Data as RDF Embedded in HTML Files</li>\n<li>Serving RDF and HTML with Custom Server-Side Scripts</li>\n<li>Serving Linked Data from Relational Databases</li>\n<li>Serving Linked Data from RDF Triple Stores</li>\n<li>Serving RDF by Wrapping Existing Application or Web APIs</li>\n</ul>\n</li>\n<li>Additional Approaches to Publishing Linked Data</li>\n<li>Testing and Debugging Linked Data</li>\n<li>Linked Data Publishing Checklist</li>\n</ul>\n</li>\n<li>Consuming Linked Data\n<ul>\n<li>Deployed Linked Data Applications\n<ul>\n<li>Generic Applications\n<ul>\n<li>Linked Data Browsers</li>\n<li>Linked Data Search Engines</li>\n</ul>\n</li>\n<li>Domain-specific Applications</li>\n</ul>\n</li>\n<li>Developing a Linked Data Mashup\n<ul>\n<li>Software Requirements</li>\n<li>Accessing Linked Data URIs</li>\n<li>Representing Data Locally using Named Graphs</li>\n<li>Querying local Data with SPARQL</li>\n</ul>\n</li>\n<li>Architecture of Linked Data Applications\n<ul>\n<li>Accessing the Web of Data</li>\n<li>Vocabulary Mapping</li>\n<li>Identity Resolution</li>\n<li>Provenance Tracking</li>\n<li>Data Quality Assessment</li>\n<li>Caching Web Data Locally</li>\n<li>Using Web Data in the Application Context</li>\n</ul>\n</li>\n<li>Effort Distribution between Publishers, Consumers and Third\nParties</li>\n</ul>\n</li>\n<li>Summary and Outlook</li>\n<li>Bibliography</li>\n</ul>\n<p>Related posts:</p>\n<ol>\n<li><a href=\"http://tomheath.com/blog/2010/06/why-carry-the-cost-of-linked-data/\" rel=\"bookmark\" title=\"Permanent Link: Why Carry the Cost of Linked Data?\">Why Carry the\nCost of Linked Data?</a> <small>In his ongoing series of niggles\nabout Linked Data, Rob...</small></li>\n</ol>\n<p>Related posts brought to you by <a href=\"http://mitcho.com/code/yarpp/\">Yet Another Related Posts\nPlugin</a>.</p>\n</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://tomheath.com/blog/2011/01/the-linked-data-book-draft-table-of-contents/> <http://purl.org/dc/elements/1.1/creator> "Tom Heath" .
<http://tomheath.com/blog/2011/01/the-linked-data-book-draft-table-of-contents/> <http://purl.org/dc/elements/1.1/date> "2011-01-26T19:01:21Z" .
<http://tomheath.com/blog/2011/01/the-linked-data-book-draft-table-of-contents/> <http://purl.org/dc/elements/1.1/relation> "http://tomheath.com/blog/" .
<http://tomheath.com/blog/2011/01/the-linked-data-book-draft-table-of-contents/> <http://purl.org/dc/elements/1.1/source> "Displacement Activities by Tom Heath" .
<http://tomheath.com/blog/2011/01/the-linked-data-book-draft-table-of-contents/> <http://purl.org/rss/1.0/description> "Chris Bizer and I have been working over the last few months on a book capturing the state of the art in Linked Data . The book will be published shortly as an e-book and in hard copy by Morgan &amp; Claypool , as part of the series Synthesis Lectures in Web Engineering , edited by Jim Hendler and Frank van Harmelen. There will also be an HTML version available free of charge on the Web. I\u2019ve been asked about the contents, so thought I\u2019d reproduce the table of contents here. This is the structure as we sent it to ..." .
<http://tomheath.com/blog/2011/01/the-linked-data-book-draft-table-of-contents/> <http://purl.org/rss/1.0/link> "http://tomheath.com/blog/2011/01/the-linked-data-book-draft-table-of-contents/" .
<http://tomheath.com/blog/2011/01/the-linked-data-book-draft-table-of-contents/> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<p>Chris Bizer and I have been working over the last few months on\na book capturing the state of the art in <a title=\"Linked Data\"\nhref=\"http://linkeddata.org/\">Linked Data</a>. The book will be\npublished shortly as an e-book and in hard copy by <a title=\n\"Morgan &amp; Claypool\" href=\n\"http://www.morganclaypool.com/\">Morgan &amp; Claypool</a>, as part\nof the series <a title=\"Synthesis Lectures in Web Engineering\"\nhref=\"http://www.morganclaypool.com/page/wbe\">Synthesis Lectures in\nWeb Engineering</a>, edited by Jim Hendler and Frank van Harmelen.\nThere will also be an HTML version available free of charge on the\nWeb.</p>\n<p>I\u2019ve been asked about the contents, so thought I\u2019d reproduce the\ntable of contents here. This is the structure as we sent it to the\npublisher \u2014 the final structure my vary a little but changes will\nlikely be superficial. <a title=\"Linked Data Book\" href=\n\"http://www.amazon.co.uk/Linked-Data-Synthesis-Lectures-Engineering/dp/1608454304/\">\nRegister at Amazon</a> to receive an update when the book is\nreleased.</p>\n<ul>\n<li>Overview</li>\n<li>Contents</li>\n<li>List of Figures</li>\n<li>Acknowledgements</li>\n<li>Introduction\n<ul>\n<li>The Data Deluge</li>\n<li>The Rationale for Linked Data\n<ul>\n<li>Structure Enables Sophisticated Processing</li>\n<li>Hyperlinks Connect Distributed Data</li>\n</ul>\n</li>\n<li>From Data Islands to a Global Data Space</li>\n<li>Structure of this book</li>\n<li>Intended Audience</li>\n<li>Introducing <em>Big Lynx Productions</em></li>\n</ul>\n</li>\n<li>Principles of Linked Data\n<ul>\n<li>The Principles in a Nutshell</li>\n<li>Naming Things with URIs</li>\n<li>Making URIs Defererencable\n<ul>\n<li>URIs</li>\n<li>Hash URIs</li>\n<li>Hash versus</li>\n</ul>\n</li>\n<li>Providing Useful RDF Information\n<ul>\n<li>The RDF Data Model\n<ul>\n<li>Benefits of using the RDF Data Model in the Linked Data\nContext</li>\n<li>RDF Features Best Avoided in the Linked Data Context</li>\n</ul>\n</li>\n<li>RDF Serialization Formats\n<ul>\n<li>RDF/XML</li>\n<li>RDFa</li>\n<li>Turtle</li>\n<li>N-Triples</li>\n<li>RDF/JSON</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Including Links to other Things\n<ul>\n<li>Relationship Links</li>\n<li>Identity Links</li>\n<li>Vocabulary Links</li>\n</ul>\n</li>\n<li>Conclusions</li>\n</ul>\n</li>\n<li>The Web of Data\n<ul>\n<li>Bootstrapping the Web of Data</li>\n<li>Topology of the Web of Data\n<ul>\n<li>Cross-Domain Data</li>\n<li>Geographic Data</li>\n<li>Media</li>\n<li>Government Data</li>\n<li>Libraries and Education</li>\n<li>Life Sciences</li>\n<li>Retail and Commerce</li>\n<li>User Generated Content and Social Media</li>\n</ul>\n</li>\n<li>Conclusions</li>\n</ul>\n</li>\n<li>Linked Data Design Considerations\n<ul>\n<li>Using URIs as Names for Things\n<ul>\n<li>Minting HTTP URIs</li>\n<li>Guidelines for Creating Cool URIs\n<ul>\n<li>Keep out of namespaces you do not control</li>\n<li>Abstract away from implementation details</li>\n<li>Use Natural Keys within URIs</li>\n</ul>\n</li>\n<li>Example URIs</li>\n</ul>\n</li>\n<li>Describing Things with RDF\n<ul>\n<li>Literal Triples and Outgoing Links</li>\n<li>Incoming Links</li>\n<li>Triples that Describe Related Resources</li>\n<li>Triples that Describe the Description</li>\n</ul>\n</li>\n<li>Publishing Data about Data\n<ul>\n<li>Describing a Data Set\n<ul>\n<li>Semantic Sitemaps</li>\n<li>voiD Descriptions</li>\n</ul>\n</li>\n<li>Provenance Metadata</li>\n<li>Licenses, Waivers and Norms for Data\n<ul>\n<li>Licenses vs. Waivers</li>\n<li>Applying Licenses to Copyrightable Material</li>\n<li>Non-copyrightable Material</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Choosing and Using Vocabularies\n<ul>\n<li>SKOS, RDFS and OWL</li>\n<li>RDFS Basics\n<ul>\n<li>Annotations in RDFS</li>\n<li>Relating Classes and Properties</li>\n</ul>\n</li>\n<li>A Little OWL</li>\n<li>Reusing Existing Terms</li>\n<li>Selecting Vocabularies</li>\n<li>Defining Terms</li>\n</ul>\n</li>\n<li>Making Links with RDF\n<ul>\n<li>Making Links within a Data Set\n<ul>\n<li>Publishing Incoming and Outgoing Links</li>\n</ul>\n</li>\n<li>Making Links with External Data Sources\n<ul>\n<li>Choosing External Linking Targets</li>\n<li>Choosing Predicates for Linking</li>\n</ul>\n</li>\n<li>Setting RDF Links Manually</li>\n<li>Auto-generating RDF Links\n<ul>\n<li>Key-based Approaches</li>\n<li>Similarity-based Approaches</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Recipes for Publishing Linked Data\n<ul>\n<li>Linked Data Publishing Patterns\n<ul>\n<li>Patterns in a Nutshell\n<ul>\n<li>From Queryable Structured Data to Linked Data</li>\n<li>From Static Structured Data to Linked Data</li>\n<li>From Text Documents to Linked Data</li>\n</ul>\n</li>\n<li>Additional Considerations\n<ul>\n<li>Data Volume: How much data needs to be served?</li>\n<li>Data Dynamism: How often does the data change?</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>The Recipes\n<ul>\n<li>Serving Linked Data as Static RDF/XML Files\n<ul>\n<li>Hosting and Naming Static RDF Files</li>\n<li>Server-Side Configuration: MIME Types</li>\n<li>Making RDF Discoverable from HTML</li>\n</ul>\n</li>\n<li>Serving Linked Data as RDF Embedded in HTML Files</li>\n<li>Serving RDF and HTML with Custom Server-Side Scripts</li>\n<li>Serving Linked Data from Relational Databases</li>\n<li>Serving Linked Data from RDF Triple Stores</li>\n<li>Serving RDF by Wrapping Existing Application or Web APIs</li>\n</ul>\n</li>\n<li>Additional Approaches to Publishing Linked Data</li>\n<li>Testing and Debugging Linked Data</li>\n<li>Linked Data Publishing Checklist</li>\n</ul>\n</li>\n<li>Consuming Linked Data\n<ul>\n<li>Deployed Linked Data Applications\n<ul>\n<li>Generic Applications\n<ul>\n<li>Linked Data Browsers</li>\n<li>Linked Data Search Engines</li>\n</ul>\n</li>\n<li>Domain-specific Applications</li>\n</ul>\n</li>\n<li>Developing a Linked Data Mashup\n<ul>\n<li>Software Requirements</li>\n<li>Accessing Linked Data URIs</li>\n<li>Representing Data Locally using Named Graphs</li>\n<li>Querying local Data with SPARQL</li>\n</ul>\n</li>\n<li>Architecture of Linked Data Applications\n<ul>\n<li>Accessing the Web of Data</li>\n<li>Vocabulary Mapping</li>\n<li>Identity Resolution</li>\n<li>Provenance Tracking</li>\n<li>Data Quality Assessment</li>\n<li>Caching Web Data Locally</li>\n<li>Using Web Data in the Application Context</li>\n</ul>\n</li>\n<li>Effort Distribution between Publishers, Consumers and Third\nParties</li>\n</ul>\n</li>\n<li>Summary and Outlook</li>\n<li>Bibliography</li>\n</ul>\n<p>Related posts:</p>\n<ol>\n<li><a href=\n'http://tomheath.com/blog/2010/06/why-carry-the-cost-of-linked-data/'\nrel='bookmark' title=\n'Permanent Link: Why Carry the Cost of Linked Data?'>Why Carry the\nCost of Linked Data?</a> <small>In his ongoing series of niggles\nabout Linked Data, Rob...</small></li>\n</ol>\n<p>Related posts brought to you by <a href=\n'http://mitcho.com/code/yarpp/'>Yet Another Related Posts\nPlugin</a>.</p>\n</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://tomheath.com/blog/2011/01/the-linked-data-book-draft-table-of-contents/> <http://purl.org/rss/1.0/title> "The Linked Data Book: Draft Table of Contents" .
<http://tomheath.com/blog/2011/01/the-linked-data-book-draft-table-of-contents/> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://tripletalk.wordpress.com/2011/01/25/rdfa-deployment-across-the-web/> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<p>I have presented on previous occasions (at Semtech 2009, \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  feeds.wordpress img removed by chumpologica  --> \n<!--  stats.wordpress img removed by chumpologica  --></p>\n</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://tripletalk.wordpress.com/2011/01/25/rdfa-deployment-across-the-web/> <http://purl.org/dc/elements/1.1/creator> "Peter Mika" .
<http://tripletalk.wordpress.com/2011/01/25/rdfa-deployment-across-the-web/> <http://purl.org/dc/elements/1.1/date> "2011-01-25T13:27:33Z" .
<http://tripletalk.wordpress.com/2011/01/25/rdfa-deployment-across-the-web/> <http://purl.org/dc/elements/1.1/relation> "http://tripletalk.wordpress.com/" .
<http://tripletalk.wordpress.com/2011/01/25/rdfa-deployment-across-the-web/> <http://purl.org/dc/elements/1.1/source> "Tripletalk by Peter Mika" .
<http://tripletalk.wordpress.com/2011/01/25/rdfa-deployment-across-the-web/> <http://purl.org/rss/1.0/description> "\n \n I have presented on previous occasions (at Semtech 2009, \n  \n  \n  \n  \n  \n  \n  \n  \n \n" .
<http://tripletalk.wordpress.com/2011/01/25/rdfa-deployment-across-the-web/> <http://purl.org/rss/1.0/link> "http://tripletalk.wordpress.com/2011/01/25/rdfa-deployment-across-the-web/" .
<http://tripletalk.wordpress.com/2011/01/25/rdfa-deployment-across-the-web/> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<p>I have presented on previous occasions (at Semtech 2009, \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- feeds.wordpress img removed by chumpologica --> \n<!-- stats.wordpress img removed by chumpologica --></p>\n</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://tripletalk.wordpress.com/2011/01/25/rdfa-deployment-across-the-web/> <http://purl.org/rss/1.0/title> "Microformats and RDFa deployment across the Web" .
<http://tripletalk.wordpress.com/2011/01/25/rdfa-deployment-across-the-web/> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://www.ldodds.com/blog/2011/01/custom-lego-sets/> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<p>For a couple of years now I\u2019ve tried to do something a little\ndifferent for Christmas presents for the kids. I\u2019m not particularly\ngood with my hands but I\u2019ve always wanted to be able to\n<em>make</em> them things: something that will hopefully mean a\nlittle more than the average gift.</p>\n<p>For example one year I made them a level in LittleBigPlanet\ncalled <a href=\"http://lbp.me/v/h7kpv\">Sackboy Saves Christmas</a>.\n(Aside for data geeks: each LittleBigPlanet level now has its own\nunique URI). The level isn\u2019t great, but I had fun making it, and\nthey\u2019ve enjoyed playing it. A little later I also made them some\n<a href=\"http://www.flickr.com/photos/ldodds/sets/72157612620171571/with/3203658964/\">\nreal pods for their sackboys</a>.</p>\n<p>This year I decided to do something with Lego.</p>\n<p><a href=\"http://ldd.lego.com/\">Lego Digital Designer</a> is a\nsimple and free CAD package for building and designing lego sets.\nOnce you\u2019ve designed something you can get it priced and ultimately\nhave it turned into a real set.</p>\n<p>I\u2019ve tried this package a few times but found that the brick set\nis a little limited and the price racks up quickly. I\u2019m also not\nthe world\u2019s greatest designer so my creations weren\u2019t great. So I\ndecided to take a slightly different tack.</p>\n<h3>Lego Community Sites</h3>\n<p>There are a lot of great lego community sites. One of these is\n<a href=\"peeron.com\">Peeron</a> which is a lego inventory website\nthat provides access to a database of lego parts, set inventories,\ninstruction scans and photos. The whole thing is crowd-sourced so\nyou can submit new inventories or scans.</p>\n<p>One particularly nice feature is that you can build a personal\ninventory of lego sets and parts. You can browse sets, ticking off\nthose that you own, and the site builds a database of the various\nparts that make up the sets. When you\u2019re browsing a set you don\u2019t\nhave you can also click \u201Ctry to build\u201D and the service will run the\nset inventory through the list of parts you own, and let you know\nwhether you have all of the required parts, if you have any of the\nright part but in the wrong colour, or which parts you\u2019re\nmissing.</p>\n<p>The core of the family lego collection is the remnants of my\nchildhood collection of <a href=\"http://peeron.com/inv/theme/LEGO/SYSTEM/Space/Classic\">Classic\nLego Space</a> sets. There were lots of parts missing, but we\u2019ve\nbeen able to use Peeron to resurrect some of the sets with\nsubstitute parts.</p>\n<p>While you can get <a href=\"http://shop.lego.com/ByCategory/Department.aspx?d=304\">new bricks,\nbaseplates and minifigs from the lego shop</a>, if you want to\ntrack down hard to find or discontinued pieces then there\u2019s one\nplace to go: <a href=\"http://www.bricklink.com/\">Bricklink</a>.</p>\n<p>For the uninitiated, Bricklink is essentially an Ebay for Lego.\nIt\u2019s a marketplace where anyone can go to buy and sell lego bricks,\nsets, and instructions. Not only is it a fantastic resource for\ntracking down hard to find pieces, but I\u2019ve found that even new\nbricks are much cheaper than buying them direct from lego.</p>\n<p>There\u2019s a search engine on the site for tracking down what you\nneed. Lego part numbers are standardised so it\u2019s easy to find what\nyou want if you\u2019re buying missing pieces for a set you want to\nbuild from Peeron. It\u2019s also a great place to go to if you\u2019re\npiecing together a custom set from scratch. You can maintain a\nwanted list and get alerts as pieces become available. And if you\ndo buy from the marketplace, you can download the part list for\nyour order for importing back into Peeron, to keep you part list up\nto date.</p>\n<p>The Bricklink community is also very friendly and efficient.\nI\u2019ve found that orders tend to be processed really quickly and come\nwell packaged. I\u2019ve taken care to rate sellers and comment on every\norder as that kind of quality interaction is something to\nencourage.</p>\n<p>So if you\u2019re thinking about building custom lego sets, Bricklink\nis definitely the place to start.</p>\n<h3>Finding and Creating Custom Lego Set Designs</h3>\n<p>Having ruled out trying to create something completely unique I\nsettled on creating sets from other people\u2019s creations. A bit of a\ncop out I suppose, but the end result would still be something\ndifferent to what\u2019s in the the Lego catalogue.</p>\n<p>I\u2019ve mentioned Lego Digital Designer already. There\u2019s also a\nmore \u201Cprofessional\u201D Lego CAD package called <a href=\"http://www.ldraw.org/\">LDraw</a> which is essentially a suite of\nopen source tools for creating and manipulating Lego model designs.\nAs well as the core CAD package itself there are also tools to\nsupport creating rendered images from designs, and even to create\ncomplete instructions that are very close to those produced by Lego\nthemselves. The tools are a bit fiddly to work with though and\nsurprisingly I found it hard to track down many designs that people\nhad actually shared.</p>\n<p>Another resource is the <a href=\"http://www.mocpages.com/\">MOCPages</a> community. MOC stands for\n\u201CMy Own Creation\u201D. It\u2019s essentially a community site where people\ncan upload photo sets for models they\u2019ve created. There are some\nreally great (and big!) Lego models on that site! Little in the way\nof instructions or parts lists though, so there\u2019s an element of\nreverse engineering involved.</p>\n<p>There\u2019s also a community of people using Flickr to share their\ncreations. I\u2019ve been following <a href=\"http://www.flickr.com/photos/legoloverman/\">Peter Reid</a> for a\nwhile as he creates the most fantastic selection of Lego space and\nrobot models. Again, you need to be prepared to reverse engineer,\nbut this isn\u2019t too hard for the smaller models at least.</p>\n<p>A final source for some small simple models is the <a href=\"http://www.brickish.org/bi.aspx\">Brick Issue</a>. This is the\nmagazine of the Brickish Association and has a regular feature \u201C5\nMinute Model\u201D feature that provides instructions for some simple\nmodels.</p>\n<h3>What I Made</h3>\n<p><a href=\"http://www.brickish.org/bi/bi7.pdf\">Issue 7 of the\nBrick Issue</a>, for example, has a 5 minute model of a Turtle\ndroid by Peter Reid (<a href=\"http://www.flickr.com/photos/legoloverman/2892942538/\">photo</a>).\nThis was perfect for my purposes as my son and I had been admiring\nthe <a href=\"http://www.flickr.com/photos/legoloverman/sets/72157625131097864/\">\nTurtle Factory</a> at the Great Western Lego Show (<a href=\"http://www.youtube.com/watch?v=Q0tFzt-Ti3o\">watch the video</a>!).\nSo this formed the basis for the first set I put together for my\nson.</p>\n<p>I found the second set I decided to package via the <a href=\"http://neoclassicspace.com/\">Neo Classic Space</a> blog. This is a\nLego fan blog focused specifically on people updating the old Lego\nClassic Space theme to use modern parts as well as covering some\nfantastic new models made to follow the theme. There are some\nexcellent micro-scale models featured on there, <a href=\"http://neoclassicspace.com/blogs/20091102/force-microscale\">including\nthis one of an X-wing</a>. This was pretty easy to reverse engineer\nso I put together a second set that consisted of three X-Wings; one\nwith some slight tweaks to make it the \u201Csquad leader\u201D.</p>\n<p>Lego has a pretty hit and miss affair when it comes to creating\nsets for girls. My daughter loves Lego too, but primarily for\nplaying with the minifigs and the towns and buildings. So for her I\nassembled a collection of female minifigs to add to her existing\nsmall collection.</p>\n<p>Once I\u2019d ordered all of the parts \u2014 which involved probably ten\nor more individual orders across a number of Bricklink sellers \u2014\nthe remaining work was to order some boxes from the <a href=\"http://www.bagnboxman.co.uk/index.html\">The Bag And Box Man</a>. I\ncreated some custom labels, following the Lego box art style, which\nis pretty easy to reproduce. The availability of some great flickr\nphotos of the models meant that I had plenty of existing resources\nto draw on.</p>\n<p>I was pretty pleased with the end result and so were the kids!\nIt was definitely a fun project over the pre-Christmas run-up and a\nwelcome distraction from a very busy work schedule. If you\u2019re\ninterested in trying this out yourself, hopefully there are some\nuseful pointers in this post.</p>\n</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://www.ldodds.com/blog/2011/01/custom-lego-sets/> <http://purl.org/dc/elements/1.1/creator> "Leigh Dodds" .
<http://www.ldodds.com/blog/2011/01/custom-lego-sets/> <http://purl.org/dc/elements/1.1/date> "2011-01-22T20:23:23Z" .
<http://www.ldodds.com/blog/2011/01/custom-lego-sets/> <http://purl.org/dc/elements/1.1/relation> "http://ldodds.com/blog/" .
<http://www.ldodds.com/blog/2011/01/custom-lego-sets/> <http://purl.org/dc/elements/1.1/source> "Lost Boy by Leigh Dodds" .
<http://www.ldodds.com/blog/2011/01/custom-lego-sets/> <http://purl.org/rss/1.0/description> "For a couple of years now I\u2019ve tried to do something a little different for Christmas presents for the kids. I\u2019m not particularly good with my hands but I\u2019ve always wanted to be able to make them things: something that will hopefully mean a little more than the average gift. For example one year I made them a level in LittleBigPlanet called Sackboy Saves Christmas . (Aside for data geeks: each LittleBigPlanet level now has its own unique URI). The level isn\u2019t great, but I had fun making it, and they\u2019ve enjoyed playing it. A little later I also made ..." .
<http://www.ldodds.com/blog/2011/01/custom-lego-sets/> <http://purl.org/rss/1.0/link> "http://www.ldodds.com/blog/2011/01/custom-lego-sets/" .
<http://www.ldodds.com/blog/2011/01/custom-lego-sets/> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<p>For a couple of years now I\u2019ve tried to do something a little\ndifferent for Christmas presents for the kids. I\u2019m not particularly\ngood with my hands but I\u2019ve always wanted to be able to\n<em>make</em> them things: something that will hopefully mean a\nlittle more than the average gift.</p>\n<p>For example one year I made them a level in LittleBigPlanet\ncalled <a href=\"http://lbp.me/v/h7kpv\">Sackboy Saves Christmas</a>.\n(Aside for data geeks: each LittleBigPlanet level now has its own\nunique URI). The level isn\u2019t great, but I had fun making it, and\nthey\u2019ve enjoyed playing it. A little later I also made them some\n<a href=\n\"http://www.flickr.com/photos/ldodds/sets/72157612620171571/with/3203658964/\">\nreal pods for their sackboys</a>.</p>\n<p>This year I decided to do something with Lego.</p>\n<p><a href=\"http://ldd.lego.com/\">Lego Digital Designer</a> is a\nsimple and free CAD package for building and designing lego sets.\nOnce you\u2019ve designed something you can get it priced and ultimately\nhave it turned into a real set.</p>\n<p>I\u2019ve tried this package a few times but found that the brick set\nis a little limited and the price racks up quickly. I\u2019m also not\nthe world\u2019s greatest designer so my creations weren\u2019t great. So I\ndecided to take a slightly different tack.</p>\n<h3>Lego Community Sites</h3>\n<p>There are a lot of great lego community sites. One of these is\n<a href=\"peeron.com\">Peeron</a> which is a lego inventory website\nthat provides access to a database of lego parts, set inventories,\ninstruction scans and photos. The whole thing is crowd-sourced so\nyou can submit new inventories or scans.</p>\n<p>One particularly nice feature is that you can build a personal\ninventory of lego sets and parts. You can browse sets, ticking off\nthose that you own, and the site builds a database of the various\nparts that make up the sets. When you\u2019re browsing a set you don\u2019t\nhave you can also click \u201Ctry to build\u201D and the service will run the\nset inventory through the list of parts you own, and let you know\nwhether you have all of the required parts, if you have any of the\nright part but in the wrong colour, or which parts you\u2019re\nmissing.</p>\n<p>The core of the family lego collection is the remnants of my\nchildhood collection of <a href=\n\"http://peeron.com/inv/theme/LEGO/SYSTEM/Space/Classic\">Classic\nLego Space</a> sets. There were lots of parts missing, but we\u2019ve\nbeen able to use Peeron to resurrect some of the sets with\nsubstitute parts.</p>\n<p>While you can get <a href=\n\"http://shop.lego.com/ByCategory/Department.aspx?d=304\">new bricks,\nbaseplates and minifigs from the lego shop</a>, if you want to\ntrack down hard to find or discontinued pieces then there\u2019s one\nplace to go: <a href=\"http://www.bricklink.com/\">Bricklink</a>.</p>\n<p>For the uninitiated, Bricklink is essentially an Ebay for Lego.\nIt\u2019s a marketplace where anyone can go to buy and sell lego bricks,\nsets, and instructions. Not only is it a fantastic resource for\ntracking down hard to find pieces, but I\u2019ve found that even new\nbricks are much cheaper than buying them direct from lego.</p>\n<p>There\u2019s a search engine on the site for tracking down what you\nneed. Lego part numbers are standardised so it\u2019s easy to find what\nyou want if you\u2019re buying missing pieces for a set you want to\nbuild from Peeron. It\u2019s also a great place to go to if you\u2019re\npiecing together a custom set from scratch. You can maintain a\nwanted list and get alerts as pieces become available. And if you\ndo buy from the marketplace, you can download the part list for\nyour order for importing back into Peeron, to keep you part list up\nto date.</p>\n<p>The Bricklink community is also very friendly and efficient.\nI\u2019ve found that orders tend to be processed really quickly and come\nwell packaged. I\u2019ve taken care to rate sellers and comment on every\norder as that kind of quality interaction is something to\nencourage.</p>\n<p>So if you\u2019re thinking about building custom lego sets, Bricklink\nis definitely the place to start.</p>\n<h3>Finding and Creating Custom Lego Set Designs</h3>\n<p>Having ruled out trying to create something completely unique I\nsettled on creating sets from other people\u2019s creations. A bit of a\ncop out I suppose, but the end result would still be something\ndifferent to what\u2019s in the the Lego catalogue.</p>\n<p>I\u2019ve mentioned Lego Digital Designer already. There\u2019s also a\nmore \u201Cprofessional\u201D Lego CAD package called <a href=\n\"http://www.ldraw.org/\">LDraw</a> which is essentially a suite of\nopen source tools for creating and manipulating Lego model designs.\nAs well as the core CAD package itself there are also tools to\nsupport creating rendered images from designs, and even to create\ncomplete instructions that are very close to those produced by Lego\nthemselves. The tools are a bit fiddly to work with though and\nsurprisingly I found it hard to track down many designs that people\nhad actually shared.</p>\n<p>Another resource is the <a href=\n\"http://www.mocpages.com/\">MOCPages</a> community. MOC stands for\n\u201CMy Own Creation\u201D. It\u2019s essentially a community site where people\ncan upload photo sets for models they\u2019ve created. There are some\nreally great (and big!) Lego models on that site! Little in the way\nof instructions or parts lists though, so there\u2019s an element of\nreverse engineering involved.</p>\n<p>There\u2019s also a community of people using Flickr to share their\ncreations. I\u2019ve been following <a href=\n\"http://www.flickr.com/photos/legoloverman/\">Peter Reid</a> for a\nwhile as he creates the most fantastic selection of Lego space and\nrobot models. Again, you need to be prepared to reverse engineer,\nbut this isn\u2019t too hard for the smaller models at least.</p>\n<p>A final source for some small simple models is the <a href=\n\"http://www.brickish.org/bi.aspx\">Brick Issue</a>. This is the\nmagazine of the Brickish Association and has a regular feature \u201C5\nMinute Model\u201D feature that provides instructions for some simple\nmodels.</p>\n<h3>What I Made</h3>\n<p><a href=\"http://www.brickish.org/bi/bi7.pdf\">Issue 7 of the\nBrick Issue</a>, for example, has a 5 minute model of a Turtle\ndroid by Peter Reid (<a href=\n\"http://www.flickr.com/photos/legoloverman/2892942538/\">photo</a>).\nThis was perfect for my purposes as my son and I had been admiring\nthe <a href=\n\"http://www.flickr.com/photos/legoloverman/sets/72157625131097864/\">\nTurtle Factory</a> at the Great Western Lego Show (<a href=\n\"http://www.youtube.com/watch?v=Q0tFzt-Ti3o\">watch the video</a>!).\nSo this formed the basis for the first set I put together for my\nson.</p>\n<p>I found the second set I decided to package via the <a href=\n\"http://neoclassicspace.com/\">Neo Classic Space</a> blog. This is a\nLego fan blog focused specifically on people updating the old Lego\nClassic Space theme to use modern parts as well as covering some\nfantastic new models made to follow the theme. There are some\nexcellent micro-scale models featured on there, <a href=\n\"http://neoclassicspace.com/blogs/20091102/force-microscale\">including\nthis one of an X-wing</a>. This was pretty easy to reverse engineer\nso I put together a second set that consisted of three X-Wings; one\nwith some slight tweaks to make it the \u201Csquad leader\u201D.</p>\n<p>Lego has a pretty hit and miss affair when it comes to creating\nsets for girls. My daughter loves Lego too, but primarily for\nplaying with the minifigs and the towns and buildings. So for her I\nassembled a collection of female minifigs to add to her existing\nsmall collection.</p>\n<p>Once I\u2019d ordered all of the parts \u2014 which involved probably ten\nor more individual orders across a number of Bricklink sellers \u2014\nthe remaining work was to order some boxes from the <a href=\n\"http://www.bagnboxman.co.uk/index.html\">The Bag And Box Man</a>. I\ncreated some custom labels, following the Lego box art style, which\nis pretty easy to reproduce. The availability of some great flickr\nphotos of the models meant that I had plenty of existing resources\nto draw on.</p>\n<p>I was pretty pleased with the end result and so were the kids!\nIt was definitely a fun project over the pre-Christmas run-up and a\nwelcome distraction from a very busy work schedule. If you\u2019re\ninterested in trying this out yourself, hopefully there are some\nuseful pointers in this post.</p>\n</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://www.ldodds.com/blog/2011/01/custom-lego-sets/> <http://purl.org/rss/1.0/title> "Custom Lego Sets" .
<http://www.ldodds.com/blog/2011/01/custom-lego-sets/> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1653> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<h3>What?</h3>\n<p>A simple guide usable by any Javascript developer seeking to\nexploit <a class=\"auto-href\" href=\"http://dbpedia.org/resource/SPARQL\" id=\"link-id0x17b447e8\" name=\"link-id0x17b447e8\">SPARQL</a> without hassles.</p>\n<h3>Why?</h3>\n<p>SPARQL is a powerful query language, results serialization\nformat, and an HTTP based <a href=\"http://dbpedia.org/resource/Data\">data</a> access protocol from\nthe W3C. It provides a mechanism for accessing and integrating data\nacross <a href=\"http://en.wikipedia.org/wiki/Deductive_database\" id=\"link-id0x1cc76540\" name=\"link-id0x1cc76540\">Deductive Database\nSystems</a> (colloquially referred to as triple or quad stores in\n<a class=\"auto-href\" href=\"http://dbpedia.org/resource/Semantic_Web\" id=\"link-id0x1d944d78\" name=\"link-id0x1d944d78\">Semantic Web</a> and <a class=\"auto-href\" href=\"http://dbpedia.org/resource/Linked_Data\" id=\"link-id0x1c7a87c8\" name=\"link-id0x1c7a87c8\">Linked Data</a>\ncircles) -- database systems (or data spaces) that manage\nproposition oriented records in 3-tuple (triples) or 4-tuple\n(quads) form.</p>\n<h3>How?</h3>\n<p>SPARQL queries are actually HTTP payloads (typically). Thus,\nusing a RESTful client-server interaction pattern, you can dispatch\ncalls to a SPARQL compliant data server and receive a payload for\nlocal processing.</p>\n<h4>Steps:</h4>\n<ol>\n<li>Determine which SPARQL endpoint you want to access e.g.\n<a href=\"http://dbpedia.org/sparql\" id=\"link-id0x1d476520\" name=\"link-id0x1d476520\">DBpedia</a> or a local <a class=\"auto-href\" href=\"http://virtuoso.openlinksw.com\" id=\"link-id0x1bcfe140\" name=\"link-id0x1bcfe140\">Virtuoso</a> instance (typically:\nhttp://localhost:8890/sparql).</li>\n<li>If using Virtuoso, and you want to populate its quad store\nusing SPARQL, assign \"<a href=\"http://docs.openlinksw.com/virtuoso/rdfsparql.html#rdfsupportedprotocolendpointuri\" id=\"link-id0x1c7630b8\" name=\"link-id0x1c7630b8\">SPARQL_SPONGE</a>\"\nprivileges to user \"SPARQL\" (this is basic control, more\nsophisticated WebID based ACLs are available for controlling SPARQL\naccess).</li>\n</ol>\n<h4>Script:</h4>\n<pre>\n/*\nDemonstrating use of a single query to populate a # Virtuoso Quad Store via Javascript. \n*/\n\n/* \nHTTP <a href=\"http://dbpedia.org/resource/Uniform_Resource_Locator\" id=\"link-id0x1bc27a18\" name=\"link-id0x1bc27a18\">URL</a> is constructed accordingly with JSON query results format as the default via mime type.\n*/\n\nfunction sparqlQuery(query, baseURL, format) {\n        if(!format)\n                format=\"application/json\";\n        var params={\n                \"default-graph\": \"\", \"should-sponge\": \"soft\", \"query\": query,\n                \"debug\": \"on\", \"timeout\": \"\", \"format\": format,\n                \"save\": \"display\", \"fname\": \"\"\n        };\n        \n        var querypart=\"\";\n        for(var k in params) {\n                querypart+=k+\"=\"+encodeURIComponent(params[k])+\"&amp;\";\n        }\n        var queryURL=baseURL + '?' + querypart;\n        if (window.XMLHttpRequest) {\n        xmlhttp=new XMLHttpRequest();\n  }\n  else {\n        xmlhttp=new ActiveXObject(\"Microsoft.XMLHTTP\");\n  }\n  xmlhttp.open(\"GET\",queryURL,false);\n  xmlhttp.send();\n  return JSON.parse(xmlhttp.responseText);\n}\n\n/*\nsetting Data Source Name (DSN)\n*/\n\nvar dsn=\"http://dbpedia.org/resource/DBpedia\";\n\n/*\nVirtuoso pragma \"DEFINE get:soft \"replace\" instructs Virtuoso SPARQL engine to perform an HTTP GET using the IRI in FROM clause as Data Source URL with regards to \nDBMS record inserts\n*/\n\nvar query=\"DEFINE get:soft \\\"replace\\\"\\nSELECT DISTINCT * FROM &lt;\"+dsn+\"&gt; WHERE {?s ?p ?o}\"; \nvar data=sparqlQuery(query, \"/sparql/\");\n</pre>\n<h4>Output</h4>\n<p>Place the snippet above into the &lt;script/&gt; section of an\nHTML document to see the <a href=\"http://twitpic.com/3s2vs3/full\" id=\"link-id0x1cff2288\" name=\"link-id0x1cff2288\">query\nresult</a>.</p>\n<h3>Conclusion</h3>\n<p>JSON was chosen over XML (re. output format) since this is about\na \"no-brainer installation and utilization\" guide for a Javascript\ndeveloper that already knows how to use Javascript for HTTP based\ndata access within HTML. SPARQL just provides an added bonus to URL\ndexterity (delivered via <a class=\"auto-href\" href=\"http://dbpedia.org/resource/Uniform_Resource_Identifier\" id=\"link-id0x1d29da98\" name=\"link-id0x1d29da98\">URI</a> abstraction)\nwith regards to constructing Data Source Names or Addresses.</p>\n<h3>Related</h3>\n<ul>\n<li><a href=\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1652\" id=\"link-id0x1b0ffb28\" name=\"link-id0x1b0ffb28\">SPARQL Guide for\nthe PHP Developer</a></li>\n<li><a href=\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1651\" id=\"link-id0x1a8c5ae0\" name=\"link-id0x1a8c5ae0\">SPARQL Guide for\nthe Python Developer</a></li>\n<li><a href=\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1648\" id=\"link-id0x1b86ad28\" name=\"link-id0x1b86ad28\">SPARQL Guide for\nthe Ruby Developer</a></li>\n<li><a href=\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1646\" id=\"link-id0x1c7af188\" name=\"link-id0x1c7af188\">Simple Guide for\nusing SPARQL with Virtuoso</a></li>\n<li><a href=\"http://www.delicious.com/kidehen/sparql_tutorial\" id=\"link-id0x1ac1ba48\" name=\"link-id0x1ac1ba48\">General SPARQL\nTutorial Collection</a></li>\n<li><a href=\"http://www.delicious.com/kidehen/virtuoso_sparql_tutorial\" id=\"link-id0x1c7be660\" name=\"link-id0x1c7be660\">Virtuoso Specific\nSPARQL Tutorial Collection</a></li>\n<li><a href=\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1567\" id=\"link-id0x1c52b438\" name=\"link-id0x1c52b438\">The URI, URL, and\nLinked Data Meme's Generic HTTP URI</a>.</li>\n</ul>\n</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1653> <http://purl.org/dc/elements/1.1/creator> "Kingsley Idehen" .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1653> <http://purl.org/dc/elements/1.1/date> "2011-01-21T19:59:49Z" .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1653> <http://purl.org/dc/elements/1.1/relation> "http://www.openlinksw.com/blog/~kidehen/" .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1653> <http://purl.org/dc/elements/1.1/source> "Data Space by Kingsley Idehen" .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1653> <http://purl.org/rss/1.0/description> "What? A simple guide usable by any Javascript developer seeking to exploit SPARQL without hassles. Why? SPARQL is a powerful query language, results serialization format, and an HTTP based data access protocol from the W3C. It provides a mechanism for accessing and integrating data across Deductive Database Systems (colloquially referred to as triple or quad stores in Semantic Web and Linked Data circles) -- database systems (or data spaces) that manage proposition oriented records in 3-tuple (triples) or 4-tuple (quads) form. How? SPARQL queries are actually HTTP payloads (typically). Thus, using a RESTful client-server interaction pattern, you can dispatch calls ..." .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1653> <http://purl.org/rss/1.0/link> "http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1653" .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1653> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<h3>What?</h3>\n<p>A simple guide usable by any Javascript developer seeking to\nexploit <a class=\"auto-href\" href=\n\"http://dbpedia.org/resource/SPARQL\" id=\"link-id0x17b447e8\" name=\n\"link-id0x17b447e8\">SPARQL</a> without hassles.</p>\n<h3>Why?</h3>\n<p>SPARQL is a powerful query language, results serialization\nformat, and an HTTP based <a href=\n\"http://dbpedia.org/resource/Data\">data</a> access protocol from\nthe W3C. It provides a mechanism for accessing and integrating data\nacross <a href=\"http://en.wikipedia.org/wiki/Deductive_database\"\nid=\"link-id0x1cc76540\" name=\"link-id0x1cc76540\">Deductive Database\nSystems</a> (colloquially referred to as triple or quad stores in\n<a class=\"auto-href\" href=\n\"http://dbpedia.org/resource/Semantic_Web\" id=\"link-id0x1d944d78\"\nname=\"link-id0x1d944d78\">Semantic Web</a> and <a class=\"auto-href\"\nhref=\"http://dbpedia.org/resource/Linked_Data\" id=\n\"link-id0x1c7a87c8\" name=\"link-id0x1c7a87c8\">Linked Data</a>\ncircles) -- database systems (or data spaces) that manage\nproposition oriented records in 3-tuple (triples) or 4-tuple\n(quads) form.</p>\n<h3>How?</h3>\n<p>SPARQL queries are actually HTTP payloads (typically). Thus,\nusing a RESTful client-server interaction pattern, you can dispatch\ncalls to a SPARQL compliant data server and receive a payload for\nlocal processing.</p>\n<h4>Steps:</h4>\n<ol>\n<li>Determine which SPARQL endpoint you want to access e.g.\n<a href=\"http://dbpedia.org/sparql\" id=\"link-id0x1d476520\" name=\n\"link-id0x1d476520\">DBpedia</a> or a local <a class=\"auto-href\"\nhref=\"http://virtuoso.openlinksw.com\" id=\"link-id0x1bcfe140\" name=\n\"link-id0x1bcfe140\">Virtuoso</a> instance (typically:\nhttp://localhost:8890/sparql).</li>\n<li>If using Virtuoso, and you want to populate its quad store\nusing SPARQL, assign \"<a href=\n\"http://docs.openlinksw.com/virtuoso/rdfsparql.html#rdfsupportedprotocolendpointuri\"\nid=\"link-id0x1c7630b8\" name=\"link-id0x1c7630b8\">SPARQL_SPONGE</a>\"\nprivileges to user \"SPARQL\" (this is basic control, more\nsophisticated WebID based ACLs are available for controlling SPARQL\naccess).</li>\n</ol>\n<h4>Script:</h4>\n<pre>\n/*\nDemonstrating use of a single query to populate a # Virtuoso Quad Store via Javascript. \n*/\n\n/* \nHTTP <a href=\"http://dbpedia.org/resource/Uniform_Resource_Locator\"\nid=\"link-id0x1bc27a18\" name=\n\"link-id0x1bc27a18\">URL</a> is constructed accordingly with JSON query results format as the default via mime type.\n*/\n\nfunction sparqlQuery(query, baseURL, format) {\n        if(!format)\n                format=\"application/json\";\n        var params={\n                \"default-graph\": \"\", \"should-sponge\": \"soft\", \"query\": query,\n                \"debug\": \"on\", \"timeout\": \"\", \"format\": format,\n                \"save\": \"display\", \"fname\": \"\"\n        };\n        \n        var querypart=\"\";\n        for(var k in params) {\n                querypart+=k+\"=\"+encodeURIComponent(params[k])+\"&amp;\";\n        }\n        var queryURL=baseURL + '?' + querypart;\n        if (window.XMLHttpRequest) {\n        xmlhttp=new XMLHttpRequest();\n  }\n  else {\n        xmlhttp=new ActiveXObject(\"Microsoft.XMLHTTP\");\n  }\n  xmlhttp.open(\"GET\",queryURL,false);\n  xmlhttp.send();\n  return JSON.parse(xmlhttp.responseText);\n}\n\n/*\nsetting Data Source Name (DSN)\n*/\n\nvar dsn=\"http://dbpedia.org/resource/DBpedia\";\n\n/*\nVirtuoso pragma \"DEFINE get:soft \"replace\" instructs Virtuoso SPARQL engine to perform an HTTP GET using the IRI in FROM clause as Data Source URL with regards to \nDBMS record inserts\n*/\n\nvar query=\"DEFINE get:soft \\\"replace\\\"\\nSELECT DISTINCT * FROM &lt;\"+dsn+\"&gt; WHERE {?s ?p ?o}\"; \nvar data=sparqlQuery(query, \"/sparql/\");\n</pre>\n<h4>Output</h4>\n<p>Place the snippet above into the &lt;script/&gt; section of an\nHTML document to see the <a href=\"http://twitpic.com/3s2vs3/full\"\nid=\"link-id0x1cff2288\" name=\"link-id0x1cff2288\">query\nresult</a>.</p>\n<h3>Conclusion</h3>\n<p>JSON was chosen over XML (re. output format) since this is about\na \"no-brainer installation and utilization\" guide for a Javascript\ndeveloper that already knows how to use Javascript for HTTP based\ndata access within HTML. SPARQL just provides an added bonus to URL\ndexterity (delivered via <a class=\"auto-href\" href=\n\"http://dbpedia.org/resource/Uniform_Resource_Identifier\" id=\n\"link-id0x1d29da98\" name=\"link-id0x1d29da98\">URI</a> abstraction)\nwith regards to constructing Data Source Names or Addresses.</p>\n<h3>Related</h3>\n<ul>\n<li><a href=\n\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1652\"\nid=\"link-id0x1b0ffb28\" name=\"link-id0x1b0ffb28\">SPARQL Guide for\nthe PHP Developer</a></li>\n<li><a href=\n\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1651\"\nid=\"link-id0x1a8c5ae0\" name=\"link-id0x1a8c5ae0\">SPARQL Guide for\nthe Python Developer</a></li>\n<li><a href=\n\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1648\"\nid=\"link-id0x1b86ad28\" name=\"link-id0x1b86ad28\">SPARQL Guide for\nthe Ruby Developer</a></li>\n<li><a href=\n\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1646\"\nid=\"link-id0x1c7af188\" name=\"link-id0x1c7af188\">Simple Guide for\nusing SPARQL with Virtuoso</a></li>\n<li><a href=\"http://www.delicious.com/kidehen/sparql_tutorial\" id=\n\"link-id0x1ac1ba48\" name=\"link-id0x1ac1ba48\">General SPARQL\nTutorial Collection</a></li>\n<li><a href=\n\"http://www.delicious.com/kidehen/virtuoso_sparql_tutorial\" id=\n\"link-id0x1c7be660\" name=\"link-id0x1c7be660\">Virtuoso Specific\nSPARQL Tutorial Collection</a></li>\n<li><a href=\n\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1567\"\nid=\"link-id0x1c52b438\" name=\"link-id0x1c52b438\">The URI, URL, and\nLinked Data Meme's Generic HTTP URI</a>.</li>\n</ul>\n</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1653> <http://purl.org/rss/1.0/title> "SPARQL Guide for the Javascript Developer" .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1653> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1654> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<h3>What is <a class=\"auto-href\" href=\"http://dbpedia.org/resource/DBpedia\" id=\"link-id0x1d8b5df0\" name=\"link-id0x1d8b5df0\">DBpedia</a>?</h3>\n<p>DBpedia is a community effort to provide a contemporary\ndeductive database derived from Wikipedia content. Project\ncontributions can be partitioned as follows:</p>\n<ol>\n<li>Ontology Construction and Maintenance</li>\n<li>Dataset Generation via Wikipedia Content Extraction &amp;\nTransformation</li>\n<li>Live Database Maintenance &amp; Administration -- includes\nactual <a class=\"auto-href\" href=\"http://dbpedia.org/resource/Linked_Data\" id=\"link-id0x1ba81190\" name=\"link-id0x1ba81190\">Linked Data</a> loading and publishing,\nprovision of <a class=\"auto-href\" href=\"http://dbpedia.org/resource/SPARQL\" id=\"link-id0x1d8af808\" name=\"link-id0x1d8af808\">SPARQL</a> endpoint, and traditional DBA\nactivity</li>\n<li>Internationalization.</li>\n</ol>\n<h3>Why is DBpedia important?</h3>\n<p>Comprising the nucleus of the Linked Open <a href=\"http://dbpedia.org/resource/Data\">Data</a> effort, DBpedia also\nserves as a fulcrum for the burgeoning <a href=\"http://dbpedia.org/resource/World_Wide_Web\">Web</a> of Linked Data\nby delivering a dense and highly-interlinked lookup database. In\nits most basic form, DBpedia is a great source of strong and\nresolvable identifiers for People, Places, Organizations, Subject\nMatter, and many other data items of interest. Naturally, it\nprovides a fantastic starting point for comprehending the\nfundamental concepts underlying <a class=\"auto-href\" href=\"http://www.w3.org/People/Berners-Lee/card#i\" id=\"link-id0x1a8cc3d0\" name=\"link-id0x1a8cc3d0\">TimBL</a>'s initial\n<a href=\"http://blogs.usnet.private:8893/www.w3.org/DesignIssues/LinkedData.html\" id=\"link-id0x1cbbaf50\" name=\"link-id0x1cbbaf50\">Linked Data</a>\nmeme.</p>\n<h3>How do I use DBpedia?</h3>\n<p>Depending on your particular requirements, whether personal or\nservice-specific, DBpedia offers the following:</p>\n<ul>\n<li>Datasets that can be loaded on your deductive database (also\nknown as triple or quad stores) platform of choice</li>\n<li>Live browsable HTML+<a class=\"auto-href\" href=\"http://dbpedia.org/resource/RDFa\" id=\"link-id0x1d6b2148\" name=\"link-id0x1d6b2148\">RDFa</a> based <a class=\"auto-href\" href=\"http://dbpedia.org/resource/Entity\" id=\"link-id0x1d766a98\" name=\"link-id0x1d766a98\">entity</a> description pages</li>\n<li>A wide variety of data formats for importing entity description\ndata into a broad range of existing applications and services</li>\n<li>A SPARQL endpoint allowing ad-hoc querying over HTTP using the\nSPARQL query language, and delivering results serialized in a\nvariety of formats</li>\n<li>A broad variety of tools covering query by example, faceted\nbrowsing, <a class=\"auto-href\" href=\"http://dbpedia.org/resource/Full_text_search\" id=\"link-id0x1b330ff8\" name=\"link-id0x1b330ff8\">full text search</a>,\nentity name lookups, etc.</li>\n</ul>\n<h3>What is the DBpedia 3.6 + <a class=\"auto-href\" href=\"http://virtuoso.openlinksw.com\" id=\"link-id0x1d705780\" name=\"link-id0x1d705780\">Virtuoso</a> Cluster Edition Combo?</h3>\n<p><a class=\"auto-href\" href=\"http://www.openlinksw.com/dataspace/organization/openlink#this\" id=\"link-id0x1c894338\" name=\"link-id0x1c894338\">OpenLink\nSoftware</a> has preloaded the DBpedia 3.6 datasets into a\npreconfigured Virtuoso Cluster Edition database, and made the\npackage available for easy installation.</p>\n<h3>Why is the DBpedia+Virtuoso package important?</h3>\n<p>The DBpedia+Virtuoso package provides a cost-effective option\nfor personal or service-specific incarnations of DBpedia.</p>\n<p>For instance, you may have a service that isn't best-served by\ncompeting with the rest of the world for ad-hoc query time and\nresources on the live instance, which itself operates under various\nrestrictions which enable this ad-hoc query service to be provided\nat Web Scale.</p>\n<p>Now you can easily commission your own instance and quickly\nexploit DBpedia and Virtuoso's database feature set to the max,\npowered by your own hardware and network infrastructure.</p>\n<h3>How do I use the DBpedia+Virtuoso package?</h3>\n<p>Pre-requisites are simply:</p>\n<ol>\n<li><a href=\"http://wikis.openlinksw.com/dataspace/owiki/wiki/VirtuosoWikiWeb/VirtuosoInstallConfig\" id=\"link-id0x19e3e450\" name=\"link-id0x19e3e450\">Functional Virtuoso\nCluster Edition installation</a>.</li>\n<li><a href=\"http://virtuoso.openlinksw.com/pricing/\" id=\"link-id0x1b703ad8\" name=\"link-id0x1b703ad8\">Virtuoso Cluster\nEdition License</a>.</li>\n<li>90 GB of free disk space -- you ultimately only need 43 gigs,\nbut this our recommended free disk space size pre installation\ncompletion.</li>\n</ol>\n<p>To install the Virtuoso Cluster Edition simply perform the\nfollowing steps:</p>\n<ol>\n<li><a href=\"http://virtuoso.openlinksw.com/download/\" id=\"link-id0x17b41648\" name=\"link-id0x17b41648\">Download\nSoftware</a>.</li>\n<li>Run installer</li>\n<li>\n<p>Set key environment variables and start the OpenLink License\nManager, using command (this may vary depending on your shell):</p>\n<blockquote>\n<p><code>. /opt/virtuoso/virtuoso-enterprise.sh</code></p>\n</blockquote>\n</li>\n<li>Run the <code>mkcluster.sh</code> script which defaults to a 4\nnode cluster</li>\n<li>Set <code>VIRTUOSO_HOME</code> environment variable -- if you\nwant to start cluster databases distinct from single server\ndatabases via distinct root directory for database files (one that\nisn't adjacent to single-server database directories)</li>\n<li>Start Virtuoso Cluster Edition instances using command:\n<blockquote>\n<p><code>virtuoso-start.sh</code></p>\n</blockquote>\n</li>\n<li>Stop Virtuoso Cluster Edition instances using command:\n<blockquote>\n<p><code>virtuoso-stop.sh</code></p>\n</blockquote>\n</li>\n</ol>\n<p>To install your personal or service specific edition of DBpedia\nsimply perform the following steps:</p>\n<ol>\n<li>Navigate to your installation directory</li>\n<li>Download Installer script (<code><a href=\"https://s3.amazonaws.com/dbpedia-36-usa/dbpedia-install.sh\" id=\"link-id0x1da0c978\" name=\"link-id0x1da0c978\">dbpedia-install.sh</a></code>)</li>\n<li>Set execution mode on script using command:\n<blockquote>\n<p><code>chmod 755 dbpedia-install.sh</code></p>\n</blockquote>\n</li>\n<li>Shutdown any Virtuoso instances that may be currently\nrunning</li>\n<li>Set your <code>VIRTUOSO_HOME</code> environment variable, e.g.,\nto the current directory, via command (this may vary depending on\nyour shell):\n<blockquote>\n<p><code>export VIRTUOSO_HOME=`pwd`</code></p>\n</blockquote>\n</li>\n<li>Run script using command:\n<blockquote>\n<p><code>sh dbpedia-install.sh</code></p>\n</blockquote>\n</li>\n</ol>\n<p>Once the installation completes (approximately 1 hour and 30\nminutes from start time), perform the following steps:</p>\n<ol>\n<li>Verify that the Virtuoso Conductor (HTML based Admin UI) is in\nplace via:\n<blockquote>\n<p><code>http://localhost:[port]/conductor</code></p>\n</blockquote>\n</li>\n<li>Verify that the Precision Search &amp; Find UI is in place via:\n<blockquote>\n<p><code>http://localhost:[port]/fct</code></p>\n</blockquote>\n</li>\n<li>Verify that DBpedia's Green Entity Description Pages are in\nplace via:\n<blockquote>\n<p><code>http://localhost:[port]/resource/DBpedia</code></p>\n</blockquote>\n</li>\n</ol>\n<h3>Related</h3>\n<ul>\n<li><a href=\"http://www.openlinksw.com/dataspace/dav/wiki/Main/VirtAWSDBpedia351C\" id=\"link-id0x1d819b90\" name=\"link-id0x1d819b90\">Amazon EC2\nSnapshots for DBpedia 3.6 &amp; 3.5</a></li>\n<li><a href=\"http://virtuoso.openlinksw.com/download/\" id=\"link-id0x1c3e27c8\" name=\"link-id0x1c3e27c8\">Virtuoso Commercial\nEdition Download Page</a></li>\n<li><a href=\"http://docs.openlinksw.com/virtuoso/clusterstcnf.html\" id=\"link-id0x1d0ff170\" name=\"link-id0x1d0ff170\">Virtuoso Cluster\nEdition Guide</a></li>\n<li><a href=\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1594\" id=\"link-id0x1c891cf8\" name=\"link-id0x1c891cf8\">What is the DBpedia\nProject?</a></li>\n</ul>\n</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1654> <http://purl.org/dc/elements/1.1/creator> "Kingsley Idehen" .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1654> <http://purl.org/dc/elements/1.1/date> "2011-01-25T01:08:55Z" .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1654> <http://purl.org/dc/elements/1.1/relation> "http://www.openlinksw.com/blog/~kidehen/" .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1654> <http://purl.org/dc/elements/1.1/source> "Data Space by Kingsley Idehen" .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1654> <http://purl.org/rss/1.0/description> "What is DBpedia ? DBpedia is a community effort to provide a contemporary deductive database derived from Wikipedia content. Project contributions can be partitioned as follows: Ontology Construction and Maintenance Dataset Generation via Wikipedia Content Extraction &amp; Transformation Live Database Maintenance &amp; Administration -- includes actual Linked Data loading and publishing, provision of SPARQL endpoint, and traditional DBA activity Internationalization. Why is DBpedia important? Comprising the nucleus of the Linked Open Data effort, DBpedia also serves as a fulcrum for the burgeoning Web of Linked Data by delivering a dense and highly-interlinked lookup database. In its most basic form, DBpedia ..." .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1654> <http://purl.org/rss/1.0/link> "http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1654" .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1654> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<h3>What is <a class=\"auto-href\" href=\n\"http://dbpedia.org/resource/DBpedia\" id=\"link-id0x1d8b5df0\" name=\n\"link-id0x1d8b5df0\">DBpedia</a>?</h3>\n<p>DBpedia is a community effort to provide a contemporary\ndeductive database derived from Wikipedia content. Project\ncontributions can be partitioned as follows:</p>\n<ol>\n<li>Ontology Construction and Maintenance</li>\n<li>Dataset Generation via Wikipedia Content Extraction &amp;\nTransformation</li>\n<li>Live Database Maintenance &amp; Administration -- includes\nactual <a class=\"auto-href\" href=\n\"http://dbpedia.org/resource/Linked_Data\" id=\"link-id0x1ba81190\"\nname=\"link-id0x1ba81190\">Linked Data</a> loading and publishing,\nprovision of <a class=\"auto-href\" href=\n\"http://dbpedia.org/resource/SPARQL\" id=\"link-id0x1d8af808\" name=\n\"link-id0x1d8af808\">SPARQL</a> endpoint, and traditional DBA\nactivity</li>\n<li>Internationalization.</li>\n</ol>\n<h3>Why is DBpedia important?</h3>\n<p>Comprising the nucleus of the Linked Open <a href=\n\"http://dbpedia.org/resource/Data\">Data</a> effort, DBpedia also\nserves as a fulcrum for the burgeoning <a href=\n\"http://dbpedia.org/resource/World_Wide_Web\">Web</a> of Linked Data\nby delivering a dense and highly-interlinked lookup database. In\nits most basic form, DBpedia is a great source of strong and\nresolvable identifiers for People, Places, Organizations, Subject\nMatter, and many other data items of interest. Naturally, it\nprovides a fantastic starting point for comprehending the\nfundamental concepts underlying <a class=\"auto-href\" href=\n\"http://www.w3.org/People/Berners-Lee/card#i\" id=\n\"link-id0x1a8cc3d0\" name=\"link-id0x1a8cc3d0\">TimBL</a>'s initial\n<a href=\n\"http://blogs.usnet.private:8893/www.w3.org/DesignIssues/LinkedData.html\"\nid=\"link-id0x1cbbaf50\" name=\"link-id0x1cbbaf50\">Linked Data</a>\nmeme.</p>\n<h3>How do I use DBpedia?</h3>\n<p>Depending on your particular requirements, whether personal or\nservice-specific, DBpedia offers the following:</p>\n<ul>\n<li>Datasets that can be loaded on your deductive database (also\nknown as triple or quad stores) platform of choice</li>\n<li>Live browsable HTML+<a class=\"auto-href\" href=\n\"http://dbpedia.org/resource/RDFa\" id=\"link-id0x1d6b2148\" name=\n\"link-id0x1d6b2148\">RDFa</a> based <a class=\"auto-href\" href=\n\"http://dbpedia.org/resource/Entity\" id=\"link-id0x1d766a98\" name=\n\"link-id0x1d766a98\">entity</a> description pages</li>\n<li>A wide variety of data formats for importing entity description\ndata into a broad range of existing applications and services</li>\n<li>A SPARQL endpoint allowing ad-hoc querying over HTTP using the\nSPARQL query language, and delivering results serialized in a\nvariety of formats</li>\n<li>A broad variety of tools covering query by example, faceted\nbrowsing, <a class=\"auto-href\" href=\n\"http://dbpedia.org/resource/Full_text_search\" id=\n\"link-id0x1b330ff8\" name=\"link-id0x1b330ff8\">full text search</a>,\nentity name lookups, etc.</li>\n</ul>\n<h3>What is the DBpedia 3.6 + <a class=\"auto-href\" href=\n\"http://virtuoso.openlinksw.com\" id=\"link-id0x1d705780\" name=\n\"link-id0x1d705780\">Virtuoso</a> Cluster Edition Combo?</h3>\n<p><a class=\"auto-href\" href=\n\"http://www.openlinksw.com/dataspace/organization/openlink#this\"\nid=\"link-id0x1c894338\" name=\"link-id0x1c894338\">OpenLink\nSoftware</a> has preloaded the DBpedia 3.6 datasets into a\npreconfigured Virtuoso Cluster Edition database, and made the\npackage available for easy installation.</p>\n<h3>Why is the DBpedia+Virtuoso package important?</h3>\n<p>The DBpedia+Virtuoso package provides a cost-effective option\nfor personal or service-specific incarnations of DBpedia.</p>\n<p>For instance, you may have a service that isn't best-served by\ncompeting with the rest of the world for ad-hoc query time and\nresources on the live instance, which itself operates under various\nrestrictions which enable this ad-hoc query service to be provided\nat Web Scale.</p>\n<p>Now you can easily commission your own instance and quickly\nexploit DBpedia and Virtuoso's database feature set to the max,\npowered by your own hardware and network infrastructure.</p>\n<h3>How do I use the DBpedia+Virtuoso package?</h3>\n<p>Pre-requisites are simply:</p>\n<ol>\n<li><a href=\n\"http://wikis.openlinksw.com/dataspace/owiki/wiki/VirtuosoWikiWeb/VirtuosoInstallConfig\"\nid=\"link-id0x19e3e450\" name=\"link-id0x19e3e450\">Functional Virtuoso\nCluster Edition installation</a>.</li>\n<li><a href=\"http://virtuoso.openlinksw.com/pricing/\" id=\n\"link-id0x1b703ad8\" name=\"link-id0x1b703ad8\">Virtuoso Cluster\nEdition License</a>.</li>\n<li>90 GB of free disk space -- you ultimately only need 43 gigs,\nbut this our recommended free disk space size pre installation\ncompletion.</li>\n</ol>\n<p>To install the Virtuoso Cluster Edition simply perform the\nfollowing steps:</p>\n<ol>\n<li><a href=\"http://virtuoso.openlinksw.com/download/\" id=\n\"link-id0x17b41648\" name=\"link-id0x17b41648\">Download\nSoftware</a>.</li>\n<li>Run installer</li>\n<li>\n<p>Set key environment variables and start the OpenLink License\nManager, using command (this may vary depending on your shell):</p>\n<blockquote>\n<p><code>. /opt/virtuoso/virtuoso-enterprise.sh</code></p>\n</blockquote>\n</li>\n<li>Run the <code>mkcluster.sh</code> script which defaults to a 4\nnode cluster</li>\n<li>Set <code>VIRTUOSO_HOME</code> environment variable -- if you\nwant to start cluster databases distinct from single server\ndatabases via distinct root directory for database files (one that\nisn't adjacent to single-server database directories)</li>\n<li>Start Virtuoso Cluster Edition instances using command:\n<blockquote>\n<p><code>virtuoso-start.sh</code></p>\n</blockquote>\n</li>\n<li>Stop Virtuoso Cluster Edition instances using command:\n<blockquote>\n<p><code>virtuoso-stop.sh</code></p>\n</blockquote>\n</li>\n</ol>\n<p>To install your personal or service specific edition of DBpedia\nsimply perform the following steps:</p>\n<ol>\n<li>Navigate to your installation directory</li>\n<li>Download Installer script (<code><a href=\n\"https://s3.amazonaws.com/dbpedia-36-usa/dbpedia-install.sh\" id=\n\"link-id0x1da0c978\" name=\n\"link-id0x1da0c978\">dbpedia-install.sh</a></code>)</li>\n<li>Set execution mode on script using command:\n<blockquote>\n<p><code>chmod 755 dbpedia-install.sh</code></p>\n</blockquote>\n</li>\n<li>Shutdown any Virtuoso instances that may be currently\nrunning</li>\n<li>Set your <code>VIRTUOSO_HOME</code> environment variable, e.g.,\nto the current directory, via command (this may vary depending on\nyour shell):\n<blockquote>\n<p><code>export VIRTUOSO_HOME=`pwd`</code></p>\n</blockquote>\n</li>\n<li>Run script using command:\n<blockquote>\n<p><code>sh dbpedia-install.sh</code></p>\n</blockquote>\n</li>\n</ol>\n<p>Once the installation completes (approximately 1 hour and 30\nminutes from start time), perform the following steps:</p>\n<ol>\n<li>Verify that the Virtuoso Conductor (HTML based Admin UI) is in\nplace via:\n<blockquote>\n<p><code>http://localhost:[port]/conductor</code></p>\n</blockquote>\n</li>\n<li>Verify that the Precision Search &amp; Find UI is in place via:\n<blockquote>\n<p><code>http://localhost:[port]/fct</code></p>\n</blockquote>\n</li>\n<li>Verify that DBpedia's Green Entity Description Pages are in\nplace via:\n<blockquote>\n<p><code>http://localhost:[port]/resource/DBpedia</code></p>\n</blockquote>\n</li>\n</ol>\n<h3>Related</h3>\n<ul>\n<li><a href=\n\"http://www.openlinksw.com/dataspace/dav/wiki/Main/VirtAWSDBpedia351C\"\nid=\"link-id0x1d819b90\" name=\"link-id0x1d819b90\">Amazon EC2\nSnapshots for DBpedia 3.6 &amp; 3.5</a></li>\n<li><a href=\"http://virtuoso.openlinksw.com/download/\" id=\n\"link-id0x1c3e27c8\" name=\"link-id0x1c3e27c8\">Virtuoso Commercial\nEdition Download Page</a></li>\n<li><a href=\"http://docs.openlinksw.com/virtuoso/clusterstcnf.html\"\nid=\"link-id0x1d0ff170\" name=\"link-id0x1d0ff170\">Virtuoso Cluster\nEdition Guide</a></li>\n<li><a href=\n\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1594\"\nid=\"link-id0x1c891cf8\" name=\"link-id0x1c891cf8\">What is the DBpedia\nProject?</a></li>\n</ul>\n</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1654> <http://purl.org/rss/1.0/title> "Virtuoso + DBpedia 3.6 Installation Guide (Update 1)" .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1654> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1655> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">\n<h3>What?</h3>\n<p>A simple guide usable by any <a class=\"auto-href\" href=\"http://dbpedia.org/resource/Perl\" id=\"link-id0x1bdcab80\" name=\"link-id0x1bdcab80\">Perl</a> developer seeking to exploit <a class=\"auto-href\" href=\"http://dbpedia.org/resource/SPARQL\" id=\"link-id0x17b447e8\" name=\"link-id0x17b447e8\">SPARQL</a> without\nhassles.</p>\n<h3>Why?</h3>\n<p>SPARQL is a powerful query language, results serialization\nformat, and an HTTP based <a href=\"http://dbpedia.org/resource/Data\">data</a> access protocol from\nthe W3C. It provides a mechanism for accessing and integrating data\nacross <a href=\"http://en.wikipedia.org/wiki/Deductive_database\" id=\"link-id0x1cc76540\" name=\"link-id0x1cc76540\">Deductive Database\nSystems</a> (colloquially referred to as triple or quad stores in\n<a class=\"auto-href\" href=\"http://dbpedia.org/resource/Semantic_Web\" id=\"link-id0x1d944d78\" name=\"link-id0x1d944d78\">Semantic Web</a> and <a class=\"auto-href\" href=\"http://dbpedia.org/resource/Linked_Data\" id=\"link-id0x1c7a87c8\" name=\"link-id0x1c7a87c8\">Linked Data</a>\ncircles) -- database systems (or data spaces) that manage\nproposition oriented records in 3-tuple (triples) or 4-tuple\n(quads) form.</p>\n<h3>How?</h3>\n<p>SPARQL queries are actually HTTP payloads (typically). Thus,\nusing a RESTful client-server interaction pattern, you can dispatch\ncalls to a SPARQL compliant data server and receive a payload for\nlocal processing.</p>\n<h4>Steps:</h4>\n<ol>\n<li>Determine which SPARQL endpoint you want to access e.g.\n<a href=\"http://dbpedia.org/sparql\" id=\"link-id0x1d476520\" name=\"link-id0x1d476520\">DBpedia</a> or a local <a class=\"auto-href\" href=\"http://virtuoso.openlinksw.com\" id=\"link-id0x1bcfe140\" name=\"link-id0x1bcfe140\">Virtuoso</a> instance (typically:\nhttp://localhost:8890/sparql).</li>\n<li>If using Virtuoso, and you want to populate its quad store\nusing SPARQL, assign \"<a href=\"http://docs.openlinksw.com/virtuoso/rdfsparql.html#rdfsupportedprotocolendpointuri\" id=\"link-id0x1c7630b8\" name=\"link-id0x1c7630b8\">SPARQL_SPONGE</a>\"\nprivileges to user \"SPARQL\" (this is basic control, more\nsophisticated WebID based ACLs are available for controlling SPARQL\naccess).</li>\n</ol>\n<h4>Script:</h4>\n<pre>\n#\n# Demonstrating use of a single query to populate a \n# Virtuoso Quad Store via Perl. \n#\n\n# \n# HTTP <a href=\"http://dbpedia.org/resource/Uniform_Resource_Locator\" id=\"link-id0x1d6465e8\" name=\"link-id0x1d6465e8\">URL</a> is constructed accordingly with CSV query results format as the default via mime type.\n#\n\nuse CGI qw/:standard/;\nuse LWP::UserAgent;\nuse Data::Dumper;\nuse Text::CSV_XS;\n\nsub sparqlQuery(@args) {\n  my $query=shift;\n  my $baseURL=shift;\n  my $format=shift;\n        \n        %params=(\n                \"default-graph\" =&gt; \"\", \"should-sponge\" =&gt; \"soft\", \"query\" =&gt; $query,\n                \"debug\" =&gt; \"on\", \"timeout\" =&gt; \"\", \"format\" =&gt; $format,\n                \"save\" =&gt; \"display\", \"fname\" =&gt; \"\"\n        );\n        \n        @fragments=();\n        foreach $k (keys %params) {\n                $fragment=\"$k=\".CGI::escape($params{$k});\n                push(@fragments,$fragment);\n        }\n        $query=join(\"&amp;\", @fragments);\n        \n        $sparqlURL=\"${baseURL}?$query\";\n        \n        my $ua = LWP::UserAgent-&gt;new;\n        $ua-&gt;agent(\"MyApp/0.1 \");\n        my $req = HTTP::Request-&gt;new(GET =&gt; $sparqlURL);\n        my $res = $ua-&gt;request($req);\n        $str=$res-&gt;content;\n        \n        $csv = Text::CSV_XS-&gt;new();\n        \n        foreach $line ( split(/^/, $str) ) {\n                $csv-&gt;parse($line);\n                @bits=$csv-&gt;fields();\n          push(@rows, [ @bits ] );\n        }\n        return \\@rows;\n}\n\n\n# Setting Data Source Name (DSN)\n\n$dsn=\"http://dbpedia.org/resource/DBpedia\";\n\n# Virtuoso pragmas for instructing SPARQL engine to perform an HTTP GET using the IRI in\n# FROM clause as Data Source URL en route to DBMS\n# record Inserts.\n\n$query=\"DEFINE get:soft \\\"replace\\\"\\n\n\n# Generic (non Virtuoso specific SPARQL\n# Note: this will not add records to the \n# DBMS \n\nSELECT DISTINCT * FROM &lt;$dsn&gt; WHERE {?s ?p ?o}\"; \n\n$data=sparqlQuery($query, \"http://localhost:8890/sparql/\", \"text/csv\");\n\nprint \"Retrieved data:\\n\";\nprint Dumper($data);\n</pre>\n<h4>Output</h4>\n<pre>\nRetrieved data:\n$VAR1 = [\n          [\n            's',\n            'p',\n            'o'\n          ],\n          [\n            'http://dbpedia.org/resource/DBpedia',\n            'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',\n            'http://www.w3.org/2002/07/owl#Thing'\n          ],\n          [\n            'http://dbpedia.org/resource/DBpedia',\n            'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',\n            'http://dbpedia.org/ontology/Work'\n          ],\n          [\n            'http://dbpedia.org/resource/DBpedia',\n            'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',\n            'http://dbpedia.org/class/yago/Software106566077'\n          ],\n...\n</pre>\n<h3>Conclusion</h3>\n<p>CSV was chosen over XML (re. output format) since this is about\na \"no-brainer installation and utilization\" guide for a Perl\ndeveloper that already knows how to use Perl for HTTP based data\naccess within HTML. SPARQL just provides an added bonus to URL\ndexterity (delivered via <a class=\"auto-href\" href=\"http://dbpedia.org/resource/Uniform_Resource_Identifier\" id=\"link-id0x1d29da98\" name=\"link-id0x1d29da98\">URI</a> abstraction)\nwith regards to constructing Data Source Names or Addresses.</p>\n<h3>Related</h3>\n<ul>\n<li><a href=\"http://cpansearch.perl.org/src/TOBYINK/RDF-Query-Client-0.103/README\" id=\"link-id0x1c279130\" name=\"link-id0x1c279130\">RDF::Query::Client\nGuide</a></li>\n<li><a href=\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1653\" id=\"link-id0x1cf307f0\" name=\"link-id0x1cf307f0\">SPARQL Guide for\nthe Perl Developer</a></li>\n<li><a href=\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1652\" id=\"link-id0x1b0ffb28\" name=\"link-id0x1b0ffb28\">SPARQL Guide for\nthe PHP Developer</a></li>\n<li><a href=\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1651\" id=\"link-id0x1a8c5ae0\" name=\"link-id0x1a8c5ae0\">SPARQL Guide for\nthe Python Developer</a></li>\n<li><a href=\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1648\" id=\"link-id0x1b86ad28\" name=\"link-id0x1b86ad28\">SPARQL Guide for\nthe Ruby Developer</a></li>\n<li><a href=\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1646\" id=\"link-id0x1c7af188\" name=\"link-id0x1c7af188\">Simple Guide for\nusing SPARQL with Virtuoso</a></li>\n<li><a href=\"http://www.delicious.com/kidehen/sparql_tutorial\" id=\"link-id0x1ac1ba48\" name=\"link-id0x1ac1ba48\">General SPARQL\nTutorial Collection</a></li>\n<li><a href=\"http://www.delicious.com/kidehen/virtuoso_sparql_tutorial\" id=\"link-id0x1c7be660\" name=\"link-id0x1c7be660\">Virtuoso Specific\nSPARQL Tutorial Collection</a></li>\n<li><a href=\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1567\" id=\"link-id0x1c52b438\" name=\"link-id0x1c52b438\">The URI, URL, and\nLinked Data Meme's Generic HTTP URI</a>.</li>\n</ul>\n</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1655> <http://purl.org/dc/elements/1.1/creator> "Kingsley Idehen" .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1655> <http://purl.org/dc/elements/1.1/date> "2011-01-25T16:05:17Z" .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1655> <http://purl.org/dc/elements/1.1/relation> "http://www.openlinksw.com/blog/~kidehen/" .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1655> <http://purl.org/dc/elements/1.1/source> "Data Space by Kingsley Idehen" .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1655> <http://purl.org/rss/1.0/description> "What? A simple guide usable by any Perl developer seeking to exploit SPARQL without hassles. Why? SPARQL is a powerful query language, results serialization format, and an HTTP based data access protocol from the W3C. It provides a mechanism for accessing and integrating data across Deductive Database Systems (colloquially referred to as triple or quad stores in Semantic Web and Linked Data circles) -- database systems (or data spaces) that manage proposition oriented records in 3-tuple (triples) or 4-tuple (quads) form. How? SPARQL queries are actually HTTP payloads (typically). Thus, using a RESTful client-server interaction pattern, you can dispatch calls ..." .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1655> <http://purl.org/rss/1.0/link> "http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1655" .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1655> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>\n<h3>What?</h3>\n<p>A simple guide usable by any <a class=\"auto-href\" href=\n\"http://dbpedia.org/resource/Perl\" id=\"link-id0x1bdcab80\" name=\n\"link-id0x1bdcab80\">Perl</a> developer seeking to exploit <a class=\n\"auto-href\" href=\"http://dbpedia.org/resource/SPARQL\" id=\n\"link-id0x17b447e8\" name=\"link-id0x17b447e8\">SPARQL</a> without\nhassles.</p>\n<h3>Why?</h3>\n<p>SPARQL is a powerful query language, results serialization\nformat, and an HTTP based <a href=\n\"http://dbpedia.org/resource/Data\">data</a> access protocol from\nthe W3C. It provides a mechanism for accessing and integrating data\nacross <a href=\"http://en.wikipedia.org/wiki/Deductive_database\"\nid=\"link-id0x1cc76540\" name=\"link-id0x1cc76540\">Deductive Database\nSystems</a> (colloquially referred to as triple or quad stores in\n<a class=\"auto-href\" href=\n\"http://dbpedia.org/resource/Semantic_Web\" id=\"link-id0x1d944d78\"\nname=\"link-id0x1d944d78\">Semantic Web</a> and <a class=\"auto-href\"\nhref=\"http://dbpedia.org/resource/Linked_Data\" id=\n\"link-id0x1c7a87c8\" name=\"link-id0x1c7a87c8\">Linked Data</a>\ncircles) -- database systems (or data spaces) that manage\nproposition oriented records in 3-tuple (triples) or 4-tuple\n(quads) form.</p>\n<h3>How?</h3>\n<p>SPARQL queries are actually HTTP payloads (typically). Thus,\nusing a RESTful client-server interaction pattern, you can dispatch\ncalls to a SPARQL compliant data server and receive a payload for\nlocal processing.</p>\n<h4>Steps:</h4>\n<ol>\n<li>Determine which SPARQL endpoint you want to access e.g.\n<a href=\"http://dbpedia.org/sparql\" id=\"link-id0x1d476520\" name=\n\"link-id0x1d476520\">DBpedia</a> or a local <a class=\"auto-href\"\nhref=\"http://virtuoso.openlinksw.com\" id=\"link-id0x1bcfe140\" name=\n\"link-id0x1bcfe140\">Virtuoso</a> instance (typically:\nhttp://localhost:8890/sparql).</li>\n<li>If using Virtuoso, and you want to populate its quad store\nusing SPARQL, assign \"<a href=\n\"http://docs.openlinksw.com/virtuoso/rdfsparql.html#rdfsupportedprotocolendpointuri\"\nid=\"link-id0x1c7630b8\" name=\"link-id0x1c7630b8\">SPARQL_SPONGE</a>\"\nprivileges to user \"SPARQL\" (this is basic control, more\nsophisticated WebID based ACLs are available for controlling SPARQL\naccess).</li>\n</ol>\n<h4>Script:</h4>\n<pre>\n#\n# Demonstrating use of a single query to populate a \n# Virtuoso Quad Store via Perl. \n#\n\n# \n# HTTP <a href=\n\"http://dbpedia.org/resource/Uniform_Resource_Locator\" id=\n\"link-id0x1d6465e8\" name=\n\"link-id0x1d6465e8\">URL</a> is constructed accordingly with CSV query results format as the default via mime type.\n#\n\nuse CGI qw/:standard/;\nuse LWP::UserAgent;\nuse Data::Dumper;\nuse Text::CSV_XS;\n\nsub sparqlQuery(@args) {\n  my $query=shift;\n  my $baseURL=shift;\n  my $format=shift;\n        \n        %params=(\n                \"default-graph\" =&gt; \"\", \"should-sponge\" =&gt; \"soft\", \"query\" =&gt; $query,\n                \"debug\" =&gt; \"on\", \"timeout\" =&gt; \"\", \"format\" =&gt; $format,\n                \"save\" =&gt; \"display\", \"fname\" =&gt; \"\"\n        );\n        \n        @fragments=();\n        foreach $k (keys %params) {\n                $fragment=\"$k=\".CGI::escape($params{$k});\n                push(@fragments,$fragment);\n        }\n        $query=join(\"&amp;\", @fragments);\n        \n        $sparqlURL=\"${baseURL}?$query\";\n        \n        my $ua = LWP::UserAgent-&gt;new;\n        $ua-&gt;agent(\"MyApp/0.1 \");\n        my $req = HTTP::Request-&gt;new(GET =&gt; $sparqlURL);\n        my $res = $ua-&gt;request($req);\n        $str=$res-&gt;content;\n        \n        $csv = Text::CSV_XS-&gt;new();\n        \n        foreach $line ( split(/^/, $str) ) {\n                $csv-&gt;parse($line);\n                @bits=$csv-&gt;fields();\n          push(@rows, [ @bits ] );\n        }\n        return \\@rows;\n}\n\n\n# Setting Data Source Name (DSN)\n\n$dsn=\"http://dbpedia.org/resource/DBpedia\";\n\n# Virtuoso pragmas for instructing SPARQL engine to perform an HTTP GET using the IRI in\n# FROM clause as Data Source URL en route to DBMS\n# record Inserts.\n\n$query=\"DEFINE get:soft \\\"replace\\\"\\n\n\n# Generic (non Virtuoso specific SPARQL\n# Note: this will not add records to the \n# DBMS \n\nSELECT DISTINCT * FROM &lt;$dsn&gt; WHERE {?s ?p ?o}\"; \n\n$data=sparqlQuery($query, \"http://localhost:8890/sparql/\", \"text/csv\");\n\nprint \"Retrieved data:\\n\";\nprint Dumper($data);\n</pre>\n<h4>Output</h4>\n<pre>\nRetrieved data:\n$VAR1 = [\n          [\n            's',\n            'p',\n            'o'\n          ],\n          [\n            'http://dbpedia.org/resource/DBpedia',\n            'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',\n            'http://www.w3.org/2002/07/owl#Thing'\n          ],\n          [\n            'http://dbpedia.org/resource/DBpedia',\n            'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',\n            'http://dbpedia.org/ontology/Work'\n          ],\n          [\n            'http://dbpedia.org/resource/DBpedia',\n            'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',\n            'http://dbpedia.org/class/yago/Software106566077'\n          ],\n...\n</pre>\n<h3>Conclusion</h3>\n<p>CSV was chosen over XML (re. output format) since this is about\na \"no-brainer installation and utilization\" guide for a Perl\ndeveloper that already knows how to use Perl for HTTP based data\naccess within HTML. SPARQL just provides an added bonus to URL\ndexterity (delivered via <a class=\"auto-href\" href=\n\"http://dbpedia.org/resource/Uniform_Resource_Identifier\" id=\n\"link-id0x1d29da98\" name=\"link-id0x1d29da98\">URI</a> abstraction)\nwith regards to constructing Data Source Names or Addresses.</p>\n<h3>Related</h3>\n<ul>\n<li><a href=\n\"http://cpansearch.perl.org/src/TOBYINK/RDF-Query-Client-0.103/README\"\nid=\"link-id0x1c279130\" name=\"link-id0x1c279130\">RDF::Query::Client\nGuide</a></li>\n<li><a href=\n\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1653\"\nid=\"link-id0x1cf307f0\" name=\"link-id0x1cf307f0\">SPARQL Guide for\nthe Perl Developer</a></li>\n<li><a href=\n\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1652\"\nid=\"link-id0x1b0ffb28\" name=\"link-id0x1b0ffb28\">SPARQL Guide for\nthe PHP Developer</a></li>\n<li><a href=\n\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1651\"\nid=\"link-id0x1a8c5ae0\" name=\"link-id0x1a8c5ae0\">SPARQL Guide for\nthe Python Developer</a></li>\n<li><a href=\n\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1648\"\nid=\"link-id0x1b86ad28\" name=\"link-id0x1b86ad28\">SPARQL Guide for\nthe Ruby Developer</a></li>\n<li><a href=\n\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1646\"\nid=\"link-id0x1c7af188\" name=\"link-id0x1c7af188\">Simple Guide for\nusing SPARQL with Virtuoso</a></li>\n<li><a href=\"http://www.delicious.com/kidehen/sparql_tutorial\" id=\n\"link-id0x1ac1ba48\" name=\"link-id0x1ac1ba48\">General SPARQL\nTutorial Collection</a></li>\n<li><a href=\n\"http://www.delicious.com/kidehen/virtuoso_sparql_tutorial\" id=\n\"link-id0x1c7be660\" name=\"link-id0x1c7be660\">Virtuoso Specific\nSPARQL Tutorial Collection</a></li>\n<li><a href=\n\"http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1567\"\nid=\"link-id0x1c52b438\" name=\"link-id0x1c52b438\">The URI, URL, and\nLinked Data Meme's Generic HTTP URI</a>.</li>\n</ul>\n</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1655> <http://purl.org/rss/1.0/title> "SPARQL Guide for the Perl Developer" .
<http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1655> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://www.snee.com/bobdc.blog/2011/02/what-skos-xl-adds-to-skos.html> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\">Extra flexibility for label metadata.</div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://www.snee.com/bobdc.blog/2011/02/what-skos-xl-adds-to-skos.html> <http://purl.org/dc/elements/1.1/creator> "Bob DuCharme" .
<http://www.snee.com/bobdc.blog/2011/02/what-skos-xl-adds-to-skos.html> <http://purl.org/dc/elements/1.1/date> "2011-02-08T12:47:22Z" .
<http://www.snee.com/bobdc.blog/2011/02/what-skos-xl-adds-to-skos.html> <http://purl.org/dc/elements/1.1/relation> "http://www.snee.com/bobdc.blog/" .
<http://www.snee.com/bobdc.blog/2011/02/what-skos-xl-adds-to-skos.html> <http://purl.org/dc/elements/1.1/source> "bobdc.blog by Bob DuCharme" .
<http://www.snee.com/bobdc.blog/2011/02/what-skos-xl-adds-to-skos.html> <http://purl.org/rss/1.0/description> "\n Extra flexibility for label metadata. \n" .
<http://www.snee.com/bobdc.blog/2011/02/what-skos-xl-adds-to-skos.html> <http://purl.org/rss/1.0/link> "http://www.snee.com/bobdc.blog/2011/02/what-skos-xl-adds-to-skos.html" .
<http://www.snee.com/bobdc.blog/2011/02/what-skos-xl-adds-to-skos.html> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div>Extra flexibility for label metadata.</div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://www.snee.com/bobdc.blog/2011/02/what-skos-xl-adds-to-skos.html> <http://purl.org/rss/1.0/title> "What SKOS-XL adds to SKOS" .
<http://www.snee.com/bobdc.blog/2011/02/what-skos-xl-adds-to-skos.html> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
<http://www.w3.org/blog/SW/2011/02/04/japanese_translation_of_the_owl_2_overvi> <http://planetrdf.com/ns/content> "\n<div xmlns=\"http://www.w3.org/1999/xhtml\"><span lang=\"ja\">\u4E0A\u7DB1 \u79C0\u6CBB (Shuji Kamitsuna) has\npublished a Japanese translations of the <a href=\"http://www.w3.org/TR/2009/REC-owl2-overview-20091027/\">OWL 2\nOverview</a> document, under the title \u201C<a href=\"http://www.asahi-net.or.jp/~ax2s-kmtn/internet/owl2/rec-owl2-overview-20091027.html\" lang=\"ja\">OWL 2\u30A6\u30A7\u30D6\u30FB\u30AA\u30F3\u30C8\u30ED\u30B8\u30FC\u8A00\u8A9E\n\u30C9\u30AD\u30E5\u30E1\u30F3\u30C8\u6982\u8981</a>\u201D.</span></div>\n"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://www.w3.org/blog/SW/2011/02/04/japanese_translation_of_the_owl_2_overvi> <http://purl.org/dc/elements/1.1/creator> "W3C Semantic Web News" .
<http://www.w3.org/blog/SW/2011/02/04/japanese_translation_of_the_owl_2_overvi> <http://purl.org/dc/elements/1.1/date> "2011-02-04T16:00:49Z" .
<http://www.w3.org/blog/SW/2011/02/04/japanese_translation_of_the_owl_2_overvi> <http://purl.org/dc/elements/1.1/relation> "http://www.w3.org/2001/sw/" .
<http://www.w3.org/blog/SW/2011/02/04/japanese_translation_of_the_owl_2_overvi> <http://purl.org/dc/elements/1.1/source> "W3C Semantic Web News" .
<http://www.w3.org/blog/SW/2011/02/04/japanese_translation_of_the_owl_2_overvi> <http://purl.org/rss/1.0/description> "\n  \u4E0A\u7DB1 \u79C0\u6CBB (Shuji Kamitsuna) has\npublished a Japanese translations of the  OWL 2\nOverview  document, under the title \u201C OWL 2\u30A6\u30A7\u30D6\u30FB\u30AA\u30F3\u30C8\u30ED\u30B8\u30FC\u8A00\u8A9E\n\u30C9\u30AD\u30E5\u30E1\u30F3\u30C8\u6982\u8981 \u201D.  \n" .
<http://www.w3.org/blog/SW/2011/02/04/japanese_translation_of_the_owl_2_overvi> <http://purl.org/rss/1.0/link> "http://www.w3.org/blog/SW/2011/02/04/japanese_translation_of_the_owl_2_overvi" .
<http://www.w3.org/blog/SW/2011/02/04/japanese_translation_of_the_owl_2_overvi> <http://purl.org/rss/1.0/modules/content/encoded> "\n<div xmlns='http://www.w3.org/1999/xhtml'>\n<div><span lang=\"ja\" xml:lang=\"ja\">\u4E0A\u7DB1 \u79C0\u6CBB (Shuji Kamitsuna) has\npublished a Japanese translations of the <a href=\n\"http://www.w3.org/TR/2009/REC-owl2-overview-20091027/\">OWL 2\nOverview</a> document, under the title \u201C<a href=\n\"http://www.asahi-net.or.jp/~ax2s-kmtn/internet/owl2/rec-owl2-overview-20091027.html\"\nlang=\"ja\" xml:lang=\"ja\">OWL 2\u30A6\u30A7\u30D6\u30FB\u30AA\u30F3\u30C8\u30ED\u30B8\u30FC\u8A00\u8A9E\n\u30C9\u30AD\u30E5\u30E1\u30F3\u30C8\u6982\u8981</a>\u201D.</span></div>\n</div>"^^<http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral> .
<http://www.w3.org/blog/SW/2011/02/04/japanese_translation_of_the_owl_2_overvi> <http://purl.org/rss/1.0/title> "Japanese Translation of the OWL 2 Overview Document\nPublished" .
<http://www.w3.org/blog/SW/2011/02/04/japanese_translation_of_the_owl_2_overvi> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://purl.org/rss/1.0/item> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_10> <http://norman.walsh.name//2011/02/03/snowsnowsnow> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_11> <http://norman.walsh.name//2011/02/02/shortform> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_12> <http://decentralyze.com/2011/02/02/elevator-pitch-for-the-semantic-web/> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_13> <http://danbri.org/words/2011/02/01/658> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_14> <http://blogs.talis.com/nodalities/2011/02/talis-inc-ceo-bernadette-hyland-speaks-to-the-semantic-link-%e2%80%93-episode-1-and-2.php> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_15> <http://blogs.talis.com/nodalities/2011/02/nodalities-issue-12-%e2%80%93-now-available.php> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_16> <http://feedproxy.google.com/~r/Nodalities/~3/jxlMCwEZUW4/linked-spending-data-how-and-why-bother-pt2.php> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_17> <http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt2.php> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_18> <http://decentralyze.com/2011/01/28/can-we-use-lean-startup-methods-to-build-the-semantic-web/> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_19> <http://blogs.ecs.soton.ac.uk/enakting/2011/01/28/fast-sparql-xml-results-parser-in-python/> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_1> <http://www.snee.com/bobdc.blog/2011/02/what-skos-xl-adds-to-skos.html> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_20> <http://tomheath.com/blog/2011/01/the-linked-data-book-draft-table-of-contents/> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_21> <http://rdfa.info/2011/01/26/rdfa-grows/> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_22> <http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1655> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_23> <http://tripletalk.wordpress.com/2011/01/25/rdfa-deployment-across-the-web/> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_24> <http://rdfa.info/2011/01/25/flickr-uses-rdfa/> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_25> <http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1654> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_26> <http://www.ldodds.com/blog/2011/01/custom-lego-sets/> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_27> <http://dannyayers.com/2011/01/22/Some-Problems> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_28> <http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1653> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_29> <http://blog.georgikobilarov.com/2011/01/making-linked-data-work-isnt-the-problem/> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_2> <http://blog.aksw.org/2011/dr-philipp_cimiano_visits_aksw/> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_30> <http://feedproxy.google.com/~r/Nodalities/~3/qxI6zmzBTeU/linked-spending-data-how-and-why-bother-pt1.php> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_3> <http://blog.planetrdf.com/added-dydra-to-planet-rdf> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_4> <http://dublincore.org/news/2010/#dcmi-news-20110207-01> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_5> <http://blog.semantic-web.at/2011/02/07/drupal-and-the-semantic-web-interview-with-stephane-corlosquet/> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_6> <http://norman.walsh.name//2011/02/06/shortform> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_7> <http://jeenbroekstra.blogspot.com/2011/02/implementing-sparql-11-query-first.html> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_8> <http://norman.walsh.name//2011/01/30/shortform> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_9> <http://www.w3.org/blog/SW/2011/02/04/japanese_translation_of_the_owl_2_overvi> .
_:g82518540 <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/1999/02/22-rdf-syntax-ns#Seq> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_10> <http://norman.walsh.name//2011/02/03/snowsnowsnow> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_11> <http://norman.walsh.name//2011/02/02/shortform> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_12> <http://decentralyze.com/2011/02/02/elevator-pitch-for-the-semantic-web/> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_13> <http://danbri.org/words/2011/02/01/658> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_14> <http://blogs.talis.com/nodalities/2011/02/talis-inc-ceo-bernadette-hyland-speaks-to-the-semantic-link-%e2%80%93-episode-1-and-2.php> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_15> <http://blogs.talis.com/nodalities/2011/02/nodalities-issue-12-%e2%80%93-now-available.php> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_16> <http://feedproxy.google.com/~r/Nodalities/~3/jxlMCwEZUW4/linked-spending-data-how-and-why-bother-pt2.php> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_17> <http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt2.php> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_18> <http://decentralyze.com/2011/01/28/can-we-use-lean-startup-methods-to-build-the-semantic-web/> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_19> <http://blogs.ecs.soton.ac.uk/enakting/2011/01/28/fast-sparql-xml-results-parser-in-python/> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_1> <http://www.snee.com/bobdc.blog/2011/02/what-skos-xl-adds-to-skos.html> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_20> <http://tomheath.com/blog/2011/01/the-linked-data-book-draft-table-of-contents/> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_21> <http://rdfa.info/2011/01/26/rdfa-grows/> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_22> <http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1655> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_23> <http://tripletalk.wordpress.com/2011/01/25/rdfa-deployment-across-the-web/> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_24> <http://rdfa.info/2011/01/25/flickr-uses-rdfa/> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_25> <http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1654> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_26> <http://www.ldodds.com/blog/2011/01/custom-lego-sets/> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_27> <http://dannyayers.com/2011/01/22/Some-Problems> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_28> <http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1653> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_29> <http://blog.georgikobilarov.com/2011/01/making-linked-data-work-isnt-the-problem/> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_2> <http://blog.aksw.org/2011/dr-philipp_cimiano_visits_aksw/> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_30> <http://feedproxy.google.com/~r/Nodalities/~3/qxI6zmzBTeU/linked-spending-data-how-and-why-bother-pt1.php> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_3> <http://blog.planetrdf.com/added-dydra-to-planet-rdf> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_4> <http://dublincore.org/news/2010/#dcmi-news-20110207-01> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_5> <http://blog.semantic-web.at/2011/02/07/drupal-and-the-semantic-web-interview-with-stephane-corlosquet/> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_6> <http://norman.walsh.name//2011/02/06/shortform> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_7> <http://jeenbroekstra.blogspot.com/2011/02/implementing-sparql-11-query-first.html> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_8> <http://norman.walsh.name//2011/01/30/shortform> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_9> <http://www.w3.org/blog/SW/2011/02/04/japanese_translation_of_the_owl_2_overvi> .
_:g83020610 <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/1999/02/22-rdf-syntax-ns#Seq> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_10> <http://norman.walsh.name//2011/02/03/snowsnowsnow> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_11> <http://norman.walsh.name//2011/02/02/shortform> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_12> <http://decentralyze.com/2011/02/02/elevator-pitch-for-the-semantic-web/> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_13> <http://danbri.org/words/2011/02/01/658> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_14> <http://blogs.talis.com/nodalities/2011/02/talis-inc-ceo-bernadette-hyland-speaks-to-the-semantic-link-%e2%80%93-episode-1-and-2.php> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_15> <http://blogs.talis.com/nodalities/2011/02/nodalities-issue-12-%e2%80%93-now-available.php> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_16> <http://feedproxy.google.com/~r/Nodalities/~3/jxlMCwEZUW4/linked-spending-data-how-and-why-bother-pt2.php> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_17> <http://blogs.talis.com/nodalities/2011/01/linked-spending-data-how-and-why-bother-pt2.php> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_18> <http://decentralyze.com/2011/01/28/can-we-use-lean-startup-methods-to-build-the-semantic-web/> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_19> <http://blogs.ecs.soton.ac.uk/enakting/2011/01/28/fast-sparql-xml-results-parser-in-python/> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_1> <http://www.snee.com/bobdc.blog/2011/02/what-skos-xl-adds-to-skos.html> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_20> <http://tomheath.com/blog/2011/01/the-linked-data-book-draft-table-of-contents/> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_21> <http://rdfa.info/2011/01/26/rdfa-grows/> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_22> <http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1655> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_23> <http://tripletalk.wordpress.com/2011/01/25/rdfa-deployment-across-the-web/> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_24> <http://rdfa.info/2011/01/25/flickr-uses-rdfa/> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_25> <http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1654> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_26> <http://www.ldodds.com/blog/2011/01/custom-lego-sets/> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_27> <http://dannyayers.com/2011/01/22/Some-Problems> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_28> <http://www.openlinksw.com/blog/kidehen@openlinksw.com/blog/?id=1653> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_29> <http://blog.georgikobilarov.com/2011/01/making-linked-data-work-isnt-the-problem/> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_2> <http://blog.aksw.org/2011/dr-philipp_cimiano_visits_aksw/> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_30> <http://feedproxy.google.com/~r/Nodalities/~3/qxI6zmzBTeU/linked-spending-data-how-and-why-bother-pt1.php> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_3> <http://blog.planetrdf.com/added-dydra-to-planet-rdf> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_4> <http://dublincore.org/news/2010/#dcmi-news-20110207-01> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_5> <http://blog.semantic-web.at/2011/02/07/drupal-and-the-semantic-web-interview-with-stephane-corlosquet/> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_6> <http://norman.walsh.name//2011/02/06/shortform> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_7> <http://jeenbroekstra.blogspot.com/2011/02/implementing-sparql-11-query-first.html> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_8> <http://norman.walsh.name//2011/01/30/shortform> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#_9> <http://www.w3.org/blog/SW/2011/02/04/japanese_translation_of_the_owl_2_overvi> .
_:g90146890 <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/1999/02/22-rdf-syntax-ns#Seq> .
